{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "# Enables figures loading outside of browser.\n",
    "# If not run, figures will load inline.\n",
    "%matplotlib\n",
    "\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "import datetime\n",
    "import collections\n",
    "import itertools\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# Depends on: pip install sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Some matplotlib features are version dependent.\n",
    "assert(matplotlib.__version__ >= '2.1.2')\n",
    "\n",
    "# Depends on: pip install --upgrade google-cloud-bigquery\n",
    "from google.cloud import bigquery\n",
    "\n",
    "def run_query(query, project='mlab-sandbox'):\n",
    "    client = bigquery.Client(project=project)\n",
    "    job = client.query(query)\n",
    "\n",
    "    results = collections.defaultdict(list)\n",
    "    for row in job.result(timeout=300):\n",
    "        for key in row.keys():\n",
    "            results[key].append(row.get(key))\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def unlog(x, pos):\n",
    "    \"\"\"Formats the x axis for histograms taken on the log of values.\"\"\"\n",
    "    v = math.pow(10, x)\n",
    "    frac, whole = math.modf(v)\n",
    "    if frac > 0:\n",
    "        return '%.1f' % v\n",
    "    else:\n",
    "        return '%d' % whole\n",
    "    \n",
    "    \n",
    "def hist(vals, bin_count, log=True, cdf=False):\n",
    "    \"\"\"Produces hist or cdf values for smooth plots.\"\"\"\n",
    "    if log:\n",
    "        r = [math.log10(x) for x in vals]\n",
    "    else:\n",
    "        r = vals\n",
    "        \n",
    "    m, bins = np.histogram(r, bin_count, normed=True)\n",
    "    m = m.astype(float)\n",
    "\n",
    "    tops = m\n",
    "    if cdf:\n",
    "        tops = np.cumsum(m)\n",
    "        total = sum(m)\n",
    "        tops = [float(t) / total for t in tops ]\n",
    "    \n",
    "    return tops, bins\n",
    "\n",
    "\n",
    "logFormatter = matplotlib.ticker.FuncFormatter(unlog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_df(\n",
    "    df, xname='', yname='',\n",
    "    cname='', bins=None, cdf=False,\n",
    "    fig_by='', axes_by='', group_by='',\n",
    "    figsize=(6,8), axes=(1,1),\n",
    "    label='{group}',\n",
    "    xlabel='', ylabel='',\n",
    "    xlim=(), ylim=(),\n",
    "    fx=list, fy=list,\n",
    "    xlog=False, ylog=False,\n",
    "    suptitle='', title='', legend={}, figmap=None, log=None, fxn=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        df: pandas.DataFrame,\n",
    "        xname: str, name of column to use as x-axis.\n",
    "        yname: str, name of column to use as y-axis.\n",
    "        cname: str, name of column to use as data source.\n",
    "        cdf: bool,\n",
    "        bins: int or callable,\n",
    "        fig_by: str, name of column to split data into multiple figures.\n",
    "        axes_by: str, name of column to arrange into a single panel.\n",
    "        group_by: str, name of column to plot common split_by and group_by columns.\n",
    "        figsize: (int, int), dimensions of figure.\n",
    "        axes: (int, int), arrangement of axes within figure.\n",
    "        label: str,\n",
    "        xlabel: str,\n",
    "        ylabel: str,\n",
    "        xlim: (xmin, xmax),\n",
    "        ylim: (ymin, ymax),\n",
    "        fx: func,\n",
    "        fy: func,\n",
    "        xlog: bool,\n",
    "        ylog: bool,\n",
    "        suptitle: str,\n",
    "        title: str,\n",
    "        legend: **legend_args,\n",
    "        figmap: returned from a previous run of plot_df, used to overlay values\n",
    "            from multiple data frames. Must use the same fig_by, axes_by, and\n",
    "            group_by values.\n",
    "        log: bool,\n",
    "        f: callable,\n",
    "    Returns:\n",
    "      dict of str to (figures, axes) tuples\n",
    "    \"\"\"\n",
    "    def info(f):\n",
    "        if log:\n",
    "            print f\n",
    "\n",
    "    if figmap is None:\n",
    "        info('new figmap')\n",
    "        figmap = {}\n",
    "    scatter = None\n",
    "    if (xname and yname):\n",
    "        scatter = True\n",
    "    if cname:\n",
    "        scatter = False\n",
    "    if scatter is None:\n",
    "        raise Exception('Provide xname and yname or cname')\n",
    "    \n",
    "    for f in sorted(set(['default'] if not fig_by else df[fig_by])):\n",
    "        if f in figmap:\n",
    "            info('reusing figmap for %s' % f)\n",
    "            fig, ax = figmap[f]\n",
    "        else:\n",
    "            fig = plt.figure(figsize=figsize)\n",
    "            ax = fig.subplots(axes[0], axes[1], squeeze=False)\n",
    "            info('saving figmap for %s' % f)\n",
    "            figmap[f] = (fig, ax)\n",
    "        ax_index = list(itertools.product(range(axes[0]), range(axes[1])))\n",
    "        \n",
    "        df_fig = df if f == 'default' else df[df[fig_by] == f]\n",
    "        for p, a in enumerate(sorted(set(['default'] if not axes_by else df_fig[axes_by]))):\n",
    "\n",
    "            df_axes = df_fig if a == 'default' else df_fig[df_fig[axes_by] == a]\n",
    "            if p >= len(ax_index):\n",
    "                print 'SKIPPING', p, f, a, 'too few axes positions'\n",
    "                continue\n",
    "                \n",
    "            i, j = ax_index[p]\n",
    "            for g in sorted(set(['default'] if not group_by else df_axes[group_by])):\n",
    "                df_g = df_axes if g == 'default' else df_axes[df_axes[group_by] == g]\n",
    "\n",
    "                if scatter:\n",
    "                    x = fx(df_g[xname])\n",
    "                    y = fy(df_g[yname])\n",
    "                    l = label.format(figure=f, axis=a, group=g)\n",
    "                    ax[i][j].scatter(x, y, s=1, label=l)\n",
    "                else:\n",
    "                    r = df_g[cname]\n",
    "                    if bins is None:\n",
    "                        size = int(math.sqrt(len(r)))\n",
    "                    else:\n",
    "                        size = bins(r)\n",
    "                    if fxn:\n",
    "                        fxn(r, figure=f, axis=a, group=g, size=size)\n",
    "                    info(\"%s %s %s %s %s\" % (f, a, g, size, len(r)))\n",
    "                    h_tops, h_bins = hist(r, size, log=xlog , cdf=cdf)\n",
    "                    l = label.format(figure=f, axis=a, group=g, size=size)\n",
    "                    ax[i][j].plot(h_bins[:-1], h_tops, label=l)\n",
    "\n",
    "            if i != len(ax)-1:\n",
    "                ax[i][j].set_xticklabels([])\n",
    "\n",
    "            if title:\n",
    "                ax[i][j].set_title(title.format(figure=f, axis=a, group=g))\n",
    "            if ylabel:\n",
    "                ax[i][j].set_ylabel(ylabel.format(figure=f, axis=a, group=g))\n",
    "            if xlabel:\n",
    "                ax[i][j].set_xlabel(xlabel.format(figure=f, axis=a, group=g))\n",
    "\n",
    "            if xlim:\n",
    "                ax[i][j].set_xlim(xlim)\n",
    "            if ylim:\n",
    "                ax[i][j].set_ylim(ylim)\n",
    "\n",
    "            ax[i][j].grid(color='#dddddd')\n",
    "            ax[i][j].legend(fontsize='x-small', **legend)\n",
    "            if scatter:\n",
    "                ax[i][j].tick_params(axis='x', labelrotation=-90)\n",
    "            if xlog:\n",
    "                ax[i][j].xaxis.set_major_formatter(logFormatter)\n",
    "            if ylog:\n",
    "                ax[i][j].semilogy()\n",
    "\n",
    "        if suptitle:\n",
    "            fig.suptitle(suptitle.format(figure=f))\n",
    "        fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "    return figmap\n",
    "\n",
    "        \n",
    "def plot_scatter(df, xname, yname, **kwargs):\n",
    "    return plot_df(df, xname=xname, yname=yname, **kwargs)\n",
    "\n",
    "    \n",
    "def plot_hist(df, cname, bins=None, **kwargs):\n",
    "    return plot_df(df, cname=cname, bins=bins, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UPLINK UTILIZATION OVER TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    }
   ],
   "source": [
    "df_disco_pct = run_query(\"\"\"\n",
    "#standardSQL\n",
    "SELECT\n",
    "\n",
    "  UPPER(REGEXP_EXTRACT(hostname, r'mlab1.([a-z]{3})[0-9]{2}.*')) AS metro,\n",
    "  REGEXP_EXTRACT(hostname, r'mlab1.([a-z]{3}[0-9]{2}).*') AS site,\n",
    "  FORMAT_TIMESTAMP(\"%Y-%m-%d\", TIMESTAMP_TRUNC(sts, DAY)) AS day,\n",
    "  UNIX_SECONDS(TIMESTAMP_TRUNC(sts, DAY)) AS ts,  \n",
    "  0.8 * APPROX_QUANTILES(value, 101)[ORDINAL(50)] as bytes_50th,\n",
    "  APPROX_QUANTILES(value, 101)[ORDINAL(90)] as bytes_90th\n",
    "\n",
    "FROM (\n",
    "  SELECT\n",
    "    metric,\n",
    "    REGEXP_EXTRACT(hostname, r'(mlab1.[a-z]{3}[0-9]{2}).*') AS hostname,\n",
    "    sample.timestamp AS sts,\n",
    "    sample.value AS value\n",
    "  FROM\n",
    "    `measurement-lab.base_tables.switch*`,\n",
    "    UNNEST(sample) AS sample\n",
    "  WHERE\n",
    "    metric LIKE 'switch.octets.uplink.tx'\n",
    "    AND REGEXP_CONTAINS(hostname, r\"mlab1.(dfw|lga|nuq)\\d\\d\")\n",
    "  GROUP BY\n",
    "    hostname, metric, sts, value\n",
    ")\n",
    "WHERE\n",
    "  hostname IS NOT NULL\n",
    "GROUP BY\n",
    "  hostname, day, ts\n",
    "ORDER BY\n",
    "  hostname, day, ts\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default': (<Figure size 600x800 with 3 Axes>,\n",
       "  array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f8300c912d0>],\n",
       "         [<matplotlib.axes._subplots.AxesSubplot object at 0x7f8301b1e050>],\n",
       "         [<matplotlib.axes._subplots.AxesSubplot object at 0x7f8301b36310>]],\n",
       "        dtype=object))}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_scatter(\n",
    "    df_disco_pct, 'ts', 'bytes_50th',\n",
    "    axes_by='metro', group_by='site', axes=(3, 1),\n",
    "    suptitle='Daily Median Uplink Utilization',\n",
    "    ylabel=\"Mbps\",\n",
    "    title='{axis}',\n",
    "    xlim=(pd.to_datetime(\"2016-05-31\"), pd.to_datetime(\"2018-08-01\")),\n",
    "    ylim=(1e4, 1e9),\n",
    "    fx=lambda l: [pd.to_datetime(t, unit='s') for t in l],\n",
    "    legend={'loc':3, 'ncol':7, 'columnspacing':1},\n",
    "    ylog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily DISCO discard ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    }
   ],
   "source": [
    "df_disco_ratio = run_query(\"\"\"\n",
    "WITH measurementlab_switch_dedup AS (\n",
    "  SELECT\n",
    "    metric,\n",
    "    REGEXP_EXTRACT(hostname, r'(mlab[1-4].[a-z]{3}[0-9]{2}).*') AS hostname,\n",
    "    sample.timestamp AS sts,\n",
    "    sample.value AS value\n",
    "  FROM\n",
    "    `measurement-lab.base_tables.switch*`,\n",
    "    UNNEST(sample) AS sample\n",
    "  WHERE\n",
    "    (metric LIKE 'switch.discards.uplink.tx' OR metric LIKE 'switch.unicast.uplink.tx')\n",
    "    AND REGEXP_CONTAINS(hostname, r\"mlab1.(dfw|lga|nuq)\\d\\d\")\n",
    "  GROUP BY\n",
    "    hostname, metric, sts, value\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  UPPER(REGEXP_EXTRACT(hostname, r'mlab1.([a-z]{3})[0-9]{2}.*')) AS metro,\n",
    "  REGEXP_EXTRACT(hostname, r'mlab1.([a-z]{3}[0-9]{2}).*') AS site,\n",
    "  hostname,\n",
    "  day,\n",
    "  ts,\n",
    "  IF(total > 0, discards / total, 0) as ratio\n",
    "FROM (\n",
    "SELECT\n",
    "  hostname,\n",
    "  FORMAT_TIMESTAMP(\"%Y-%m-%d\", TIMESTAMP_TRUNC(sts, DAY)) AS day,\n",
    "  UNIX_SECONDS(TIMESTAMP_TRUNC(sts, DAY)) AS ts,\n",
    "  SUM(IF(metric = \"switch.discards.uplink.tx\", value, 0)) AS discards,\n",
    "  SUM(IF(metric = \"switch.unicast.uplink.tx\", value, 0)) AS total\n",
    "FROM\n",
    "  measurementlab_switch_dedup\n",
    "WHERE\n",
    "  hostname IS NOT NULL\n",
    "GROUP BY\n",
    "  hostname, day, ts\n",
    "HAVING\n",
    "  discards < total\n",
    "ORDER BY\n",
    "  hostname, day, ts\n",
    ")\n",
    "GROUP BY\n",
    "  hostname, day, ts, ratio\n",
    "HAVING\n",
    "  ratio < 0.01\n",
    "ORDER BY\n",
    "  hostname, day, ts\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default': (<Figure size 600x800 with 3 Axes>,\n",
       "  array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f82e283ee90>],\n",
       "         [<matplotlib.axes._subplots.AxesSubplot object at 0x7f8307a3cd10>],\n",
       "         [<matplotlib.axes._subplots.AxesSubplot object at 0x7f830211d990>]],\n",
       "        dtype=object))}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_scatter(\n",
    "    df_disco_ratio, 'ts', 'ratio', axes_by='metro', group_by='site', axes=(3, 1),\n",
    "    suptitle='Daily Packet Loss Ratio (discards / unicast)',\n",
    "    ylabel=\"Ratio\",\n",
    "    title='{axis}',\n",
    "    xlim=(pd.to_datetime(\"2016-05-31\"), pd.to_datetime(\"2018-08-01\")),\n",
    "    ylim=(1e-6, 1e-1),\n",
    "    fx=lambda l: [pd.to_datetime(t, unit='s') for t in l],\n",
    "    legend={'loc':2},\n",
    "    ylog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDT Median Download Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    }
   ],
   "source": [
    "df_ndt_all = run_query(\"\"\"\n",
    "WITH mlab_ndt AS (\n",
    "  SELECT\n",
    "    UPPER(REGEXP_EXTRACT(connection_spec.server_hostname, r\"([a-z]{3})[0-9]{2}\")) as metro,\n",
    "    REGEXP_EXTRACT(connection_spec.server_hostname, r\"([a-z]{3}[0-9]{2})\") as site,\n",
    "    web100_log_entry.connection_spec.remote_ip as remote_ip,\n",
    "    log_time,\n",
    "    (8 * (web100_log_entry.snap.HCThruOctetsAcked / (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd))) AS download_mbps\n",
    "\n",
    "  FROM\n",
    "  \n",
    "    `measurement-lab.base_tables.ndt*`\n",
    "  WHERE\n",
    "\n",
    "        REGEXP_CONTAINS(connection_spec.server_hostname, r\"(lga|dfw|nuq)\\d\\d\")\n",
    "    AND web100_log_entry.snap.HCThruOctetsAcked >= 1000000\n",
    "    AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) >= 9000000\n",
    "    AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) < 600000000\n",
    "    AND connection_spec.data_direction = 1\n",
    "    AND web100_log_entry.connection_spec.remote_ip != \"45.56.98.222\"\n",
    "    AND web100_log_entry.connection_spec.remote_ip != \"2600:3c03::f03c:91ff:fe33:819\"\n",
    "    AND web100_log_entry.connection_spec.remote_ip != \"35.225.75.192\"\n",
    "    AND web100_log_entry.connection_spec.remote_ip != \"35.192.37.249\"\n",
    "    AND web100_log_entry.connection_spec.remote_ip != \"35.193.254.117\"\n",
    "    AND anomalies.no_meta is not true\n",
    "    \n",
    "  \n",
    "  GROUP BY\n",
    "    connection_spec.server_hostname,\n",
    "    log_time,\n",
    "    web100_log_entry.connection_spec.remote_ip,\n",
    "    web100_log_entry.connection_spec.local_ip,\n",
    "    web100_log_entry.connection_spec.remote_port,\n",
    "    web100_log_entry.connection_spec.local_port,\n",
    "    download_mbps\n",
    ")\n",
    "    \n",
    "SELECT\n",
    "  metro,\n",
    "  site,\n",
    "  day,\n",
    " --  AVG(download_mbps) as download_mbps,\n",
    "  APPROX_QUANTILES(download_mbps, 101)[ORDINAL(50)] as download_mbps,\n",
    "  count(*) as count\n",
    "FROM\n",
    "(\n",
    "  SELECT\n",
    "    metro,\n",
    "    site,\n",
    "    TIMESTAMP_TRUNC(log_time, DAY) as day,\n",
    "    -- APPROX_QUANTILES(download_mbps, 101)[ORDINAL(50)] as download_mbps\n",
    "    MAX(download_mbps) as download_mbps\n",
    "  FROM\n",
    "    mlab_ndt\n",
    "\n",
    "  GROUP BY\n",
    "    metro, site, day, remote_ip\n",
    ")\n",
    "\n",
    "GROUP BY\n",
    "  metro, site, day\n",
    "\n",
    "ORDER BY\n",
    "  day\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_scatter(\n",
    "    df_ndt_all, 'day', 'download_mbps', axes_by='metro', group_by='site', axes=(3, 1),\n",
    "    suptitle='Median NDT Download Rates',\n",
    "    ylabel=\"Mbps\",\n",
    "    title='{axis}',\n",
    "    xlim=(pd.to_datetime(\"2016-05-31\"), pd.to_datetime(\"2018-08-01\")),\n",
    "    ylim=(0, 50),\n",
    "    fx=lambda l: [pd.to_datetime(t) for t in l],\n",
    "    legend={'loc':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDT Segs Retrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOT ENOUGH HISTORICAL NDT DATA TO GET FULL TIMELINE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    }
   ],
   "source": [
    "df_ndt_retrans = run_query(\"\"\"\n",
    "WITH mlab_ndt AS (\n",
    "  SELECT\n",
    "    connection_spec.server_hostname as hostname,\n",
    "    web100_log_entry.connection_spec.remote_ip as remote_ip,\n",
    "    log_time,\n",
    "    web100_log_entry.snap.SegsRetrans as SegsRetrans,\n",
    "    web100_log_entry.snap.SegsOut as SegsOut\n",
    "\n",
    "  FROM\n",
    "    `measurement-lab.base_tables.ndt*`\n",
    "\n",
    "  WHERE\n",
    "        REGEXP_CONTAINS(connection_spec.server_hostname, r\"(lga|dfw|nuq)\\d\\d\")\n",
    "    AND web100_log_entry.snap.HCThruOctetsAcked >= 1000000\n",
    "    AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) >= 9000000\n",
    "    AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) < 600000000\n",
    "    AND connection_spec.data_direction = 1\n",
    "    AND web100_log_entry.connection_spec.remote_ip != \"45.56.98.222\"\n",
    "    AND web100_log_entry.connection_spec.remote_ip != \"2600:3c03::f03c:91ff:fe33:819\"\n",
    "    AND web100_log_entry.connection_spec.remote_ip != \"35.225.75.192\"\n",
    "    AND web100_log_entry.connection_spec.remote_ip != \"35.192.37.249\"\n",
    "    AND web100_log_entry.connection_spec.remote_ip != \"35.193.254.117\"\n",
    "    AND log_time >= TIMESTAMP(\"2016-06-01\")\n",
    "  \n",
    "  GROUP BY\n",
    "    connection_spec.server_hostname,\n",
    "    log_time,\n",
    "    web100_log_entry.connection_spec.remote_ip,\n",
    "    web100_log_entry.connection_spec.local_ip,\n",
    "    web100_log_entry.connection_spec.remote_port,\n",
    "    web100_log_entry.connection_spec.local_port,\n",
    "    SegsRetrans,\n",
    "    SegsOut\n",
    ")\n",
    "    \n",
    "SELECT\n",
    "  UPPER(REGEXP_EXTRACT(hostname, r\"([a-z]{3})[0-9]{2}\")) as metro,\n",
    "  REGEXP_EXTRACT(hostname, r\"([a-z]{3}[0-9]{2})\") as site,\n",
    "  day,\n",
    "  APPROX_QUANTILES(ratio, 101)[ORDINAL(50)] AS median_ratio,\n",
    "  count(*) as count\n",
    "FROM\n",
    "(\n",
    "  SELECT\n",
    "    hostname,\n",
    "    TIMESTAMP_TRUNC(log_time, DAY) as day,\n",
    "    MAX(SAFE_DIVIDE(SegsRetrans, SegsOut)) as ratio\n",
    "\n",
    "  FROM\n",
    "    mlab_ndt\n",
    "\n",
    "  GROUP BY\n",
    "    hostname,\n",
    "    day,\n",
    "    remote_ip\n",
    ")\n",
    "\n",
    "GROUP BY\n",
    "  hostname, day\n",
    "\n",
    "ORDER BY\n",
    "  day\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default': (<Figure size 600x800 with 3 Axes>,\n",
       "  array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f82df2cb210>],\n",
       "         [<matplotlib.axes._subplots.AxesSubplot object at 0x7f82ddf5b610>],\n",
       "         [<matplotlib.axes._subplots.AxesSubplot object at 0x7f82de101f90>]],\n",
       "        dtype=object))}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_scatter(\n",
    "    df_ndt_retrans, 'day', 'median_ratio', axes_by='metro', group_by='site', axes=(3, 1),\n",
    "    suptitle='Median NDT Retransmission Ratio - (SegsRetran / SegsOut)',\n",
    "    ylabel=\"Ratio\",\n",
    "    title='{axis}',\n",
    "    xlim=(pd.to_datetime(\"2016-05-31\"), pd.to_datetime(\"2018-08-01\")),\n",
    "    ylim=(1e-6, 1e-1),\n",
    "    fx=lambda l: [pd.to_datetime(t) for t in l],\n",
    "    legend={'loc':2},\n",
    "    ylog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMBINED SegsRetrans & Switch Discards\n",
    "\n",
    "sites = [\n",
    "    ['dfw'],\n",
    "    ['lga'],\n",
    "    ['nuq'],\n",
    "]\n",
    "\n",
    "axes = [\n",
    "    [None],\n",
    "    [None],\n",
    "    [None],\n",
    "    [None],\n",
    "    [None],\n",
    "    [None],\n",
    "]\n",
    "def box(x, y, text):\n",
    "    plt.text(x, y, text,\n",
    "        bbox=dict(boxstyle=\"round\",\n",
    "              ec=(.5, 0.5, 1., 0.25),\n",
    "              fc=(.5, 0.8, 1., 0.25),\n",
    "        )\n",
    "    )\n",
    "print len(df_ndt_retrans)\n",
    "\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "\n",
    "fig = plt.figure(figsize=(6, 8))\n",
    "\n",
    "for i, site_row in enumerate(sites):\n",
    "    for j, site in enumerate(site_row):\n",
    "        axes[i][j] = plt.subplot2grid((3, 1), (i, j))\n",
    "        axes[i][j].set_ylabel('Ratio ' + site.upper())\n",
    "        if i != len(sites)-1:\n",
    "            axes[i][j].set_xticklabels([])\n",
    "\n",
    "        c = 0\n",
    "        for s in sorted(set(df_ndt_retrans['site'])):\n",
    "            if site in s:\n",
    "                ds = df_ndt_retrans[ (df_ndt_retrans['site'] == s) ]\n",
    "                d = [pd.to_datetime(t) for t in ds['day']]\n",
    "                axes[i][j].scatter(d, ds['median_ratio'], s=1, label=s, c=colors[c])\n",
    "                c += 1\n",
    "\n",
    "        axes[i][j].set_ylim(1e-6, 1e-1)\n",
    "        axes[i][j].set_xlim(pd.to_datetime(\"2016-05-31\"), pd.to_datetime(\"2018-08-01\"))\n",
    "        axes[i][j].tick_params(axis='x', labelrotation=-90)\n",
    "        axes[i][j].grid(color='#dddddd')\n",
    "        axes[i][j].legend(loc=2, fontsize='x-small')\n",
    "        axes[i][j].semilogy()\n",
    "\n",
    "for i, site_row in enumerate(sites):\n",
    "    for j, site in enumerate(site_row):       \n",
    "\n",
    "        if i != len(sites)-1:\n",
    "            axes[i][j].set_xticklabels([])\n",
    "        c = 0\n",
    "        for h in set(df_disco_ratio['hostname']):\n",
    "            if ('mlab1.' + site) in h:\n",
    "                ds = df_disco_ratio[ (df_disco_ratio['hostname'] == h) ]\n",
    "                d = [pd.to_datetime(t, unit='s') for t in ds['ts']]\n",
    "                axes[i][j].scatter(d, ds['ratio'], s=1, label=h[6:11], c=colors[c])\n",
    "                c += 1\n",
    "\n",
    "box(pd.to_datetime(\"2016-10-30\"), 5e-3, u\"Segs Retransmit ↘\")\n",
    "box(pd.to_datetime(\"2016-10-30\"), 9e-6, u\"Switch Discards ↗\")\n",
    "                \n",
    "fig.suptitle('Retrans & Switch Discard Rates')\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# NDT test distributions - Before & After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print df_ndt_dist.keys()\n",
    "print len(df_ndt_dist)\n",
    "\n",
    "def hist(vals, bin_count, log=True, cdf=False):\n",
    "    \"\"\"Produces hist or cdf values for smooth plots.\"\"\"\n",
    "    if log:\n",
    "        r = [math.log10(x) for x in vals]\n",
    "    else:\n",
    "        r = vals\n",
    "        \n",
    "    m, bins = np.histogram(r, bin_count, normed=True)\n",
    "    m = m.astype(float)\n",
    "\n",
    "    tops = m\n",
    "    if cdf:\n",
    "        tops = np.cumsum(m)\n",
    "        total = sum(m)\n",
    "        tops = [float(t) / total for t in tops ]\n",
    "    \n",
    "    return tops, bins\n",
    "\n",
    "seq = [(0, 0), (0, 1), (1, 0), (1, 1), (2, 0), (2, 1)]\n",
    "\n",
    "for site in set([v[6:9] for v in set(df_ndt_dist['name'])]):\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12, 6))\n",
    "    for p, h in enumerate(sorted([h for h in set(df_ndt_dist['name']) if site in h])):\n",
    "        before = None\n",
    "        r_before = None\n",
    "\n",
    "        for day in ['before-2w', 'after-2w']:\n",
    "            ds = df_ndt_dist[ (df_ndt_dist['name'] == h) & (df_ndt_dist['period'] == day) ]\n",
    "            r = ds['download_mbps']\n",
    "            #print h, len(r)\n",
    "            if not len(r):\n",
    "                continue\n",
    "\n",
    "            size = int(math.sqrt(len(r)))\n",
    "            \n",
    "            if day == 'after-2w':\n",
    "                size = before                 # Test before vs after\n",
    "                result = stats.ks_2samp(r, r_before)\n",
    "                #if result.pvalue < 0.01:     # print 'diff', h, result  # Test itself.\n",
    "                a, b = train_test_split(r, test_size=0.5)\n",
    "                result = stats.ks_2samp(a, b)\n",
    "                #if result.pvalue < 0.01:\n",
    "                    #print 'same', h, result\n",
    "                    #print '================================='\n",
    "\n",
    "            else:\n",
    "                before = size\n",
    "                r_before = r\n",
    "            \n",
    "                \n",
    "            #tops, bins = hist(r, int(1.8 * math.sqrt(len(r))), log=True , cdf=True)\n",
    "            #tops, bins = hist(r, int(math.sqrt(len(r))), log=True , cdf=True)\n",
    "            #print size, h, day\n",
    "            #tops, bins = hist(r, size, log=True , cdf=True)\n",
    "            tops, bins = hist(r, size, log=True , cdf=True)\n",
    "            #tops, bins = hist(r, int(1.8 * math.sqrt(len(r))), log=False , cdf=True)           \n",
    "            #tops, bins = hist(r, len(r), log=False , cdf=True)            \n",
    "            \n",
    "\n",
    "            #tops_a, bins_a = hist(a, int(1 * math.sqrt(len(a))), log=True, cdf=True)\n",
    "            #tops_b, bins_b = hist(b, int(1 * math.sqrt(len(b))), log=True, cdf=True)\n",
    "            if p > len(seq)-1:\n",
    "                print 'skipping', h\n",
    "                continue\n",
    "            i, j = seq[p]\n",
    "            #print h, len(bins), len(tops)\n",
    "            axes[i, j].plot(bins[:-1], tops, label='cdf-'+h[6:11] + '-' + str(day))\n",
    "            #axes[i, j].plot(bins_a[:-1], tops_a, label=h[6:11] + '-' + str(day)+'-a')\n",
    "            #axes[i, j].plot(bins_b[:-1], tops_b, label=h[6:11] + '-' + str(day)+'-b')\n",
    "            axes[i, j].set_title(h[6:11])\n",
    "            #axes[i, j].set_xlim(-10, 1000)\n",
    "            #axes[i, j].set_xlim(math.log10(.25), math.log10(1000))\n",
    "            axes[i, j].set_xlim(math.log10(.1), math.log10(1000))\n",
    "            axes[i, j].grid(color='#dddddd')\n",
    "            axes[i, j].legend(loc=2, fontsize='x-small')\n",
    "            #axes[i, j].set_ylim(-0.1, 1.1)\n",
    "            axes[i, j].xaxis.set_major_formatter(logFormatter)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.4)\n",
    "    fig.suptitle('NDT Download Distributions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n",
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n",
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n",
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n",
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-a156d9514204>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mrun_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mlab1.dfw04\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_discards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mrun_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mlab1.dfw05\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_discards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mrun_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mlab1.dfw06\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_discards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;31m#run_query(query(\"mlab1.lga03\")),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;31m#run_query(query(\"mlab1.lga04\")),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-9ae3265e9c0b>\u001b[0m in \u001b[0;36mrun_query\u001b[0;34m(query, project)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#print query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/soltesz/.local/lib/python2.7/site-packages/google/cloud/bigquery/client.pyc\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query, job_config, job_id, job_id_prefix, retry)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0mjob_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_job_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_id_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQueryJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m         \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/soltesz/.local/lib/python2.7/site-packages/google/cloud/bigquery/job.pyc\u001b[0m in \u001b[0;36m_begin\u001b[0;34m(self, client, retry)\u001b[0m\n\u001b[1;32m    394\u001b[0m         api_response = client._call_api(\n\u001b[1;32m    395\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             method='POST', path=path, data=self._build_resource())\n\u001b[0m\u001b[1;32m    397\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/soltesz/.local/lib/python2.7/site-packages/google/cloud/bigquery/client.pyc\u001b[0m in \u001b[0;36m_call_api\u001b[0;34m(self, retry, **kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEFAULT_RETRY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/soltesz/.local/lib/python2.7/site-packages/google/api_core/retry.pyc\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0msleep_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m                 \u001b[0mon_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m             )\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/soltesz/.local/lib/python2.7/site-packages/google/api_core/retry.pyc\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/soltesz/.local/lib/python2.7/site-packages/google/cloud/_http.pyc\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object)\u001b[0m\n\u001b[1;32m    288\u001b[0m         response = self._make_request(\n\u001b[1;32m    289\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontent_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m             headers=headers, target_object=_target_object)\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/soltesz/.local/lib/python2.7/site-packages/google/cloud/_http.pyc\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, method, url, data, content_type, headers, target_object)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'User-Agent'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUSER_AGENT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     def _do_request(self, method, url, headers, data,\n",
      "\u001b[0;32m/usr/local/google/home/soltesz/.local/lib/python2.7/site-packages/google/cloud/_http.pyc\u001b[0m in \u001b[0;36m_do_request\u001b[0;34m(self, method, url, headers, data, target_object)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \"\"\"\n\u001b[1;32m    211\u001b[0m         return self.http.request(\n\u001b[0;32m--> 212\u001b[0;31m             url=url, method=method, headers=headers, data=data)\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     def api_request(self, method, path, query_params=None,\n",
      "\u001b[0;32m/usr/local/google/home/soltesz/.local/lib/python2.7/site-packages/google/auth/transport/requests.pyc\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, data, headers, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         response = super(AuthorizedSession, self).request(\n\u001b[0;32m--> 201\u001b[0;31m             method, url, data=data, headers=request_headers, **kwargs)\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;31m# If the response indicated that the credentials needed to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/soltesz/.local/lib/python2.7/site-packages/requests/sessions.pyc\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    506\u001b[0m         }\n\u001b[1;32m    507\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/soltesz/.local/lib/python2.7/site-packages/requests/sessions.pyc\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/soltesz/.local/lib/python2.7/site-packages/requests/adapters.pyc\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m                 )\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/soltesz/.local/lib/python2.7/site-packages/urllib3/connectionpool.pyc\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/soltesz/.local/lib/python2.7/site-packages/urllib3/connectionpool.pyc\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.6 and older, Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self, buffering)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwill_close\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_UNKNOWN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_CS_IDLE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/httplib.pyc\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Initialize with Simple-Response defaults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"header line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/soltesz/.local/lib/python2.7/site-packages/urllib3/contrib/pyopenssl.pyc\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSysCallError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Unexpected EOF'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/google/home/soltesz/.local/lib/python2.7/site-packages/OpenSSL/SSL.pyc\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, bufsiz, flags)\u001b[0m\n\u001b[1;32m   1780\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_peek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsiz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1782\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsiz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1783\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1784\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def query(hostname, with_discards=True):\n",
    "    if with_discards:\n",
    "        # no-op.\n",
    "        discards = ''\n",
    "    else:\n",
    "        discards = 'NOT'\n",
    "    return (\"\"\"\n",
    "CREATE TEMPORARY FUNCTION\n",
    "  timeBin(ts_usec INT64,\n",
    "    size INT64) AS ( CAST(TRUNC(ts_usec / 1e6 / 10) * 10 AS INT64) );\n",
    "\n",
    "WITH\n",
    "  ndt_test_ids_with_discards AS (\n",
    "  SELECT\n",
    "    ndt.test_id AS test_id,\n",
    "    SUM(disco.discards) AS discards\n",
    "  FROM (\n",
    "    SELECT\n",
    "      hostname,\n",
    "      UNIX_SECONDS(sample.timestamp) - 10 AS tstart,\n",
    "      UNIX_SECONDS(sample.timestamp) AS tend,\n",
    "      sample.value AS discards\n",
    "    FROM\n",
    "      `measurement-lab.base_tables.switch*`,\n",
    "      UNNEST(sample) AS sample\n",
    "    WHERE\n",
    "      metric LIKE 'switch.discards.uplink.tx'\n",
    "      AND sample.timestamp BETWEEN TIMESTAMP(\"2018-02-11\") AND TIMESTAMP(\"2018-02-25\")\n",
    "      -- AND REGEXP_CONTAINS(hostname, r\"mlab[1-4].(dfw|lga|nuq)\\d\\d\")\n",
    "      AND REGEXP_CONTAINS(hostname, r'\"\"\"+hostname+\"\"\"')\n",
    "    GROUP BY\n",
    "      hostname,\n",
    "      tstart,\n",
    "      tend,\n",
    "      discards\n",
    "    HAVING\n",
    "      discards > 0 ) AS disco\n",
    "  JOIN (\n",
    "    SELECT\n",
    "      test_id,\n",
    "      connection_spec.server_hostname AS hostname,\n",
    "      timeBin(web100_log_entry.snap.StartTimeStamp, 10) AS tstart,\n",
    "      timeBin(web100_log_entry.snap.StartTimeStamp, 10) + 20 AS tend\n",
    "    FROM\n",
    "      `measurement-lab.base_tables.ndt*`\n",
    "    WHERE\n",
    "      (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) >= 9000000\n",
    "      AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) < 600000000\n",
    "      AND connection_spec.data_direction = 1\n",
    "      AND log_time BETWEEN TIMESTAMP(\"2018-02-11\") AND TIMESTAMP(\"2018-02-25\")\n",
    "      --AND REGEXP_CONTAINS(connection_spec.server_hostname, r\"mlab[1-4].(dfw|lga|nuq)\\d\\d\")\n",
    "      AND REGEXP_CONTAINS(connection_spec.server_hostname, r'\"\"\"+hostname+\"\"\"')\n",
    "    GROUP BY\n",
    "      hostname,\n",
    "      tstart,\n",
    "      tend,\n",
    "      test_id ) AS ndt\n",
    "  ON (disco.hostname = ndt.hostname\n",
    "      AND (disco.tstart = ndt.tstart OR disco.tend = ndt.tend))\n",
    "  GROUP BY\n",
    "    test_id\n",
    "  ORDER BY\n",
    "    test_id)\n",
    " \n",
    "  ,mlab_ndt AS (\n",
    "  SELECT\n",
    "    connection_spec.server_hostname AS server_hostname,\n",
    "    log_time,\n",
    "    web100_log_entry.connection_spec.remote_ip AS remote_ip,\n",
    "    (8 * (web100_log_entry.snap.HCThruOctetsAcked / (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd))) AS download_mbps\n",
    "  FROM\n",
    "    `measurement-lab.base_tables.ndt*`\n",
    "  WHERE\n",
    "    ( (TIMESTAMP_TRUNC(log_time, DAY) BETWEEN TIMESTAMP(\"2018-02-11\") AND TIMESTAMP(\"2018-02-25\") AND test_id \"\"\"+discards+\"\"\" IN(SELECT test_id FROM ndt_test_ids_with_discards))\n",
    "      OR (TIMESTAMP_TRUNC(log_time, DAY) BETWEEN TIMESTAMP(\"2018-03-11\") AND TIMESTAMP(\"2018-03-25\")))\n",
    "    AND web100_log_entry.snap.HCThruOctetsAcked >= 1000000\n",
    "    AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) >= 9000000\n",
    "    AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) < 600000000\n",
    "    AND connection_spec.data_direction = 1\n",
    "    --AND REGEXP_CONTAINS(connection_spec.server_hostname, r\"mlab[1-4].(dfw|lga|nuq)\\d\\d\")\n",
    "    AND REGEXP_CONTAINS(connection_spec.server_hostname, r'\"\"\"+hostname+\"\"\"')\n",
    "\n",
    "  GROUP BY\n",
    "    server_hostname,\n",
    "    log_time,\n",
    "    web100_log_entry.connection_spec.remote_ip,\n",
    "    web100_log_entry.connection_spec.local_ip,\n",
    "    web100_log_entry.connection_spec.remote_port,\n",
    "    web100_log_entry.connection_spec.local_port,\n",
    "    download_mbps)\n",
    "\n",
    "-- Split the two timebins into separate periods: before-2w and after-2w. Select clients (remote_ips) with more than 5 tests in both periods.\n",
    "-- All tests from the before-2w period will have a test_id found in ndt_test_ids_with_discards.\n",
    "SELECT\n",
    "  REGEXP_EXTRACT(server_hostname, r'mlab[1-4].([a-z]{3})[0-9]{2}.*') AS metro,\n",
    "  REGEXP_EXTRACT(server_hostname, r'mlab[1-4].([a-z]{3}[0-9]{2}).*') AS site,\n",
    "  REGEXP_EXTRACT(server_hostname, r'(mlab[1-4].[a-z]{3}[0-9]{2}).*') AS hostname,\n",
    "  CASE\n",
    "    WHEN TIMESTAMP_TRUNC(log_time, DAY) BETWEEN TIMESTAMP(\"2018-02-11\") AND TIMESTAMP(\"2018-02-25\") THEN 'before-2w'\n",
    "    WHEN TIMESTAMP_TRUNC(log_time, DAY) BETWEEN TIMESTAMP(\"2018-03-11\") AND TIMESTAMP(\"2018-03-25\") THEN 'after-2w'\n",
    "    ELSE 'what'\n",
    "  END AS period,\n",
    "  remote_ip,\n",
    "  STDDEV(download_mbps) AS download_stddev,\n",
    "  (STDDEV(download_mbps) / AVG(download_mbps)) AS download_cv,\n",
    "  MAX(download_mbps) AS download_max,\n",
    "  MIN(download_mbps) AS download_min,\n",
    "  AVG(download_mbps) AS download_avg\n",
    "\n",
    "\n",
    "FROM\n",
    "  mlab_ndt\n",
    "WHERE\n",
    "  remote_ip IN(\n",
    "    SELECT\n",
    "      remote_ip\n",
    "    FROM (\n",
    "      SELECT\n",
    "        remote_ip, count(*) as c1\n",
    "      FROM\n",
    "        mlab_ndt\n",
    "      WHERE\n",
    "        TIMESTAMP_TRUNC(log_time, DAY) BETWEEN TIMESTAMP(\"2018-02-11\") AND TIMESTAMP(\"2018-02-25\")\n",
    "      GROUP BY\n",
    "        remote_ip\n",
    "      HAVING c1 > 5\n",
    "    ) INNER JOIN (\n",
    "      SELECT\n",
    "        remote_ip AS remote_ip, count(*) as c2\n",
    "      FROM\n",
    "        mlab_ndt\n",
    "      WHERE\n",
    "        TIMESTAMP_TRUNC(log_time, DAY) BETWEEN TIMESTAMP(\"2018-03-11\") AND TIMESTAMP(\"2018-03-25\")\n",
    "      GROUP BY\n",
    "        remote_ip\n",
    "      HAVING c2 > 5\n",
    "    ) USING (remote_ip)) \n",
    "GROUP BY\n",
    "  server_hostname,\n",
    "  period,\n",
    "  remote_ip\n",
    "HAVING\n",
    "  download_stddev is not NULL\n",
    "  AND download_max is not NULL\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "df_ndt_variance = pd.concat([\n",
    "    run_query(query(\"mlab1.dfw02\", with_discards=True)),\n",
    "    run_query(query(\"mlab1.dfw03\", with_discards=True)),\n",
    "    run_query(query(\"mlab1.dfw04\", with_discards=True)),\n",
    "    run_query(query(\"mlab1.dfw05\", with_discards=True)),\n",
    "    run_query(query(\"mlab1.dfw06\", with_discards=True)),\n",
    "    #run_query(query(\"mlab1.lga03\")),\n",
    "    #run_query(query(\"mlab1.lga04\")),\n",
    "    #run_query(query(\"mlab1.lga05\")),\n",
    "    #run_query(query(\"mlab1.lga06\")),\n",
    "    #run_query(query(\"mlab1.lga07\")),\n",
    "    #run_query(query(\"mlab1.nuq02\")),\n",
    "    #run_query(query(\"mlab1.nuq03\")),\n",
    "    #run_query(query(\"mlab1.nuq04\")),\n",
    "    #run_query(query(\"mlab1.nuq05\")),\n",
    "    #run_query(query(\"mlab1.nuq06\")),\n",
    "])\n",
    "df_ndt_variance_without_discards = pd.concat([\n",
    "    run_query(query(\"mlab1.dfw02\", with_discards=False)),\n",
    "    run_query(query(\"mlab1.dfw03\", with_discards=False)),\n",
    "    run_query(query(\"mlab1.dfw04\", with_discards=False)),\n",
    "    run_query(query(\"mlab1.dfw05\", with_discards=False)),\n",
    "    run_query(query(\"mlab1.dfw06\", with_discards=False)),\n",
    "    #run_query(query(\"mlab1.lga03\")),\n",
    "    #run_query(query(\"mlab1.lga04\")),\n",
    "    #run_query(query(\"mlab1.lga05\")),\n",
    "    #run_query(query(\"mlab1.lga06\")),\n",
    "    #run_query(query(\"mlab1.lga07\")),\n",
    "    #run_query(query(\"mlab1.nuq02\")),\n",
    "    #run_query(query(\"mlab1.nuq03\")),\n",
    "    #run_query(query(\"mlab1.nuq04\")),\n",
    "    #run_query(query(\"mlab1.nuq05\")),\n",
    "    #run_query(query(\"mlab1.nuq06\")),\n",
    "])\n",
    "print len(df_ndt_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NOTE: does not preserve binsize across group_by. Each line re-calculates the bin size.\n",
    "f = plot_hist(\n",
    "    df_ndt_variance, 'download_stddev', lambda r: int(math.sqrt(len(r))),\n",
    "    #df_ndt_variance, 'download_stddev', lambda r: len(r),\n",
    "    fig_by='metro', axes_by='site', group_by='period',\n",
    "    suptitle='Distribution of Stddev of NDT Downloads per remote_ip',\n",
    "    label='w/ dis {group} ({size})',\n",
    "    title='{axis}', axes=(3, 2),\n",
    "    xlim=(math.log10(.01), math.log10(1000)),\n",
    "    cdf=False, xlog=True, figsize=(12, 10))\n",
    "\n",
    "#plot_hist(\n",
    "#    #df_ndt_variance_without_discards, 'download_stddev', lambda r: int(math.sqrt(len(r))),\n",
    "#    df_ndt_variance_without_discards, 'download_stddev', lambda r: len(r),\n",
    "#    fig_by='metro', axes_by='site', group_by='period',\n",
    "#    label='no dis {group} ({size})',\n",
    "#    axes=(3, 2), cdf=True, xlog=True, figmap=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    }
   ],
   "source": [
    "df_ndt_variance = run_query(\"\"\"\n",
    "WITH mlab_ndt AS (\n",
    "  SELECT\n",
    "    connection_spec.server_hostname as server_hostname,\n",
    "    log_time,\n",
    "    web100_log_entry.connection_spec.remote_ip AS remote_ip,\n",
    "    (8 * (web100_log_entry.snap.HCThruOctetsAcked / (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd))) AS download_mbps\n",
    "  FROM\n",
    "    `measurement-lab.base_tables.ndt*`\n",
    "  WHERE\n",
    "\n",
    "  (    TIMESTAMP_TRUNC(log_time, DAY) BETWEEN TIMESTAMP(\"2018-02-11\") AND TIMESTAMP(\"2018-02-25\")\n",
    "    OR TIMESTAMP_TRUNC(log_time, DAY) BETWEEN TIMESTAMP(\"2018-03-11\") AND TIMESTAMP(\"2018-03-25\"))\n",
    "  AND REGEXP_CONTAINS(connection_spec.server_hostname, r\"mlab1.(dfw|lga|nuq)\\d\\d\")\n",
    "  AND web100_log_entry.snap.HCThruOctetsAcked >= 1000000\n",
    "  AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) >= 9000000\n",
    "  AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) < 600000000\n",
    "  AND connection_spec.data_direction = 1\n",
    "  \n",
    "  GROUP BY\n",
    "    server_hostname,\n",
    "    log_time,\n",
    "    web100_log_entry.connection_spec.remote_ip,\n",
    "    web100_log_entry.connection_spec.local_ip,\n",
    "    web100_log_entry.connection_spec.remote_port,\n",
    "    web100_log_entry.connection_spec.local_port,\n",
    "    download_mbps)\n",
    "\n",
    "\n",
    "SELECT\n",
    "  REGEXP_EXTRACT(server_hostname, r'mlab[1-4].([a-z]{3})[0-9]{2}.*') AS metro,\n",
    "  REGEXP_EXTRACT(server_hostname, r'mlab[1-4].([a-z]{3}[0-9]{2}).*') AS site,\n",
    "  REGEXP_EXTRACT(server_hostname, r'(mlab[1-4].[a-z]{3}[0-9]{2}).*') AS hostname,\n",
    "  CASE\n",
    "    WHEN TIMESTAMP_TRUNC(log_time, DAY) BETWEEN TIMESTAMP(\"2018-02-11\") AND TIMESTAMP(\"2018-02-25\") THEN 'before-2w'\n",
    "    WHEN TIMESTAMP_TRUNC(log_time, DAY) BETWEEN TIMESTAMP(\"2018-03-11\") AND TIMESTAMP(\"2018-03-25\") THEN 'after-2w'\n",
    "    ELSE 'what'\n",
    "  END AS period,\n",
    "  remote_ip,\n",
    "  STDDEV(download_mbps) AS download_stddev,\n",
    "  (STDDEV(download_mbps) / AVG(download_mbps)) AS download_cv,\n",
    "  MAX(download_mbps) AS download_max,\n",
    "  MIN(download_mbps) AS download_min,\n",
    "  AVG(download_mbps) AS download_avg\n",
    "\n",
    "FROM\n",
    "  mlab_ndt\n",
    "WHERE\n",
    "  remote_ip IN(\n",
    "    SELECT\n",
    "      remote_ip\n",
    "    FROM (\n",
    "      SELECT\n",
    "        remote_ip, count(*) as c1\n",
    "      FROM\n",
    "        mlab_ndt\n",
    "      WHERE\n",
    "        TIMESTAMP_TRUNC(log_time, DAY) BETWEEN TIMESTAMP(\"2018-02-11\") AND TIMESTAMP(\"2018-02-25\")\n",
    "      GROUP BY\n",
    "        remote_ip\n",
    "      HAVING c1 > 5\n",
    "    ) INNER JOIN (\n",
    "      SELECT\n",
    "        remote_ip AS remote_ip, count(*) as c2\n",
    "      FROM\n",
    "        mlab_ndt\n",
    "      WHERE\n",
    "        TIMESTAMP_TRUNC(log_time, DAY) BETWEEN TIMESTAMP(\"2018-03-11\") AND TIMESTAMP(\"2018-03-25\")\n",
    "      GROUP BY\n",
    "        remote_ip\n",
    "      HAVING c2 > 5\n",
    "    ) USING (remote_ip)) \n",
    "GROUP BY\n",
    "  server_hostname,\n",
    "  period,\n",
    "  remote_ip\n",
    "  --download_mbps\n",
    "\n",
    "HAVING download_stddev is not NULL\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: does not preserve binsize across group_by. Each line re-calculates the bin size.\n",
    "f = plot_hist(\n",
    "    df_ndt_variance, 'download_stddev', lambda r: int(math.sqrt(len(r))),\n",
    "    #df_ndt_variance, 'download_stddev', lambda r: len(r),\n",
    "    fig_by='metro', axes_by='site', group_by='period',\n",
    "    suptitle='Distribution of Stddev of NDT Downloads per remote_ip',\n",
    "    label='{group} ({size})',\n",
    "    title='{axis}', axes=(3, 2),\n",
    "    xlim=(math.log10(.01), math.log10(1000)),\n",
    "    cdf=False, xlog=True, figsize=(12, 10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = plot_hist(\n",
    "    df_ndt_variance, 'download_max', lambda r: int(math.sqrt(len(r))),\n",
    "    fig_by='metro', axes_by='site', group_by='period',\n",
    "    suptitle='Distribution of MAX NDT Downloads per remote_ip)',\n",
    "    label='{group} ({size})',\n",
    "    title='{axis}', axes=(3, 2),\n",
    "    xlim=(math.log10(.01), math.log10(1000)),\n",
    "    cdf=False, xlog=True, figsize=(12, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = plot_hist(\n",
    "    df_ndt_variance, 'download_avg', lambda r: int(math.sqrt(len(r))),\n",
    "    fig_by='metro', axes_by='site', group_by='period',\n",
    "    suptitle='Distribution of AVG NDT Downloads per remote_ip)',\n",
    "    label='{group} ({size})',\n",
    "    title='{axis}', axes=(3, 2),\n",
    "    xlim=(math.log10(.01), math.log10(1000)),\n",
    "    cdf=False, xlog=True, figsize=(12, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3415137312296462 {'size': 43, 'group': u'after-2w', 'figure': u'dfw', 'axis': u'dfw01'}\n",
      "0.35785595930029795 {'size': 43, 'group': u'before-2w', 'figure': u'dfw', 'axis': u'dfw01'}\n",
      "0.3852970108437764 {'size': 44, 'group': u'after-2w', 'figure': u'dfw', 'axis': u'dfw02'}\n",
      "0.4094858219403052 {'size': 45, 'group': u'before-2w', 'figure': u'dfw', 'axis': u'dfw02'}\n",
      "0.3930978582941774 {'size': 45, 'group': u'after-2w', 'figure': u'dfw', 'axis': u'dfw03'}\n",
      "0.3961266024014954 {'size': 44, 'group': u'before-2w', 'figure': u'dfw', 'axis': u'dfw03'}\n",
      "0.4174804561196605 {'size': 45, 'group': u'after-2w', 'figure': u'dfw', 'axis': u'dfw04'}\n",
      "0.4514418111002561 {'size': 44, 'group': u'before-2w', 'figure': u'dfw', 'axis': u'dfw04'}\n",
      "0.29926654037343753 {'size': 50, 'group': u'after-2w', 'figure': u'dfw', 'axis': u'dfw05'}\n",
      "0.3320801662739377 {'size': 49, 'group': u'before-2w', 'figure': u'dfw', 'axis': u'dfw05'}\n",
      "0.40541188804417816 {'size': 45, 'group': u'after-2w', 'figure': u'dfw', 'axis': u'dfw06'}\n",
      "0.42642386183741676 {'size': 44, 'group': u'before-2w', 'figure': u'dfw', 'axis': u'dfw06'}\n",
      "0.4149943826880397 {'size': 54, 'group': u'after-2w', 'figure': u'lga', 'axis': u'lga02'}\n",
      "0.042551695662133245 {'size': 17, 'group': u'before-2w', 'figure': u'lga', 'axis': u'lga02'}\n",
      "0.430207433816288 {'size': 49, 'group': u'after-2w', 'figure': u'lga', 'axis': u'lga03'}\n",
      "0.5099189540193014 {'size': 50, 'group': u'before-2w', 'figure': u'lga', 'axis': u'lga03'}\n",
      "0.6220246635120912 {'size': 49, 'group': u'after-2w', 'figure': u'lga', 'axis': u'lga04'}\n",
      "0.6075505346031622 {'size': 50, 'group': u'before-2w', 'figure': u'lga', 'axis': u'lga04'}\n",
      "0.4327267773388593 {'size': 54, 'group': u'after-2w', 'figure': u'lga', 'axis': u'lga05'}\n",
      "0.41501019655075366 {'size': 55, 'group': u'before-2w', 'figure': u'lga', 'axis': u'lga05'}\n",
      "0.4098926950478214 {'size': 49, 'group': u'after-2w', 'figure': u'lga', 'axis': u'lga06'}\n",
      "0.43585971697613046 {'size': 51, 'group': u'before-2w', 'figure': u'lga', 'axis': u'lga06'}\n",
      "0.46233284590826706 {'size': 47, 'group': u'after-2w', 'figure': u'lga', 'axis': u'lga07'}\n",
      "0.511551637387802 {'size': 48, 'group': u'before-2w', 'figure': u'lga', 'axis': u'lga07'}\n",
      "0.44932611900534936 {'size': 31, 'group': u'after-2w', 'figure': u'nuq', 'axis': u'nuq02'}\n",
      "0.4766070436328526 {'size': 31, 'group': u'before-2w', 'figure': u'nuq', 'axis': u'nuq02'}\n",
      "0.4747411137919618 {'size': 31, 'group': u'after-2w', 'figure': u'nuq', 'axis': u'nuq03'}\n",
      "0.41217847775770716 {'size': 27, 'group': u'before-2w', 'figure': u'nuq', 'axis': u'nuq03'}\n",
      "0.4244501730817939 {'size': 28, 'group': u'after-2w', 'figure': u'nuq', 'axis': u'nuq04'}\n",
      "0.4442973944837691 {'size': 29, 'group': u'before-2w', 'figure': u'nuq', 'axis': u'nuq04'}\n",
      "0.4892550042606254 {'size': 31, 'group': u'after-2w', 'figure': u'nuq', 'axis': u'nuq05'}\n",
      "0.46793463943368063 {'size': 31, 'group': u'before-2w', 'figure': u'nuq', 'axis': u'nuq05'}\n",
      "0.4567814835034493 {'size': 31, 'group': u'after-2w', 'figure': u'nuq', 'axis': u'nuq06'}\n",
      "0.45144055492078206 {'size': 31, 'group': u'before-2w', 'figure': u'nuq', 'axis': u'nuq06'}\n"
     ]
    }
   ],
   "source": [
    "def print_median(r, **kwargs):\n",
    "    print np.median(r), kwargs\n",
    "    \n",
    "f = plot_hist(\n",
    "    df_ndt_variance, 'download_cv', #lambda r: int(math.sqrt(len(r))),\n",
    "    fig_by='metro', axes_by='site', group_by='period',\n",
    "    suptitle='Distribution of CV NDT Downloads per remote_ip)',\n",
    "    label='{group} ({size})',\n",
    "    title='{axis}', axes=(3, 2),\n",
    "    #xlim=(math.log10(.01), math.log10(10)),\n",
    "    cdf=True, xlog=True, figsize=(12, 10), fxn=print_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = plot_hist(\n",
    "    df_ndt_variance, 'download_min', #lambda r: int(math.sqrt(len(r))),\n",
    "    fig_by='metro', axes_by='site', group_by='period',\n",
    "    suptitle='Distribution of MIN NDT Downloads per remote_ip)',\n",
    "    label='{group} ({size})',\n",
    "    title='{axis}', axes=(3, 2),\n",
    "    #xlim=(math.log10(.01), math.log10(10)),\n",
    "    cdf=True, xlog=True, figsize=(12, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'dfw': (<Figure size 1200x1000 with 6 Axes>,\n",
       "  array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f8304647e50>,\n",
       "          <matplotlib.axes._subplots.AxesSubplot object at 0x7f83022170d0>],\n",
       "         [<matplotlib.axes._subplots.AxesSubplot object at 0x7f82f1ea8650>,\n",
       "          <matplotlib.axes._subplots.AxesSubplot object at 0x7f83118ea450>],\n",
       "         [<matplotlib.axes._subplots.AxesSubplot object at 0x7f82e0596890>,\n",
       "          <matplotlib.axes._subplots.AxesSubplot object at 0x7f82e5058050>]],\n",
       "        dtype=object)),\n",
       " u'lga': (<Figure size 1200x1000 with 6 Axes>,\n",
       "  array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f8301462050>,\n",
       "          <matplotlib.axes._subplots.AxesSubplot object at 0x7f8300062550>],\n",
       "         [<matplotlib.axes._subplots.AxesSubplot object at 0x7f82fe634a10>,\n",
       "          <matplotlib.axes._subplots.AxesSubplot object at 0x7f82f7104bd0>],\n",
       "         [<matplotlib.axes._subplots.AxesSubplot object at 0x7f83008fda50>,\n",
       "          <matplotlib.axes._subplots.AxesSubplot object at 0x7f830170a810>]],\n",
       "        dtype=object)),\n",
       " u'nuq': (<Figure size 1200x1000 with 6 Axes>,\n",
       "  array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f82ddcc5950>,\n",
       "          <matplotlib.axes._subplots.AxesSubplot object at 0x7f83003bbd50>],\n",
       "         [<matplotlib.axes._subplots.AxesSubplot object at 0x7f82e6fd2650>,\n",
       "          <matplotlib.axes._subplots.AxesSubplot object at 0x7f8300e7e290>],\n",
       "         [<matplotlib.axes._subplots.AxesSubplot object at 0x7f8302d78b10>,\n",
       "          <matplotlib.axes._subplots.AxesSubplot object at 0x7f830198b8d0>]],\n",
       "        dtype=object))}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: does not preserve binsize across group_by. Each line re-calculates the bin size.\n",
    "f = plot_hist(\n",
    "    #df_ndt_variance, 'download_max', lambda r: int(math.sqrt(len(r))),\n",
    "    df_ndt_variance, 'download_max', lambda r: len(r),\n",
    "    fig_by='metro',\n",
    "    axes_by='site', group_by='period', suptitle='Distribution of MAX NDT Downloads per remote_ip)',\n",
    "    label='w/ dis {group} ({size})',\n",
    "    title='{axis}', axes=(3, 2),\n",
    "    xlim=(math.log10(.01), math.log10(1000)),\n",
    "    cdf=True, xlog=True, figsize=(12, 10))\n",
    "\n",
    "# NOTE: does not preserve binsize across group_by. Each line re-calculates the bin size.\n",
    "plot_hist(\n",
    "    #df_ndt_variance_nodiscards, 'download_max', lambda r: int(math.sqrt(len(r))),\n",
    "    df_ndt_variance_without_discards, 'download_max', lambda r: len(r),\n",
    "    fig_by='metro', axes_by='site', group_by='period',\n",
    "    suptitle='Distribution of MAX NDT Downloads per remote_ip',\n",
    "    label='no dis {group} ({size})',\n",
    "    title='{axis}', axes=(3, 2),\n",
    "    cdf=True, xlog=True, figmap=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seq = [(0, 0), (0, 1), (1, 0), (1, 1), (2, 0), (2, 1)]\n",
    "\n",
    "skip = 'mlab1.lga02'\n",
    "for site in set([v[6:9] for v in set(df_ndt_variance['hostname'])]):\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12, 6))\n",
    "    for p, h in enumerate(sorted([h for h in set(df_ndt_variance['hostname']) if site in h])):\n",
    "        before = None\n",
    "        for day in ['before-2w', 'after-2w']:\n",
    "            ds = df_ndt_variance[ (df_ndt_variance['hostname'] == h) & (df_ndt_variance['period'] == day) ]\n",
    "            r = ds['download_stddev']\n",
    "            print h, len(r)\n",
    "            if not len(r) or h == skip:\n",
    "                continue\n",
    "\n",
    "            size = int(math.sqrt(len(r)))\n",
    "            if day == 'after-2w':\n",
    "                size = before\n",
    "            else:\n",
    "                before = size\n",
    "\n",
    "            tops, bins = hist(r, size, log=True, cdf=False)\n",
    "            if p > len(seq)-1:\n",
    "                print 'skipping', h\n",
    "                continue\n",
    "            i, j = seq[p]\n",
    "\n",
    "            axes[i, j].plot(bins[:-1], tops, label='cdf-'+h[6:11] + '-' + str(day))\n",
    "    \n",
    "            axes[i, j].set_title(h[6:11])\n",
    "            #axes[i, j].set_xlim(-10, 1000)\n",
    "            #axes[i, j].set_xlim(math.log10(.25), math.log10(1000))\n",
    "            axes[i, j].set_xlim(math.log10(.01), math.log10(1000))\n",
    "            axes[i, j].grid(color='#dddddd')\n",
    "            axes[i, j].legend(loc=2, fontsize='x-small')\n",
    "            #axes[i, j].set_ylim(-0.1, 1.1)\n",
    "            axes[i, j].xaxis.set_major_formatter(logFormatter)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.4)\n",
    "    fig.suptitle('Distribution of Stddev of NDT Downloads per remote_ip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    }
   ],
   "source": [
    "df_tests_with_discards = run_query(\"\"\"\n",
    "CREATE TEMPORARY FUNCTION\n",
    "  timeBin(ts_usec INT64,\n",
    "    size INT64) AS ( CAST(TRUNC(ts_usec / 1e6 / 10) * 10 AS INT64) );\n",
    "\n",
    "WITH\n",
    "  mlab_ndt_dedup AS (\n",
    "  SELECT\n",
    "    test_id,\n",
    "    log_time,\n",
    "    connection_spec.server_hostname AS hostname,\n",
    "    web100_log_entry.snap.StartTimeStamp as StartTimeStamp,\n",
    "    (8 * (web100_log_entry.snap.HCThruOctetsAcked / (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd))) AS download_mbps\n",
    "\n",
    "  FROM\n",
    "    `measurement-lab.base_tables.ndt*`\n",
    "  WHERE\n",
    "          (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) >= 9000000\n",
    "      AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) < 600000000\n",
    "      AND web100_log_entry.snap.HCThruOctetsAcked >= 1000000\n",
    "      AND connection_spec.data_direction = 1\n",
    "      AND REGEXP_CONTAINS(connection_spec.server_hostname, r\"mlab1.(dfw)\\d\\d\")\n",
    "      AND log_time BETWEEN TIMESTAMP(\"2017-06-01\") AND TIMESTAMP(\"2018-04-01\")\n",
    "\n",
    "  GROUP BY\n",
    "    test_id,\n",
    "    log_time,\n",
    "    hostname,\n",
    "    StartTimeStamp,\n",
    "    web100_log_entry.connection_spec.remote_ip,\n",
    "    web100_log_entry.connection_spec.local_ip,\n",
    "    web100_log_entry.connection_spec.remote_port,\n",
    "    web100_log_entry.connection_spec.local_port,\n",
    "    download_mbps)\n",
    "    \n",
    "  ,ndt_test_ids_with_discards AS (\n",
    "  SELECT\n",
    "    ndt.test_id as test_id,\n",
    "    ndt.hostname as hostname,\n",
    "    ndt.day as day,\n",
    "    SUM(disco.discards) AS discards,\n",
    "    ndt.download_mbps as download_mbps\n",
    "  FROM (\n",
    "    SELECT\n",
    "      hostname,\n",
    "      UNIX_SECONDS(sample.timestamp) - 10 AS tstart,\n",
    "      UNIX_SECONDS(sample.timestamp) AS tend,\n",
    "      sample.value AS discards\n",
    "    FROM\n",
    "      `measurement-lab.base_tables.switch*`,\n",
    "      UNNEST(sample) AS sample\n",
    "    WHERE\n",
    "      metric LIKE 'switch.discards.uplink.tx'\n",
    "      AND sample.timestamp BETWEEN TIMESTAMP(\"2017-06-01\") AND TIMESTAMP(\"2018-04-01\")\n",
    "      AND REGEXP_CONTAINS(hostname, r\"mlab1.(dfw)\\d\\d\")\n",
    "    GROUP BY\n",
    "      hostname,\n",
    "      tstart,\n",
    "      tend,\n",
    "      discards\n",
    "    HAVING\n",
    "      discards > 0\n",
    "  ) AS disco\n",
    "  JOIN (\n",
    "    SELECT\n",
    "      test_id,\n",
    "      connection_spec.server_hostname as hostname,\n",
    "      TIMESTAMP_TRUNC(log_time, DAY) as day,\n",
    "      timeBin(web100_log_entry.snap.StartTimeStamp, 10) AS tstart,\n",
    "      timeBin(web100_log_entry.snap.StartTimeStamp, 10) + 20 AS tend,\n",
    "      (8 * (web100_log_entry.snap.HCThruOctetsAcked / (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd))) AS download_mbps\n",
    "\n",
    "  FROM\n",
    "    `measurement-lab.base_tables.ndt*`\n",
    "  WHERE\n",
    "          (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) >= 9000000\n",
    "      AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) < 600000000\n",
    "      AND web100_log_entry.snap.HCThruOctetsAcked >= 1000000\n",
    "      AND connection_spec.data_direction = 1\n",
    "      AND REGEXP_CONTAINS(connection_spec.server_hostname, r\"mlab1.(dfw)\\d\\d\")\n",
    "      AND log_time BETWEEN TIMESTAMP(\"2017-06-01\") AND TIMESTAMP(\"2018-04-01\")\n",
    "    GROUP BY\n",
    "      test_id,\n",
    "      hostname,\n",
    "      day,\n",
    "      tstart,\n",
    "      tend,\n",
    "      download_mbps ) AS ndt\n",
    "  ON (disco.hostname = ndt.hostname\n",
    "      AND (disco.tstart = ndt.tstart OR disco.tend = ndt.tend))\n",
    "  GROUP BY\n",
    "    day, hostname, test_id, download_mbps\n",
    "  )\n",
    "\n",
    "\n",
    "-- Split the two timebins into separate periods: before-2w and after-2w. Select clients (remote_ips) with more than 5 tests in both periods.\n",
    "-- All tests from the before-2w period will have a test_id found in ndt_test_ids_with_discards.\n",
    "SELECT\n",
    " day, metro, site, hostname, discards, COUNT(*) as count\n",
    "FROM\n",
    "(\n",
    "SELECT\n",
    "  TIMESTAMP_TRUNC(log_time, DAY) as day,\n",
    "  REGEXP_EXTRACT(hostname, r'mlab[1-4].([a-z]{3})[0-9]{2}.*') AS metro,\n",
    "  REGEXP_EXTRACT(hostname, r'mlab[1-4].([a-z]{3}[0-9]{2}).*') AS site,\n",
    "  REGEXP_EXTRACT(hostname, r'(mlab[1-4].[a-z]{3}[0-9]{2}).*') AS hostname,\n",
    "  CASE\n",
    "    WHEN test_id IN(SELECT test_id from ndt_test_ids_with_discards) THEN 'discards'\n",
    "    WHEN test_id NOT IN(SELECT test_id from ndt_test_ids_with_discards) THEN 'without'\n",
    "    ELSE 'what'\n",
    "  END as discards\n",
    "  --COUNT(*) AS total_discards\n",
    "--  STDDEV(download_mbps) AS download_stddev,\n",
    "--  MAX(download_mbps) AS download_max\n",
    "\n",
    "FROM\n",
    "  mlab_ndt_dedup\n",
    "\n",
    ")\n",
    "GROUP BY\n",
    "  day, metro, site, hostname, discards\n",
    "\n",
    "--HAVING\n",
    "--  download_stddev is not NULL\n",
    "--  AND download_max is not NULL\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NOTE: does not preserve binsize across group_by. Each line re-calculates the bin size.\n",
    "f = plot_scatter(\n",
    "    df_tests_with_discards, 'day', 'count',\n",
    "    fig_by='metro', axes_by='site', group_by='discards', suptitle='NDT Tests with Discards',\n",
    "    label='{group}',\n",
    "    title='{axis}', axes=(3, 2),\n",
    "    figsize=(12, 10),\n",
    "    #ylim=(0, )\n",
    "    xlim=(pd.to_datetime(\"2016-05-31\"), pd.to_datetime(\"2018-08-01\")),\n",
    "    fx=lambda l: [pd.to_datetime(t) for t in l])\n",
    "    #legend={'loc':3, 'ncol':7, 'columnspacing':1},\n",
    "    #ylog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default': (<Figure size 600x800 with 3 Axes>,\n",
       "  array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f82f4f6c810>],\n",
       "         [<matplotlib.axes._subplots.AxesSubplot object at 0x7f82dea75490>],\n",
       "         [<matplotlib.axes._subplots.AxesSubplot object at 0x7f830469b150>]],\n",
       "        dtype=object))}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
