{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "# Enables figures loading outside of browser.\n",
    "# If not run, figures will load inline.\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "import datetime\n",
    "import collections\n",
    "\n",
    "# Some matplotlib features are version dependent.\n",
    "assert(matplotlib.__version__ >= '2.1.2')\n",
    "\n",
    "# Depends on: pip install --upgrade google-cloud-bigquery\n",
    "import query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unlog(x, pos):\n",
    "    v = math.pow(10, x)\n",
    "    frac, whole = math.modf(v)\n",
    "    if frac > 0:\n",
    "        return '%.1f' % v\n",
    "    else:\n",
    "        return '%d' % whole\n",
    "\n",
    "logFormatter = matplotlib.ticker.FuncFormatter(unlog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = query.sync_query(\"\"\"\n",
    "#standardSQL\n",
    "SELECT\n",
    "  name AS hostname,\n",
    "  FORMAT_TIMESTAMP(\"%Y-%m-%d\", TIMESTAMP_TRUNC(sts, DAY)) AS day,\n",
    "  UNIX_SECONDS(TIMESTAMP_TRUNC(sts, DAY)) AS ts,\n",
    "  SUM(IF(metric = 'switch.discards.uplink.tx', value, 0)) AS total_discards,\n",
    "  SUM(IF(metric = 'switch.unicast.uplink.tx', value, 0)) AS total_packets,\n",
    "  SUM(IF(metric = 'switch.octets.uplink.tx', value, 0)) AS total_bytes,\n",
    "  COUNTIF(metric = 'switch.discards.uplink.tx' AND value > 0) / 8640 AS pct_discards\n",
    "\n",
    "FROM (\n",
    "  SELECT\n",
    "    metric,\n",
    "    REGEXP_EXTRACT(hostname, r'(mlab[1-4].[a-z]{3}[0-9]{2}).*') AS name,\n",
    "    sample.timestamp AS sts,\n",
    "    sample.value AS value\n",
    "  FROM\n",
    "    `mlab-sandbox.base_tables.switch*`,\n",
    "    UNNEST(sample) AS sample\n",
    "  WHERE\n",
    "       metric LIKE 'switch.discards.uplink.tx'\n",
    "    OR metric LIKE 'switch.unicast.uplink.tx'\n",
    "    OR metric LIKE 'switch.octets.uplink.tx'\n",
    "  GROUP BY\n",
    "    hostname, metric, sts, value\n",
    ")\n",
    "WHERE\n",
    "  name IS NOT NULL\n",
    "GROUP BY\n",
    "  hostname, day, ts\n",
    "ORDER BY\n",
    "  hostname, day, ts\n",
    "\"\"\")\n",
    "\n",
    "df_disco = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DISCO RATES 90th PERCENTILE\n",
    "\n",
    "result = query.sync_query(\"\"\"\n",
    "#standardSQL\n",
    "SELECT\n",
    "  name AS hostname,\n",
    "  FORMAT_TIMESTAMP(\"%Y-%m-%d\", TIMESTAMP_TRUNC(sts, DAY)) AS day,\n",
    "  UNIX_SECONDS(TIMESTAMP_TRUNC(sts, DAY)) AS ts,\n",
    "  \n",
    "  APPROX_QUANTILES(value, 101)[ORDINAL(50)] as bytes_50th,\n",
    "  APPROX_QUANTILES(value, 101)[ORDINAL(90)] as bytes_90th,\n",
    "  APPROX_QUANTILES(value, 101)[ORDINAL(98)] as bytes_98th,\n",
    "  APPROX_QUANTILES(value, 101)[ORDINAL(99)] as bytes_99th,\n",
    "  MAX(value) as bytes_max\n",
    "\n",
    "FROM (\n",
    "  SELECT\n",
    "    metric,\n",
    "    REGEXP_EXTRACT(hostname, r'(mlab[1-4].[a-z]{3}[0-9]{2}).*') AS name,\n",
    "    sample.timestamp AS sts,\n",
    "    sample.value AS value\n",
    "  FROM\n",
    "    `mlab-sandbox.base_tables.switch*`,\n",
    "    UNNEST(sample) AS sample\n",
    "  WHERE\n",
    "    metric LIKE 'switch.octets.uplink.tx'\n",
    "  GROUP BY\n",
    "    hostname, metric, sts, value\n",
    ")\n",
    "WHERE\n",
    "  name IS NOT NULL\n",
    "GROUP BY\n",
    "  hostname, day, ts\n",
    "ORDER BY\n",
    "  hostname, day, ts\n",
    "\"\"\")\n",
    "\n",
    "df_disco_max = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    }
   ],
   "source": [
    "result = query.sync_query(\n",
    "    \"\"\"#standardSQL                                                                    \n",
    "CREATE TEMPORARY FUNCTION sliceFromIP(ipaddr STRING)\n",
    "    AS ( MOD(CAST(REGEXP_EXTRACT(ipaddr, r'[:.]([0-9]+)$') AS INT64), 64) - 10 );\n",
    "\n",
    "\n",
    "SELECT\n",
    "   hostname, ts, count(*) as count\n",
    "FROM (\n",
    "    SELECT\n",
    "        REGEXP_EXTRACT(test_id, r\"\\d\\d\\d\\d/\\d\\d/\\d\\d/(mlab[1-4].[a-z]{3}[0-9]{2})\") AS hostname,\n",
    "        UNIX_SECONDS(TIMESTAMP_TRUNC(log_time, DAY)) AS ts                            \n",
    "    FROM\n",
    "         `mlab-sandbox.private.sidestream*`\n",
    "    WHERE\n",
    "      REGEXP_CONTAINS(test_id, r\"mlab1.(dfw|lga|iad|lax|atl|nuq|yyz)[0-9]{2}.*\")     \n",
    "      AND sliceFromIP(web100_log_entry.connection_spec.local_ip) = 1\n",
    "      --AND web100_log_entry.snap.HCThruOctetsAcked >= 1000000 -- 819200                          \n",
    "      --AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "      --  web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "      --  web100_log_entry.snap.SndLimTimeSnd) >= 9000000                             \n",
    "      --AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "      --  web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "      --  web100_log_entry.snap.SndLimTimeSnd) < 600000000                            \n",
    "      --AND (web100_log_entry.snap.State = 1 OR                                       \n",
    "      --  (web100_log_entry.snap.State >= 5 AND                                       \n",
    "      --  web100_log_entry.snap.State <= 11))\n",
    "\n",
    "    GROUP BY\n",
    "      hostname, ts, web100_log_entry.connection_spec.remote_ip, web100_log_entry.connection_spec.remote_port, web100_log_entry.connection_spec.local_port, web100_log_entry.connection_spec.local_ip\n",
    ")\n",
    "\n",
    "GROUP BY\n",
    "  hostname, ts\n",
    "ORDER BY\n",
    "  hostname, ts\n",
    "    \"\"\")\n",
    "df_ss_count = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    }
   ],
   "source": [
    "result = query.sync_query(\n",
    "    \"\"\"#standardSQL   \n",
    "CREATE TEMPORARY FUNCTION\n",
    "  sliceFromIP(ipaddr STRING) AS ( MOD(MOD(CAST(REGEXP_EXTRACT(ipaddr, r'[:.]([0-9]+)$') AS INT64) - 10, 64), 13) );\n",
    "SELECT\n",
    "  site,\n",
    "  index,\n",
    "  UNIX_SECONDS(TIMESTAMP_TRUNC(TIMESTAMP_MICROS(StartTimeStamp), DAY)) AS ts,\n",
    "  SUM(bytes) / 86400 AS bytes_per_sec\n",
    "FROM (\n",
    "  SELECT\n",
    "    REGEXP_EXTRACT(test_id, r\"\\d\\d\\d\\d/\\d\\d/\\d\\d/mlab[1-4].([a-z]{3}[0-9]{2})\") AS site,\n",
    "    sliceFromIP(web100_log_entry.connection_spec.local_ip) AS index,\n",
    "    MAX(web100_log_entry.snap.HCThruOctetsAcked) AS bytes,\n",
    "    web100_log_entry.snap.StartTimeStamp AS StartTimeStamp\n",
    "  FROM\n",
    "    -- `mlab-sandbox.private.sidestream*`\n",
    "    `mlab-oti.private.sidestream*`\n",
    "  WHERE\n",
    "    REGEXP_CONTAINS(test_id, r\"mlab[1-4].(dfw|lga|iad|lax|atl|nuq|yyz)[0-9]{2}.*\")\n",
    "          --AND sliceFromIP(web100_log_entry.connection_spec.local_ip) = 1\n",
    "      --AND web100_log_entry.snap.HCThruOctetsAcked >= 1000000 -- 819200                          \n",
    "      --AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "      --  web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "      --  web100_log_entry.snap.SndLimTimeSnd) >= 9000000                             \n",
    "      --AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "      --  web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "      --  web100_log_entry.snap.SndLimTimeSnd) < 600000000                            \n",
    "      --AND (web100_log_entry.snap.State = 1 OR                                       \n",
    "      --  (web100_log_entry.snap.State >= 5 AND                                       \n",
    "      --  web100_log_entry.snap.State <= 11))\n",
    "  GROUP BY\n",
    "    site,\n",
    "    web100_log_entry.snap.StartTimeStamp,\n",
    "    index,\n",
    "    web100_log_entry.connection_spec.remote_ip,\n",
    "    web100_log_entry.connection_spec.remote_port,\n",
    "    web100_log_entry.connection_spec.local_port,\n",
    "    web100_log_entry.connection_spec.local_ip )\n",
    "GROUP BY\n",
    "  site,\n",
    "  index,\n",
    "  ts\n",
    "    \"\"\")\n",
    "df_ss_bytes = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    }
   ],
   "source": [
    "result = query.sync_query(\n",
    "    \"\"\"#standardSQL   \n",
    "SELECT\n",
    "  site,\n",
    "  UNIX_SECONDS(TIMESTAMP_TRUNC(TIMESTAMP_MICROS(StartTimeStamp), DAY)) AS ts,\n",
    "  SUM(bytes) / 86400 AS bytes_per_sec\n",
    "FROM (\n",
    "  SELECT\n",
    "    REGEXP_EXTRACT(test_id, r\"\\d\\d\\d\\d/\\d\\d/\\d\\d/mlab[1-4].([a-z]{3}[0-9]{2})\") AS site,\n",
    "    MAX(web100_log_entry.snap.HCThruOctetsAcked) AS bytes,\n",
    "    web100_log_entry.snap.StartTimeStamp AS StartTimeStamp\n",
    "  FROM\n",
    "    `mlab-sandbox.private.sidestream*`\n",
    "  WHERE\n",
    "    REGEXP_CONTAINS(test_id, r\"mlab[1-4].(dfw|lga|iad|lax|atl|nuq|yyz)[0-9]{2}.*\")\n",
    "          --AND sliceFromIP(web100_log_entry.connection_spec.local_ip) = 1\n",
    "      --AND web100_log_entry.snap.HCThruOctetsAcked >= 1000000 -- 819200                          \n",
    "      --AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "      --  web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "      --  web100_log_entry.snap.SndLimTimeSnd) >= 9000000                             \n",
    "      --AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "      --  web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "      --  web100_log_entry.snap.SndLimTimeSnd) < 600000000                            \n",
    "      --AND (web100_log_entry.snap.State = 1 OR                                       \n",
    "      --  (web100_log_entry.snap.State >= 5 AND                                       \n",
    "      --  web100_log_entry.snap.State <= 11))\n",
    "  GROUP BY\n",
    "    site,\n",
    "    web100_log_entry.snap.StartTimeStamp,\n",
    "    web100_log_entry.connection_spec.remote_ip,\n",
    "    web100_log_entry.connection_spec.remote_port,\n",
    "    web100_log_entry.connection_spec.local_port,\n",
    "    web100_log_entry.connection_spec.local_ip )\n",
    "GROUP BY\n",
    "  site,\n",
    "  ts\n",
    "    \"\"\")\n",
    "df_ss_total_bytes = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discards over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0.98,'Discards over time')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites = [\n",
    "    ['dfw', 'lga', 'iad'],\n",
    "    ['sea', 'atl', 'den'],\n",
    "    ['mia', 'nuq', 'ord'],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(12, 10))\n",
    "for i, site_row in enumerate(sites):\n",
    "    for j, site in enumerate(site_row):\n",
    "        if j != 0:\n",
    "            axes[i, j].set_yticklabels([])\n",
    "        if i != len(sites)-1:\n",
    "            axes[i, j].set_xticklabels([])\n",
    "        for h in set(df_disco['hostname']):\n",
    "            if ('mlab1.' + site) in h:\n",
    "                ds = df_disco[ (df_disco['hostname'] == h) & (df_disco['total_discards'] > 100)& (df_disco['total_discards'] < 1000000)]\n",
    "                axes[i, j].plot_date(dates.epoch2num(ds['ts']), ds['total_discards'], ls='-', ms=0, label=h[6:11])\n",
    "\n",
    "        axes[i, j].set_title(site)\n",
    "        axes[i, j].set_ylim(100, 1000000)\n",
    "        axes[i, j].tick_params(axis='x', labelrotation=90)\n",
    "        axes[i, j].grid(color='#dddddd')\n",
    "        axes[i, j].legend(loc=4, fontsize='x-small')\n",
    "        axes[i, j].semilogy()\n",
    "        \n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.4)\n",
    "fig.suptitle('Discards over time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avg Daily Rate over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0.98,'Daily Avg Rate over time')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites = [\n",
    "    ['dfw', 'lga', 'iad'],\n",
    "    ['sea', 'atl', 'den'],\n",
    "    ['mia', 'nuq', 'ord'],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(12, 10))\n",
    "for i, site_row in enumerate(sites):\n",
    "    for j, site in enumerate(site_row):\n",
    "        if j != 0:\n",
    "            axes[i, j].set_yticklabels([])\n",
    "        if i != len(sites)-1:\n",
    "            axes[i, j].set_xticklabels([])\n",
    "        for h in set(df_disco['hostname']):\n",
    "            if ('mlab1.' + site) in h:\n",
    "                ds = df_disco[ (df_disco['hostname'] == h) ] # & (df_disco['total_discards'] > 100)& (df_disco['total_discards'] < 1000000)]\n",
    "                axes[i, j].plot_date(dates.epoch2num(ds['ts']), ds['total_bytes'] / 1000000 / 86400, ls='-', ms=0, label=h[6:11])\n",
    "\n",
    "        axes[i, j].set_title(site)\n",
    "        axes[i, j].set_ylim(1, 1000)\n",
    "        axes[i, j].tick_params(axis='x', labelrotation=90)\n",
    "        axes[i, j].grid(color='#dddddd')\n",
    "        axes[i, j].legend(loc=2, fontsize='x-small', ncol=3)\n",
    "        axes[i, j].semilogy()\n",
    "        \n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.4)\n",
    "fig.suptitle('Daily Avg Rate over time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 90th Percentile Over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sites = [\n",
    "    ['dfw', 'lga', 'iad'],\n",
    "    ['lax', 'atl', 'den'],\n",
    "    ['sea', 'nuq', 'ord'], # MIA is low utilization.\n",
    "]\n",
    "\n",
    "sites = [\n",
    "    ['dfw', 'lga', 'iad'],\n",
    "    ['lax', 'atl',  'nuq'], #  'ord', # MIA is low utilization. 'den', 'sea' low enough.\n",
    "]\n",
    "\n",
    "cols = len(sites[0])\n",
    "fig = plt.figure(figsize=(4 * cols, 6))\n",
    "axes = [\n",
    "    [None] * cols,\n",
    "    [None] * cols,\n",
    "    #[None] * cols,\n",
    "]\n",
    "\n",
    "for r, siter in enumerate(sites):\n",
    "    for c, site in enumerate(siter):\n",
    "        for x, rate in enumerate(['90th']):\n",
    "            axes[r][c] = plt.subplot2grid((2, cols), (r, c))\n",
    "            if c != 0:\n",
    "                axes[r][c].set_yticklabels([])\n",
    "            else:\n",
    "                axes[r][c].set_ylabel('Mbps')\n",
    "\n",
    "            if r != 1:\n",
    "                axes[r][c].set_xticklabels([])\n",
    "\n",
    "            prefix = 'mlab1.' + site\n",
    "            ds_sites = df_disco_max[ df_disco_max['hostname'].str.contains(prefix) ]\n",
    "            for h in sorted(set(ds_sites[ ds_sites['hostname'].str.contains(prefix) ]['hostname'])):\n",
    "                ds = ds_sites[ (ds_sites['hostname'].str.contains(h)) ]\n",
    "                axes[r][c].plot_date(dates.epoch2num(ds['ts']), ds['bytes_' + rate] * 8 / 10000000, ls='-', ms=0, label=h[6:11] + '-' +  rate)\n",
    "\n",
    "            axes[r][c].set_title(site)\n",
    "            axes[r][c].set_ylim(100, 1000)\n",
    "            axes[r][c].tick_params(axis='x', labelrotation=90)\n",
    "            axes[r][c].grid(color='#dddddd')\n",
    "            axes[r][c].legend(loc=2, fontsize='x-small', ncol=2)\n",
    "\n",
    "fig.suptitle('Daily Percentile Rates')\n",
    "#fig.tight_layout()\n",
    "#fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SS COUNTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# [ 'lga', nuq'], #  'ord', # MIA is low utilization. 'den', 'sea' low enough.\n",
    "\n",
    "sites = [\n",
    "    ['dfw', 'iad', 'lax', 'atl', 'lga'],\n",
    "    #['dfw', 'iad', 'lax', 'atl'],\n",
    "]\n",
    "\n",
    "cols = len(sites[0])\n",
    "fig = plt.figure(figsize=(4 * cols, 6))\n",
    "axes = [\n",
    "    [None] * cols,\n",
    "    [None] * cols,\n",
    "]\n",
    "\n",
    "for r, siter in enumerate(sites):\n",
    "    for c, site in enumerate(siter):\n",
    "\n",
    "        for x, rate in enumerate(['98th']):\n",
    "            r = 1\n",
    "            axes[r][c] = plt.subplot2grid((2, cols), (r, c))\n",
    "            if c != 0:\n",
    "                axes[r][c].set_yticklabels([])\n",
    "                pass\n",
    "            else:\n",
    "                axes[r][c].set_ylabel('Connection Counts')\n",
    "\n",
    "            if r != 1:\n",
    "                axes[r][c].set_xticklabels([])\n",
    "\n",
    "            prefix = 'mlab1.' + site\n",
    "            ds_sites = df_ss_count[ df_ss_count['hostname'].str.contains(prefix) ]\n",
    "            for h in sorted(set(ds_sites[ ds_sites['hostname'].str.contains(prefix) ]['hostname'])):\n",
    "                #if 'lga02' in h:\n",
    "                #    continue\n",
    "                ds = ds_sites[ (ds_sites['hostname'].str.contains(h)) ]\n",
    "                axes[r][c].plot_date(dates.epoch2num(ds['ts']), ds['count'], ls='-', ms=0, label=h[6:11])\n",
    "\n",
    "            axes[r][c].set_title(site)\n",
    "            axes[r][c].set_ylim(0, 150000)\n",
    "            axes[r][c].set_xlim(dates.epoch2num(1498867200), dates.epoch2num(1533081600))\n",
    "            axes[r][c].tick_params(axis='x', labelrotation=90)\n",
    "            axes[r][c].grid(color='#dddddd')\n",
    "            axes[r][c].legend(loc=2, fontsize='x-small', ncol=2)\n",
    "            \n",
    "    for c, site in enumerate(siter):\n",
    "        for r in [0]:\n",
    "            axes[r][c] = plt.subplot2grid((2, cols), (r, c))\n",
    "            if c != 0:\n",
    "                axes[r][c].set_yticklabels([])\n",
    "            else:\n",
    "                axes[r][c].set_ylabel('Mbps')\n",
    "\n",
    "            if r != 1:\n",
    "                axes[r][c].set_xticklabels([])\n",
    "\n",
    "            prefix = 'mlab1.' + site\n",
    "            ds_sites = df_disco_max[ df_disco_max['hostname'].str.contains(prefix) ]\n",
    "            for h in sorted(set(ds_sites[ ds_sites['hostname'].str.contains(prefix) ]['hostname'])):\n",
    "                ds = ds_sites[ (ds_sites['hostname'].str.contains(h)) ]\n",
    "                axes[r][c].plot_date(dates.epoch2num(ds['ts']), ds['bytes_' + rate] * 8 / 10000000, ls='-', ms=0, label=h[6:11] + '-' +  rate)\n",
    "\n",
    "            axes[r][c].set_title(site)\n",
    "            axes[r][c].set_ylim(100, 1000)\n",
    "            axes[r][c].set_xlim(dates.epoch2num(1498867200), dates.epoch2num(1533081600))\n",
    "            axes[r][c].tick_params(axis='x', labelrotation=90)\n",
    "            axes[r][c].grid(color='#dddddd')\n",
    "            axes[r][c].legend(loc=2, fontsize='x-small', ncol=2)\n",
    "\n",
    "fig.suptitle('Daily 98th Percentile Switch Traffic & TCP Connection Counts Per Metro')\n",
    "#fig.tight_layout()\n",
    "#fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# [ 'lga', nuq'], #  'ord', # MIA is low utilization. 'den', 'sea' low enough.\n",
    "\n",
    "sites = [\n",
    "    ['dfw', 'iad', 'lax', 'atl', 'lga'],\n",
    "    #['dfw', 'iad', 'lax', 'atl'],\n",
    "]\n",
    "\n",
    "cols = len(sites[0])\n",
    "fig = plt.figure(figsize=(4 * cols, 6))\n",
    "axes = [\n",
    "    [None] * cols,\n",
    "    [None] * cols,\n",
    "]\n",
    "\n",
    "for r, siter in enumerate(sites):\n",
    "    for c, site in enumerate(siter):\n",
    "\n",
    "        for x, rate in enumerate(['98th']):\n",
    "            r = 1\n",
    "            axes[r][c] = plt.subplot2grid((2, cols), (r, c))\n",
    "            if c != 0:\n",
    "                axes[r][c].set_yticklabels([])\n",
    "                pass\n",
    "            else:\n",
    "                axes[r][c].set_ylabel('Dailiy Avg Mbps')\n",
    "\n",
    "            if r != 1:\n",
    "                axes[r][c].set_xticklabels([])\n",
    "\n",
    "            prefix = site\n",
    "            ds_sites = df_ss_total_bytes[ df_ss_total_bytes['site'].str.contains(prefix) ]\n",
    "            for h in sorted(set(ds_sites[ ds_sites['site'].str.contains(prefix) ]['site'])):\n",
    "                #if 'lga02' in h:\n",
    "                #    continue\n",
    "                ds = ds_sites[ (ds_sites['site'].str.contains(h)) ]\n",
    "                ds = ds.sort_values(by=['ts'])\n",
    "                axes[r][c].plot_date(dates.epoch2num(ds['ts']), 8 * ds['bytes_per_sec'] / 1000000, ls='-', ms=0, label=h)\n",
    "\n",
    "            axes[r][c].set_title(site)\n",
    "            #axes[r][c].set_ylim(0, 150000)\n",
    "            axes[r][c].set_xlim(dates.epoch2num(1498867200), dates.epoch2num(1533081600))\n",
    "            axes[r][c].tick_params(axis='x', labelrotation=90)\n",
    "            axes[r][c].grid(color='#dddddd')\n",
    "            axes[r][c].legend(loc=2, fontsize='x-small', ncol=2)\n",
    "            \n",
    "    for c, site in enumerate(siter):\n",
    "        for r in [0]:\n",
    "            axes[r][c] = plt.subplot2grid((2, cols), (r, c))\n",
    "            if c != 0:\n",
    "                axes[r][c].set_yticklabels([])\n",
    "            else:\n",
    "                axes[r][c].set_ylabel('Mbps')\n",
    "\n",
    "            if r != 1:\n",
    "                axes[r][c].set_xticklabels([])\n",
    "\n",
    "            prefix = 'mlab1.' + site\n",
    "            ds_sites = df_disco_max[ df_disco_max['hostname'].str.contains(prefix) ]\n",
    "            for h in sorted(set(ds_sites[ ds_sites['hostname'].str.contains(prefix) ]['hostname'])):\n",
    "                ds = ds_sites[ (ds_sites['hostname'].str.contains(h)) ]\n",
    "                axes[r][c].plot_date(dates.epoch2num(ds['ts']), ds['bytes_' + rate] * 8 / 10000000, ls='-', ms=0, label=h[6:11] + '-' +  rate)\n",
    "\n",
    "            axes[r][c].set_title(site)\n",
    "            axes[r][c].set_ylim(100, 1000)\n",
    "            axes[r][c].set_xlim(dates.epoch2num(1498867200), dates.epoch2num(1533081600))\n",
    "            axes[r][c].tick_params(axis='x', labelrotation=90)\n",
    "            axes[r][c].grid(color='#dddddd')\n",
    "            axes[r][c].legend(loc=2, fontsize='x-small', ncol=2)\n",
    "\n",
    "fig.suptitle('Daily 98th Percentile Switch Traffic & TCP Connection Counts Per Metro')\n",
    "#fig.tight_layout()\n",
    "#fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([u'mlab1.dfw06', u'mlab1.dfw05', u'mlab1.dfw04', u'mlab1.dfw03', u'mlab1.dfw02', u'mlab1.dfw01'])\n"
     ]
    }
   ],
   "source": [
    "print set(df_disco_max[df_disco_max['hostname'].str.contains('mlab1.dfw')]['hostname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# [ 'lga', nuq'], #  'ord', # MIA is low utilization. 'den', 'sea' low enough.\n",
    "\n",
    "sites = {\n",
    "    1: ['dfw', 'iad', 'lax', 'atl', 'lga', 'yyz'],\n",
    "    7: ['dfw', 'iad', 'lax', 'atl', 'lga', 'yyz'],\n",
    "    9: ['dfw', 'iad', 'lax', 'atl', 'lga', 'yyz'],\n",
    "}\n",
    "\n",
    "cols = len(sites[1])\n",
    "fig = plt.figure(figsize=(4 * cols, 6))\n",
    "axes = [\n",
    "    [None] * cols,\n",
    "    [None] * cols,\n",
    "    [None] * cols,\n",
    "    [None] * cols,\n",
    "]\n",
    "\n",
    "for r, (slice_index, siter) in enumerate(sites.iteritems()):\n",
    "    r += 1\n",
    "    for c, site in enumerate(siter):\n",
    "        if True:\n",
    "            axes[r][c] = plt.subplot2grid((4, cols), (r, c))\n",
    "            if c != 0:\n",
    "                axes[r][c].set_yticklabels([])\n",
    "                pass\n",
    "            else:\n",
    "                axes[r][c].set_ylabel('Daily Average Mbps: slice(%d)' % slice_index)\n",
    "\n",
    "            if r != 3:\n",
    "                axes[r][c].set_xticklabels([])\n",
    "\n",
    "            prefix =  site\n",
    "            ds_sites = df_ss_bytes[ (df_ss_bytes['index'] == slice_index) ]\n",
    "            ds_sites = ds_sites[ ds_sites['site'].str.contains(prefix) ]\n",
    "\n",
    "            for h in sorted(set(ds_sites[ ds_sites['site'].str.contains(prefix) ]['site'])):\n",
    "                #if 'lga02' in h:\n",
    "                #    continue\n",
    "                ds = ds_sites[ (ds_sites['site'].str.contains(h)) ]\n",
    "                ds = ds.sort_values(by=['ts'])\n",
    "                #print ds\n",
    "                axes[r][c].plot_date(dates.epoch2num(ds['ts']), 8 * ds['bytes_per_sec'] / 1000000, ls='-', ms=0, label=h)\n",
    "\n",
    "            axes[r][c].set_title(site)\n",
    "            axes[r][c].set_ylim(0, 250)\n",
    "            #axes[r][c].set_xlim(dates.epoch2num(1498867200), dates.epoch2num(1533081600))\n",
    "            axes[r][c].set_xlim(dates.epoch2num(1527811200), dates.epoch2num(1533081600))\n",
    "            axes[r][c].tick_params(axis='x', labelrotation=90)\n",
    "            axes[r][c].grid(color='#dddddd')\n",
    "            axes[r][c].legend(loc=2, fontsize='x-small', ncol=2)\n",
    "            \n",
    "    for c, site in enumerate(siter):\n",
    "        for r in [0]:\n",
    "            axes[r][c] = plt.subplot2grid((4, cols), (r, c))\n",
    "            if c != 0:\n",
    "                axes[r][c].set_yticklabels([])\n",
    "            else:\n",
    "                axes[r][c].set_ylabel('Mbps')\n",
    "\n",
    "            if r != 1:\n",
    "                axes[r][c].set_xticklabels([])\n",
    "\n",
    "            prefix = 'mlab1.' + site\n",
    "            ds_sites = df_disco_max[ df_disco_max['hostname'].str.contains(prefix) ]\n",
    "            for h in sorted(set(ds_sites[ ds_sites['hostname'].str.contains(prefix) ]['hostname'])):\n",
    "                ds = ds_sites[ (ds_sites['hostname'].str.contains(h)) ]\n",
    "                axes[r][c].plot_date(dates.epoch2num(ds['ts']), ds['bytes_98th'] * 8 / 10000000, ls='-', ms=0, label=h[6:11] + '-' +  rate)\n",
    "\n",
    "            axes[r][c].set_title(site)\n",
    "            axes[r][c].set_ylim(100, 1000)\n",
    "            axes[r][c].set_xlim(dates.epoch2num(1498867200), dates.epoch2num(1533081600))\n",
    "            #axes[r][c].set_xlim(dates.epoch2num(1527811200), dates.epoch2num(1533081600))\n",
    "            axes[r][c].tick_params(axis='x', labelrotation=90)\n",
    "            axes[r][c].grid(color='#dddddd')\n",
    "            axes[r][c].legend(loc=2, fontsize='x-small', ncol=2)\n",
    "\n",
    "fig.suptitle('Daily 98th Percentile Switch Traffic & Daily Avg TCP Download Per Metro')\n",
    "#fig.tight_layout()\n",
    "#fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percent of Timebins with Discards "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0.98,u'Daily percentage of timebins with any discards')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = 'Daily percentage of timebins with any discards'\n",
    "sites = [\n",
    "    ['mlab1.dfw02', 'mlab1.dfw03', 'mlab1.dfw04'],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(sites[0]))\n",
    "for i, hosts in enumerate(sites):\n",
    "    for j, host in enumerate(hosts): \n",
    "        ax = axes[j]\n",
    "        \n",
    "        ds = df_disco[ df_disco['hostname'] == host ]\n",
    "        ax.plot_date(dates.epoch2num(ds['ts']), ds['pct_discards'], ls='-', ms=0, label=host)\n",
    "        \n",
    "        ax.set_title(host)\n",
    "        ax.set_ylim(-0.01, .4)\n",
    "        ax.tick_params(axis='x', labelrotation=90)\n",
    "        ax.grid(color='#dddddd')\n",
    "        ax.legend(loc=4, fontsize='x-small')\n",
    "        \n",
    "        \n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.4)\n",
    "fig.suptitle(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Packets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0.98,u'Daily percentage of timebins with any discards')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = 'Daily percentage of timebins with any discards'\n",
    "sites = [\n",
    "    ['mlab1.dfw02', 'mlab1.dfw03', 'mlab1.dfw04'],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(sites[0]))\n",
    "for i, hosts in enumerate(sites):\n",
    "    for j, host in enumerate(hosts): \n",
    "        ax = axes[j]\n",
    "        \n",
    "        ds = df_disco[ df_disco['hostname'] == host ]\n",
    "        ax.plot_date(dates.epoch2num(ds['ts']), ds['total_packets'], ls='-', ms=0, label=host)\n",
    "        \n",
    "        ax.set_title(host)\n",
    "        #ax.set_ylim(-0.01, .4)\n",
    "        ax.tick_params(axis='x', labelrotation=90)\n",
    "        ax.grid(color='#dddddd')\n",
    "        ax.legend(loc=4, fontsize='x-small')\n",
    "        \n",
    "        \n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.4)\n",
    "fig.suptitle(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Packet Discard Ratios (Switch Loss Rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0.98,u'Switch Packet Loss Rate')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites = [\n",
    "    ['dfw', 'lga', 'iad'],\n",
    "    ['sea', 'atl', 'den'],\n",
    "    ['mia', 'nuq', 'ord'],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(12, 10))\n",
    "for i, site_row in enumerate(sites):\n",
    "    for j, site in enumerate(site_row):\n",
    "        axes[i, j].set_title(site)\n",
    "        if j != 0:\n",
    "            axes[i, j].set_yticklabels([])\n",
    "        if i != len(sites)-1:\n",
    "            axes[i, j].set_xticklabels([])\n",
    "        if j == 0:\n",
    "            axes[i, j].set_ylabel('Daily Loss Ratio')\n",
    "\n",
    "        for h in set(df_disco['hostname']):\n",
    "            if 'mlab1.' + site in h:\n",
    "                ds = df_disco[ (df_disco['hostname'] == h) &\n",
    "                               (df_disco['total_discards'] > 100) &\n",
    "                               (df_disco['total_discards'] < 1000000) ]\n",
    "                ratio = ds['total_discards'] / ds['total_packets']\n",
    "                axes[i, j].plot_date(dates.epoch2num(ds['ts']), ratio, ls='-', ms=0, label=h[:11])\n",
    "        axes[i, j].set_ylim(10**-6, 10**-3)\n",
    "        axes[i, j].tick_params(axis='x', labelrotation=90)\n",
    "        axes[i, j].grid(color='#dddddd')\n",
    "        axes[i, j].legend(loc=4, fontsize='x-small')\n",
    "        axes[i, j].semilogy()\n",
    "        \n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.4)\n",
    "fig.suptitle('Switch Packet Loss Rate')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
