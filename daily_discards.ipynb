{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "# Enables figures loading outside of browser.\n",
    "# If not run, figures will load inline.\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "import datetime\n",
    "\n",
    "# Some matplotlib features are version dependent.\n",
    "assert(matplotlib.__version__ >= '2.1.2')\n",
    "\n",
    "# Depends on: pip install --upgrade google-cloud-bigquery\n",
    "import query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unlog(x, pos):\n",
    "    return '%.2f' % math.pow(10, x)\n",
    "\n",
    "customFormatter = matplotlib.ticker.FuncFormatter(unlog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = query.sync_query(\"\"\"\n",
    "#standardSQL\n",
    "SELECT\n",
    "  name AS hostname,\n",
    "  FORMAT_TIMESTAMP(\"%Y-%m-%d\", TIMESTAMP_TRUNC(sts, DAY)) AS day,\n",
    "  UNIX_SECONDS(TIMESTAMP_TRUNC(sts, DAY)) AS ts,\n",
    "  SUM(IF(metric = 'switch.discards.uplink.tx', value, 0)) AS total_discards,\n",
    "  SUM(IF(metric = 'switch.unicast.uplink.tx', value, 0)) AS total_packets,\n",
    "  COUNTIF(metric = 'switch.discards.uplink.tx' AND value > 0) / 8640 AS pct_discards\n",
    "\n",
    "FROM (\n",
    "  SELECT\n",
    "    metric,\n",
    "    REGEXP_EXTRACT(hostname, r'(mlab[1-4].[a-z]{3}[0-9]{2}).*') AS name,\n",
    "    sample.timestamp AS sts,\n",
    "    sample.value AS value\n",
    "  FROM\n",
    "    `mlab-sandbox.base_tables.switch*`,\n",
    "    UNNEST(sample) AS sample\n",
    "  WHERE\n",
    "    metric LIKE 'switch.discards.uplink.tx' OR metric LIKE 'switch.unicast.uplink.tx'\n",
    "  GROUP BY\n",
    "    hostname, metric, sts, value\n",
    ")\n",
    "WHERE\n",
    "  name IS NOT NULL\n",
    "GROUP BY\n",
    "  hostname, day, ts\n",
    "ORDER BY\n",
    "  hostname, day, ts\n",
    "\"\"\")\n",
    "\n",
    "df_disco = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discards over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0.98,u'Discards over time')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites = [\n",
    "    ['dfw', 'lga', 'iad'],\n",
    "    ['sea', 'atl', 'den'],\n",
    "    ['mia', 'nuq', 'ord'],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(12, 10))\n",
    "for i, site_row in enumerate(sites):\n",
    "    for j, site in enumerate(site_row):\n",
    "        if j != 0:\n",
    "            axes[i, j].set_yticklabels([])\n",
    "        if i != len(sites)-1:\n",
    "            axes[i, j].set_xticklabels([])\n",
    "        for h in set(df_disco['hostname']):\n",
    "            if ('mlab1.' + site) in h:\n",
    "                ds = df_disco[ (df_disco['hostname'] == h) & (df_disco['total_discards'] > 100)& (df_disco['total_discards'] < 1000000)]\n",
    "                axes[i, j].plot_date(dates.epoch2num(ds['ts']), ds['total_discards'], ls='-', ms=0, label=h[6:11])\n",
    "\n",
    "        axes[i, j].set_title(site)\n",
    "        axes[i, j].set_ylim(100, 1000000)\n",
    "        axes[i, j].tick_params(axis='x', labelrotation=90)\n",
    "        axes[i, j].grid(color='#dddddd')\n",
    "        axes[i, j].legend(loc=4, fontsize='x-small')\n",
    "        axes[i, j].semilogy()\n",
    "        \n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.4)\n",
    "fig.suptitle('Discards over time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percent of Timebins with Discards "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0.98,u'Daily percentage of timebins with any discards')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = 'Daily percentage of timebins with any discards'\n",
    "sites = [\n",
    "    ['mlab1.dfw02', 'mlab1.dfw03', 'mlab1.dfw04'],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(sites[0]))\n",
    "for i, hosts in enumerate(sites):\n",
    "    for j, host in enumerate(hosts): \n",
    "        ax = axes[j]\n",
    "        \n",
    "        ds = df_disco[ df_disco['hostname'] == host ]\n",
    "        ax.plot_date(dates.epoch2num(ds['ts']), ds['pct_discards'], ls='-', ms=0, label=host)\n",
    "        \n",
    "        ax.set_title(host)\n",
    "        ax.set_ylim(-0.01, .4)\n",
    "        ax.tick_params(axis='x', labelrotation=90)\n",
    "        ax.grid(color='#dddddd')\n",
    "        ax.legend(loc=4, fontsize='x-small')\n",
    "        \n",
    "        \n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.4)\n",
    "fig.suptitle(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Packet Discard Ratios (Switch Loss Rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0.98,'Switch Packet Loss Rate')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites = [\n",
    "    ['dfw', 'lga', 'iad'],\n",
    "    ['sea', 'atl', 'den'],\n",
    "    ['mia', 'nuq', 'ord'],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(12, 10))\n",
    "for i, site_row in enumerate(sites):\n",
    "    for j, site in enumerate(site_row):\n",
    "        axes[i, j].set_title(site)\n",
    "        if j != 0:\n",
    "            axes[i, j].set_yticklabels([])\n",
    "        if i != len(sites)-1:\n",
    "            axes[i, j].set_xticklabels([])\n",
    "        if j == 0:\n",
    "            axes[i, j].set_ylabel('Percent Loss')\n",
    "\n",
    "        for h in set(df_disco['hostname']):\n",
    "            if 'mlab1.' + site in h:\n",
    "                #ds = df_disco[ df_disco['hostname'] == h]\n",
    "                ds = df_disco[ (df_disco['hostname'] == h) &\n",
    "                               (df_disco['total_discards'] > 100) &\n",
    "                               (df_disco['total_discards'] < 1000000) ]\n",
    "                ratio = 100 * ds['total_discards'] / ds['total_packets']\n",
    "                axes[i, j].plot_date(dates.epoch2num(ds['ts']), ratio, ls='-', ms=0, label=h[:11])\n",
    "        axes[i, j].set_ylim(10**-4, 10**-1)\n",
    "        axes[i, j].tick_params(axis='x', labelrotation=90)\n",
    "        axes[i, j].grid(color='#dddddd')\n",
    "        axes[i, j].legend(loc=4, fontsize='x-small')\n",
    "        axes[i, j].semilogy()\n",
    "        \n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.4)\n",
    "fig.suptitle('Switch Packet Loss Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Flow-Control Trial (measurement-lab.public)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cat sidestream.sql | bq query --format=csv --max_rows=1000000 --nouse_legacy_sql > sidestream-trial-6w.csv\n",
    "#df = pd.read_csv('sidestream-trial-6w.csv')\n",
    "\n",
    "result = query.sync_query(\"\"\"\n",
    "#standardSQL                                                                    \n",
    "    -- Only works for mlab1 addresses. May not work on all machines.\n",
    "CREATE TEMPORARY FUNCTION sliceFromIP(ipaddr STRING)\n",
    "    AS ( MOD(CAST(REGEXP_EXTRACT(ipaddr, r'[:.]([0-9]+)$') AS INT64), 64) - 10 );\n",
    "\n",
    "CREATE TEMPORARY FUNCTION betweenTimes(ts INT64, starttime STRING, endtime STRING)\n",
    "    AS ( TIMESTAMP_SECONDS(ts) >= TIMESTAMP(starttime) AND TIMESTAMP_SECONDS(ts) <= TIMESTAMP(endtime) );\n",
    "\n",
    "SELECT\n",
    "    CASE \n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 1 THEN 'ndt'\n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7 THEN 'samknows'\n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 9 THEN 'neubot'\n",
    "        ELSE 'other' \n",
    "    END AS slice,\n",
    "    CASE\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-01-26 00:00:00\", \"2018-01-27 00:00:00\") THEN '5w'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-02 00:00:00\", \"2018-02-03 00:00:00\") THEN '4w'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-09 00:00:00\", \"2018-02-10 00:00:00\") THEN '3w'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-16 00:00:00\", \"2018-02-17 00:00:00\") THEN '2w'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-23 00:00:00\", \"2018-02-24 00:00:00\") THEN '1w'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-03-02 00:00:00\", \"2018-03-03 00:00:00\") THEN '0w'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-03-09 00:00:00\", \"2018-03-10 00:00:00\") THEN '+1w'\n",
    "    ELSE 'unknown'                                                                    \n",
    "    END AS period,\n",
    "    REGEXP_EXTRACT(test_id, r\"\\d\\d\\d\\d/\\d\\d/\\d\\d/(mlab[1-4].[a-z]{3}[0-9]{2})\") AS hostname,\n",
    "    web100_log_entry.snap.StartTimeStamp AS ts,                                   \n",
    "    8 * (web100_log_entry.snap.HCThruOctetsAcked /                                \n",
    "      (web100_log_entry.snap.SndLimTimeRwin +                                     \n",
    "       web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "       web100_log_entry.snap.SndLimTimeSnd)) as rate_mbps   \n",
    "FROM\n",
    "    `measurement-lab.public.sidestream`\n",
    "\n",
    "WHERE\n",
    "        (  betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-01-26 00:00:00\", \"2018-01-27 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-02 00:00:00\", \"2018-02-03 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-09 00:00:00\", \"2018-02-10 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-16 00:00:00\", \"2018-02-17 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-23 00:00:00\", \"2018-02-24 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-03-02 00:00:00\", \"2018-03-03 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-03-09 00:00:00\", \"2018-03-10 00:00:00\")\n",
    "        )\n",
    "  AND REGEXP_CONTAINS(test_id, r\"mlab1.(dfw\\d\\d)\")\n",
    "  AND web100_log_entry.snap.HCThruOctetsAcked >= 1000000 -- 819200                          \n",
    "  AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "    web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "    web100_log_entry.snap.SndLimTimeSnd) >= 9000000                             \n",
    "  AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "    web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "    web100_log_entry.snap.SndLimTimeSnd) < 600000000                            \n",
    "  AND (web100_log_entry.snap.State = 1 OR                                       \n",
    "    (web100_log_entry.snap.State >= 5 AND                                       \n",
    "    web100_log_entry.snap.State <= 11))\n",
    "    \n",
    "GROUP BY\n",
    "  hostname, slice, period, ts, rate_mbps\n",
    "\"\"\")\n",
    "df_ss = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "730671 1303.9458692 854\n",
      "94\n"
     ]
    }
   ],
   "source": [
    "print len(df_ss), max(df_ss['rate_mbps']), int(math.sqrt(len(df_ss['rate_mbps'])))\n",
    "\n",
    "hosts = [\n",
    "    ['mlab1.lga03', 'mlab1.lga04'],\n",
    "    ['mlab1.lga05', 'mlab1.lga06'],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "for i, host_row in enumerate(hosts):\n",
    "    for j, host in enumerate(host_row):\n",
    "        for period in ['+1w', '0w', '1w', '2w', '3w']: #, '4w', '5w']:\n",
    "            ds = df_ss[ (df_ss['period'] == period) & (df_ss['hostname'] == host) & (df_ss['slice'] == 'ndt') ]\n",
    "            label = 'pdf-%s (%d)' % (period, len(ds['rate_mbps']))\n",
    "            if len(ds) == 0:\n",
    "                continue\n",
    "            r = [math.log10(x) for x in ds['rate_mbps']]\n",
    "            n, bins, patches = axes[i, j].hist(r, int(math.sqrt(len(ds['rate_mbps']))),\n",
    "                                       histtype='step', normed=1, label=label, ls='-')\n",
    "#            n, bins, patches = axes[i, j].hist(ds['rate_mbps'], int(math.sqrt(len(ds['rate_mbps']))),\n",
    "#                               histtype='step', label=label, ls='-')\n",
    "#            n, bins, patches = axes[i, j].hist(ds['rate_mbps'], len(ds['rate_mbps']),\n",
    "#                               histtype='step', normed=1, cumulative=True, label='cdf-' + period,\n",
    "#                               ls='-')\n",
    "\n",
    "        axes[i, j].set_xlim(math.log10(0.1), math.log10(1000))\n",
    "        axes[i, j].set_axisbelow(True)\n",
    "        axes[i, j].legend(loc=2)\n",
    "        axes[i, j].grid(color='#dddddd')\n",
    "        axes[i, j].set_title(host)\n",
    "        axes[i, j].xaxis.set_major_formatter(customFormatter)\n",
    "\n",
    "fig.suptitle('Sidestream Download Rate PDFs over three week period (0w is trial)')\n",
    "plt.show()\n",
    "print len(bins)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Historical (mlab-sandbox.batch) - Sidestream by Period & Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Variations, for each period:\n",
    "# * all sidestream connections from each period.\n",
    "# * all sidestream connections from each period and slice\n",
    "# * all sidestream connections from each period and slice and from same cohort.\n",
    "# * some sidestream connections from each period and slice and from same cohort, grouped by ts & remote_ip.\n",
    "# * some sidestream connections from each period and slice and from same cohort, grouped by only by remote_ip.\n",
    "\n",
    "result = query.sync_query(\n",
    "    \"\"\"#standardSQL                                                                    \n",
    "    -- Only works for mlab1 addresses. May not work on all machines.\n",
    "CREATE TEMPORARY FUNCTION sliceFromIP(ipaddr STRING)\n",
    "    AS ( MOD(CAST(REGEXP_EXTRACT(ipaddr, r'[:.]([0-9]+)$') AS INT64), 64) - 10 );\n",
    "\n",
    "CREATE TEMPORARY FUNCTION betweenTimes(ts INT64, starttime STRING, endtime STRING)\n",
    "    AS ( TIMESTAMP_SECONDS(ts) >= TIMESTAMP(starttime) AND TIMESTAMP_SECONDS(ts) <= TIMESTAMP(endtime) );\n",
    "\n",
    "SELECT\n",
    "    CASE \n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 1 THEN 'ndt'\n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7 THEN 'samknows'\n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7 THEN 'neubot'\n",
    "        ELSE 'other' \n",
    "    END AS slice,\n",
    "    CASE                                                                          \n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2017-07-26 00:00:00\", \"2017-07-30 00:00:00\") THEN '07-26 to 29'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2017-08-12 00:00:00\", \"2017-08-16 00:00:00\") THEN '08-12 to 16'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2017-10-30 00:00:00\", \"2017-11-02 00:00:00\") THEN '10-30 to 11-02'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2017-11-26 00:00:00\", \"2017-12-01 00:00:00\") THEN '11-29 to 12-03'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-21 00:00:00\", \"2018-02-25 00:00:00\") THEN '02-21 to 25'\n",
    "    ELSE 'bad'                                                                    \n",
    "    END AS period,\n",
    "    REGEXP_EXTRACT(test_id, r\"\\d\\d\\d\\d/\\d\\d/\\d\\d/(mlab[1-4].[a-z]{3}[0-9]{2})\") AS hostname,\n",
    "    web100_log_entry.snap.StartTimeStamp AS ts,                                   \n",
    "    8 * (web100_log_entry.snap.HCThruOctetsAcked /                                \n",
    "      (web100_log_entry.snap.SndLimTimeRwin +                                     \n",
    "       web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "       web100_log_entry.snap.SndLimTimeSnd)) as rate_mbps   \n",
    "FROM\n",
    "    `mlab-sandbox.batch.sidestream*`                                              \n",
    "WHERE\n",
    "        (  betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2017-07-26 00:00:00\", \"2017-07-30 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2017-08-12 00:00:00\", \"2017-08-16 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2017-11-26 00:00:00\", \"2017-12-01 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-21 00:00:00\", \"2018-02-25 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2017-10-30 00:00:00\", \"2017-11-02 00:00:00\") )\n",
    "  AND (test_id LIKE '%mlab1.dfw%')            \n",
    "  AND web100_log_entry.snap.HCThruOctetsAcked >= 1000000 -- 819200                          \n",
    "  AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "    web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "    web100_log_entry.snap.SndLimTimeSnd) >= 9000000                             \n",
    "  AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "    web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "    web100_log_entry.snap.SndLimTimeSnd) < 600000000                            \n",
    "  AND (web100_log_entry.snap.State = 1 OR                                       \n",
    "    (web100_log_entry.snap.State >= 5 AND                                       \n",
    "    web100_log_entry.snap.State <= 11))\n",
    "  AND web100_log_entry.connection_spec.remote_ip IN(\n",
    "    (SELECT\n",
    "     remote_ip\n",
    "    FROM (\n",
    "      SELECT\n",
    "         web100_log_entry.connection_spec.remote_ip as remote_ip,\n",
    "         count(*) as c1\n",
    "      FROM\n",
    "         `mlab-sandbox.batch.sidestream*`\n",
    "      WHERE\n",
    "          (test_id LIKE '%mlab1.dfw0%')\n",
    "        AND TIMESTAMP_SECONDS(web100_log_entry.log_time) >= TIMESTAMP(\"2017-08-12 00:00:00\")\n",
    "        AND TIMESTAMP_SECONDS(web100_log_entry.log_time) < TIMESTAMP(\"2017-08-16 00:00:00\")\n",
    "        AND sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7\n",
    "      GROUP BY\n",
    "        remote_ip\n",
    "      HAVING c1 > 10\n",
    "    ) INNER JOIN (\n",
    "      SELECT\n",
    "         web100_log_entry.connection_spec.remote_ip as remote_ip,\n",
    "         count(*) as c2\n",
    "      FROM\n",
    "         `mlab-sandbox.batch.sidestream*`\n",
    "      WHERE\n",
    "          (test_id LIKE '%mlab1.dfw0%')\n",
    "        AND TIMESTAMP_SECONDS(web100_log_entry.log_time) >= TIMESTAMP(\"2017-11-26 00:00:00\")\n",
    "        AND TIMESTAMP_SECONDS(web100_log_entry.log_time) < TIMESTAMP(\"2017-11-30 00:00:00\")\n",
    "        AND sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7\n",
    "      GROUP BY\n",
    "        remote_ip\n",
    "      HAVING c2 > 10\n",
    "    ) USING (remote_ip))\n",
    "  )\n",
    "    \n",
    "GROUP BY\n",
    "  hostname, slice, period, ts, rate_mbps\n",
    "    \"\"\")\n",
    "df_ss = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = query.sync_query(\n",
    "    \"\"\"#standardSQL                                                                    \n",
    "\n",
    "SELECT\n",
    "   hostname, ts, count(*) as count\n",
    "FROM (\n",
    "    SELECT\n",
    "        REGEXP_EXTRACT(test_id, r\"\\d\\d\\d\\d/\\d\\d/\\d\\d/(mlab[1-4].[a-z]{3}[0-9]{2})\") AS hostname,\n",
    "        UNIX_SECONDS(TIMESTAMP_TRUNC(log_time, DAY)) AS ts                            \n",
    "    FROM\n",
    "        `mlab-sandbox.batch.sidestream*`                                              \n",
    "    WHERE\n",
    "     (test_id LIKE '%mlab1.dfw%')            \n",
    "      AND web100_log_entry.snap.HCThruOctetsAcked >= 1000000 -- 819200                          \n",
    "      AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "        web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "        web100_log_entry.snap.SndLimTimeSnd) >= 9000000                             \n",
    "      AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "        web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "        web100_log_entry.snap.SndLimTimeSnd) < 600000000                            \n",
    "      AND (web100_log_entry.snap.State = 1 OR                                       \n",
    "        (web100_log_entry.snap.State >= 5 AND                                       \n",
    "        web100_log_entry.snap.State <= 11))\n",
    "\n",
    "    GROUP BY\n",
    "      hostname, ts, web100_log_entry.connection_spec.remote_ip, web100_log_entry.connection_spec.remote_port, web100_log_entry.connection_spec.local_af, web100_log_entry.connection_spec.local_ip\n",
    ")\n",
    "\n",
    "GROUP BY\n",
    "  hostname, ts\n",
    "ORDER BY\n",
    "  hostname, ts\n",
    "    \"\"\")\n",
    "df_ss_count = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosts = [\n",
    "    ['mlab1.dfw02', 'mlab1.dfw03', 'mlab1.dfw04', 'mlab1.dfw05'],\n",
    "    #['mlab1.dfw02', 'mlab1.dfw04', 'mlab1.dfw05'],\n",
    "]\n",
    "\n",
    "periods_list = [\n",
    "    (datetime.datetime(2017,  8, 16), datetime.datetime(2017,  8, 23)),\n",
    "    (datetime.datetime(2017,  8, 23), datetime.datetime(2017,  8, 28)),\n",
    "    (datetime.datetime(2017,  8, 28), datetime.datetime(2017, 11, 22)),\n",
    "    (datetime.datetime(2017, 11, 22), datetime.datetime(2018,  2, 21)),\n",
    "    (datetime.datetime(2018,  2, 21), datetime.datetime(2018,  3,  7)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved (datetime.datetime(2017, 8, 16, 0, 0), datetime.datetime(2017, 8, 23, 0, 0)) mlab1.dfw02 586\n",
      "saved (datetime.datetime(2017, 8, 16, 0, 0), datetime.datetime(2017, 8, 23, 0, 0)) mlab1.dfw03 204\n",
      "saved (datetime.datetime(2017, 8, 16, 0, 0), datetime.datetime(2017, 8, 23, 0, 0)) mlab1.dfw04 257\n",
      "saved (datetime.datetime(2017, 8, 16, 0, 0), datetime.datetime(2017, 8, 23, 0, 0)) mlab1.dfw05 685\n",
      "saved (datetime.datetime(2017, 8, 23, 0, 0), datetime.datetime(2017, 8, 28, 0, 0)) mlab1.dfw02 819\n",
      "saved (datetime.datetime(2017, 8, 23, 0, 0), datetime.datetime(2017, 8, 28, 0, 0)) mlab1.dfw03 189\n",
      "saved (datetime.datetime(2017, 8, 23, 0, 0), datetime.datetime(2017, 8, 28, 0, 0)) mlab1.dfw04 227\n",
      "saved (datetime.datetime(2017, 8, 23, 0, 0), datetime.datetime(2017, 8, 28, 0, 0)) mlab1.dfw05 754\n",
      "saved (datetime.datetime(2017, 8, 28, 0, 0), datetime.datetime(2017, 11, 22, 0, 0)) mlab1.dfw02 529\n",
      "saved (datetime.datetime(2017, 8, 28, 0, 0), datetime.datetime(2017, 11, 22, 0, 0)) mlab1.dfw03 101\n",
      "saved (datetime.datetime(2017, 8, 28, 0, 0), datetime.datetime(2017, 11, 22, 0, 0)) mlab1.dfw04 165\n",
      "saved (datetime.datetime(2017, 8, 28, 0, 0), datetime.datetime(2017, 11, 22, 0, 0)) mlab1.dfw05 404\n",
      "saved (datetime.datetime(2017, 11, 22, 0, 0), datetime.datetime(2018, 2, 21, 0, 0)) mlab1.dfw02 1596\n",
      "saved (datetime.datetime(2017, 11, 22, 0, 0), datetime.datetime(2018, 2, 21, 0, 0)) mlab1.dfw03 565\n",
      "saved (datetime.datetime(2017, 11, 22, 0, 0), datetime.datetime(2018, 2, 21, 0, 0)) mlab1.dfw04 799\n",
      "saved (datetime.datetime(2017, 11, 22, 0, 0), datetime.datetime(2018, 2, 21, 0, 0)) mlab1.dfw05 709\n",
      "saved (datetime.datetime(2018, 2, 21, 0, 0), datetime.datetime(2018, 3, 7, 0, 0)) mlab1.dfw02 3489\n",
      "saved (datetime.datetime(2018, 2, 21, 0, 0), datetime.datetime(2018, 3, 7, 0, 0)) mlab1.dfw03 1760\n",
      "saved (datetime.datetime(2018, 2, 21, 0, 0), datetime.datetime(2018, 3, 7, 0, 0)) mlab1.dfw04 1942\n",
      "saved (datetime.datetime(2018, 2, 21, 0, 0), datetime.datetime(2018, 3, 7, 0, 0)) mlab1.dfw05 2152\n"
     ]
    }
   ],
   "source": [
    "def start_and_end(d):\n",
    "    s = d.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    e = (d + datetime.timedelta(days=4)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    return s, e\n",
    "\n",
    "df_hosts = []\n",
    "for i, periods in enumerate(periods_list):\n",
    "    a_s, a_e = start_and_end(periods[0])\n",
    "    b_s, b_e = start_and_end(periods[1])\n",
    "    df_hosts.append({})\n",
    "    #if i not in [2]:\n",
    "    #    print 'skipping', periods_list[i]\n",
    "    #    continue\n",
    "    for host in hosts[0]:\n",
    "        result = query.sync_query(\"\"\"\n",
    "#standardSQL                                                                    \n",
    "    -- Only works for mlab1 addresses. May not work on all machines.\n",
    "CREATE TEMPORARY FUNCTION sliceFromIP(ipaddr STRING)\n",
    "    AS ( MOD(CAST(REGEXP_EXTRACT(ipaddr, r'[:.]([0-9]+)$') AS INT64), 64) - 10 );\n",
    "\n",
    "CREATE TEMPORARY FUNCTION betweenTimes(ts INT64, starttime STRING, endtime STRING)\n",
    "    AS ( TIMESTAMP_SECONDS(ts) >= TIMESTAMP(starttime) AND TIMESTAMP_SECONDS(ts) <= TIMESTAMP(endtime) );\n",
    "\n",
    "SELECT\n",
    "   slice,\n",
    "   period,\n",
    "   hostname,\n",
    "   AVG(rate_mbps) as rate_mbps,\n",
    "   APPROX_QUANTILES(rate_mbps, 101)[ORDINAL(50)] as med_rate_mbps,\n",
    "   MAX(rate_mbps) as max_rate_mbps,\n",
    "   SUM(rate_mbps) as sum_rate_mbps\n",
    "    \n",
    "FROM (\n",
    "\n",
    "SELECT\n",
    "    web100_log_entry.connection_spec.remote_ip as remote_ip,\n",
    "    CASE \n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 1 THEN 'ndt'\n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7 THEN 'samknows'\n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7 THEN 'neubot'\n",
    "        ELSE 'other' \n",
    "    END AS slice,\n",
    "    CASE                                                                          \n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, '\"\"\"+a_s+\"\"\"', '\"\"\"+a_e+\"\"\"')\n",
    "            THEN '\"\"\"+a_s+\"\"\"'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, '\"\"\"+b_s+\"\"\"', '\"\"\"+b_e+\"\"\"')\n",
    "            THEN '\"\"\"+b_s+\"\"\"'\n",
    "    ELSE 'bad'                                                                    \n",
    "    END AS period,\n",
    "    REGEXP_EXTRACT(test_id, r\"\\d\\d\\d\\d/\\d\\d/\\d\\d/(mlab[1-4].[a-z]{3}[0-9]{2})\") AS hostname,\n",
    "    web100_log_entry.snap.StartTimeStamp AS ts,                                   \n",
    "    8 * (web100_log_entry.snap.HCThruOctetsAcked /                                \n",
    "      (web100_log_entry.snap.SndLimTimeRwin +                                     \n",
    "       web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "       web100_log_entry.snap.SndLimTimeSnd)) as rate_mbps   \n",
    "FROM\n",
    "    `mlab-sandbox.batch.sidestream*`                                              \n",
    "WHERE\n",
    "        (  betweenTimes(web100_log_entry.snap.StartTimeStamp, '\"\"\"+a_s+\"\"\"', '\"\"\"+a_e+\"\"\"')\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, '\"\"\"+b_s+\"\"\"', '\"\"\"+b_e+\"\"\"')\n",
    "        )\n",
    "  AND (test_id LIKE '%\"\"\"+host+\"\"\"%')            \n",
    "  AND web100_log_entry.snap.HCThruOctetsAcked >= 1000000 -- 819200                          \n",
    "  AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "    web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "    web100_log_entry.snap.SndLimTimeSnd) >= 9000000                             \n",
    "  AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "    web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "    web100_log_entry.snap.SndLimTimeSnd) < 600000000                            \n",
    "  AND (web100_log_entry.snap.State = 1 OR                                       \n",
    "    (web100_log_entry.snap.State >= 5 AND                                       \n",
    "    web100_log_entry.snap.State <= 11))\n",
    "  AND web100_log_entry.connection_spec.remote_ip IN(\n",
    "    (SELECT\n",
    "     remote_ip\n",
    "    FROM (\n",
    "      SELECT\n",
    "         web100_log_entry.connection_spec.remote_ip as remote_ip,\n",
    "         count(*) as c1\n",
    "      FROM\n",
    "         `mlab-sandbox.batch.sidestream*`\n",
    "      WHERE\n",
    "          (test_id LIKE '%\"\"\"+host+\"\"\"%')\n",
    "        AND betweenTimes(web100_log_entry.snap.StartTimeStamp, '\"\"\"+a_s+\"\"\"', '\"\"\"+a_e+\"\"\"')\n",
    "        AND sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7\n",
    "      GROUP BY\n",
    "        remote_ip\n",
    "      HAVING c1 > 10\n",
    "    ) INNER JOIN (\n",
    "      SELECT\n",
    "         web100_log_entry.connection_spec.remote_ip as remote_ip,\n",
    "         count(*) as c2\n",
    "      FROM\n",
    "         `mlab-sandbox.batch.sidestream*`\n",
    "      WHERE\n",
    "          (test_id LIKE '%\"\"\"+host+\"\"\"%')\n",
    "        AND betweenTimes(web100_log_entry.snap.StartTimeStamp, '\"\"\"+b_s+\"\"\"', '\"\"\"+b_e+\"\"\"')\n",
    "        AND sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7\n",
    "      GROUP BY\n",
    "        remote_ip\n",
    "      HAVING c2 > 10\n",
    "    ) USING (remote_ip))\n",
    "  )\n",
    "    \n",
    "GROUP BY\n",
    "  hostname, slice, period, ts, web100_log_entry.connection_spec.remote_ip, rate_mbps\n",
    ")\n",
    "\n",
    "GROUP BY\n",
    "  hostname, slice, period,   remote_ip -- CAST(ts/4 AS INT64),\n",
    "\"\"\")\n",
    "        df_hosts[i][host] = pd.DataFrame(result)\n",
    "        print 'saved', periods_list[i], host, len(df_hosts[i][host])\n",
    "#df_ss = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sidestream CDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10079 507.5426899233347\n"
     ]
    }
   ],
   "source": [
    "title = 'CDF - per-slice sidestream Download Rate CDFs'\n",
    "print len(df_ss), max(df_ss['rate_mbps']) # 'sqrt', int(math.sqrt(len(df['rate_mbps'])))\n",
    "\n",
    "hosts = [\n",
    "    ['mlab1.dfw02', 'mlab1.dfw03', 'mlab1.dfw04'],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=len(hosts[0]), figsize=(13, 10))\n",
    "\n",
    "for i, host_row in enumerate(hosts):\n",
    "    for j, host in enumerate(host_row):\n",
    "        if len(df_ss[ df_ss['hostname'] == host ]) == 0:\n",
    "            print 'skipping', host\n",
    "            continue\n",
    "        for period in ['08-12 to 16', '11-29 to 12-03', '02-21 to 25']: #set(df['period']):\n",
    "            ds = df_ss[ (df_ss['period'] == period) & (df_ss['hostname'] == host) ]\n",
    "            for k, slicename in enumerate(['ndt', 'samknows']): # set(ds['slice']):\n",
    "                #print 'sqrt', int(math.sqrt(len(ds['rate_mbps'])))\n",
    "                d = ds[ ds['slice'] == slicename ]\n",
    "                if len(d) == 0:\n",
    "                    continue\n",
    "                ax = axes[k, j]\n",
    "                #n, bins, patches = ax.hist(ds['rate_mbps'], len(ds['rate_mbps']),\n",
    "                #                   histtype='step', normed=1, cumulative=True, label='cdf-' + period,\n",
    "                #                   ls='-')\n",
    "                r = [math.log10(x) for x in d['rate_mbps']]\n",
    "                n, bins, patches = ax.hist(d['rate_mbps'], int(math.sqrt(len(d['rate_mbps']))),\n",
    "                                   histtype='step', normed=1, cumulative=True, label=('cdf-' + period + '-' + slicename), \n",
    "                                   ls='-')\n",
    "\n",
    "                ax.set_xlim(1, 200)       \n",
    "                ax.set_axisbelow(True)\n",
    "        #ax.semilogx()\n",
    "                ax.legend(loc=4, fontsize='x-small')\n",
    "\n",
    "                ax.grid(color='#dddddd')\n",
    "                ax.set_title(host)\n",
    "        #labels = ['%.2f' % math.pow(10, float(l)) for l in ax.get_xticks()]\n",
    "        #ax.xaxis.set_major_formatter(customFormatter)\n",
    "        \n",
    "\n",
    "fig.suptitle(title)\n",
    "\n",
    "plt.show()\n",
    "#print n, len(bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sidestream PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10079 507.5426899233347\n"
     ]
    }
   ],
   "source": [
    "title = 'PDF - per-slice sidestream Download Rate PDFs'\n",
    "print len(df_ss), max(df_ss['rate_mbps']) # 'sqrt', int(math.sqrt(len(df['rate_mbps'])))\n",
    "\n",
    "hosts = [\n",
    "    ['mlab1.dfw02', 'mlab1.dfw03', 'mlab1.dfw04'],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=len(hosts[0]), figsize=(13, 10))\n",
    "for i, host_row in enumerate(hosts):\n",
    "    for j, host in enumerate(host_row):\n",
    "        if len(df_ss[ df_ss['hostname'] == host ]) == 0:\n",
    "            print 'skipping', host\n",
    "            continue\n",
    "        for period in ['08-12 to 16', '02-21 to 25']: # '11-29 to 12-03',  #set(df['period']):\n",
    "            ds = df_ss[ (df_ss['period'] == period) & (df_ss['hostname'] == host) ]\n",
    "            for k, slicename in enumerate(['ndt', 'samknows']): # set(ds['slice']):\n",
    "                #print 'sqrt', int(math.sqrt(len(ds['rate_mbps'])))\n",
    "                d = ds[ ds['slice'] == slicename ]\n",
    "                if len(d) == 0:\n",
    "                    continue\n",
    "                ax = axes[k, j]\n",
    "\n",
    "                label = 'pdf-%s-%s (%d)' % (period, slicename, len(d['rate_mbps']))\n",
    "                r = [math.log10(x) for x in d['rate_mbps']]\n",
    "                n, bins, patches = ax.hist(r, int(math.sqrt(len(d['rate_mbps']))),\n",
    "                                   histtype='step', normed=1, label=label, \n",
    "                                   ls='-')\n",
    "\n",
    "                #ax.set_xlim(1, 200)       \n",
    "                #ax.semilogx()\n",
    "                #ax.set_ylim(0, 1.4)\n",
    "                ax.set_axisbelow(True)\n",
    "                ax.legend(loc=2, fontsize='x-small')\n",
    "\n",
    "                ax.grid(color='#dddddd')\n",
    "                ax.set_title(host)\n",
    "                ax.xaxis.set_major_formatter(customFormatter)\n",
    "        \n",
    "fig.suptitle(title)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF, CDF, & Switch - by Site and Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last\n",
      "last\n",
      "last\n",
      "last\n"
     ]
    }
   ],
   "source": [
    "title = 'PDF, CDF, Switch - slice sidestream Download Rates'\n",
    "#print len(df_ss), max(df_ss['rate_mbps']) # 'sqrt', int(math.sqrt(len(df['rate_mbps'])))\n",
    "\n",
    "d = None\n",
    "df=None\n",
    "label2date = {}\n",
    "slices = ['samknows', 'ndt']\n",
    "slices = ['samknows']\n",
    "colors = plt.cm.Dark2.colors\n",
    "colors = plt.cm.tab10.colors\n",
    "p2c = {}\n",
    "c=0\n",
    "for i, host_row in enumerate(hosts):\n",
    "    for j, host in enumerate(host_row):\n",
    "        #fig, axes = plt.subplots(nrows=3, ncols=len(periods_list), figsize=(16, 10))\n",
    "        fig = plt.figure(figsize=(16, 10))\n",
    "        axes = [\n",
    "            [None] * 5,\n",
    "            [None] * 5,\n",
    "            None,\n",
    "        ]\n",
    "        \n",
    "        for p, times in enumerate(periods_list):\n",
    "            axes[0][p] = plt.subplot2grid((3, 5), (0, p))\n",
    "            axes[1][p] = plt.subplot2grid((3, 5), (1, p))\n",
    "\n",
    "            for k, slicename in enumerate(slices):\n",
    "                \n",
    "                df_ss = df_hosts[p][host]\n",
    "                if len(df_ss) == 0:\n",
    "                    print 'skipping', host, 'no data'\n",
    "                    continue\n",
    "                if len(df_ss[ df_ss['hostname'] == host ]) == 0:\n",
    "                    print 'skipping', host\n",
    "                    continue\n",
    "                for period in times: # '08-12 to 16', '11-29 to 12-03',  set(df['period']):\n",
    "                #for period in [ '02-21 to 25', '03-02 to 06' ]:\n",
    "                # for period in [ '08-12 to 16','11-29 to 12-03', '02-21 to 25', '03-02 to 06']: # '08-12 to 16', '11-29 to 12-03',  set(df['period']):\n",
    "                    period_str = period.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    if period_str not in p2c:\n",
    "                        p2c[period_str] = colors[c]\n",
    "                        c += 1\n",
    "                    ds = df_ss[ (df_ss['period'] == period_str) &\n",
    "                                (df_ss['hostname'] == host) &\n",
    "                                (df_ss['slice'] == slicename) ]\n",
    "\n",
    "                    if len(ds) == 0:\n",
    "                        continue\n",
    "\n",
    "                    # Top\n",
    "                    plt.cm.Paired.colors\n",
    "                    \n",
    "                    #ax = axes[0, p]\n",
    "                    ax = axes[0][p]\n",
    "                    r = [math.log10(x) for x in ds['rate_mbps']]\n",
    "                    label = 'pdf-%s-%s (%d)' % (period_str, slicename, len(ds['rate_mbps']))\n",
    "                    label2date[label] = period\n",
    "                    n, bins, patches = ax.hist(r, int(math.sqrt(len(ds['rate_mbps']))),\n",
    "                                               histtype='step', normed=1, label=label, ls='-',\n",
    "                                               color=p2c[period_str])\n",
    "\n",
    "                    #ax.set_xlim(1, 100)\n",
    "                    ax.set_axisbelow(True)\n",
    "\n",
    "                \n",
    "                    ax.legend(fontsize='x-small', loc='upper center', bbox_to_anchor=(0.5, 1.3))\n",
    "                    ax.grid(color='#dddddd')\n",
    "                    ax.set_title(host)\n",
    "                    labels = ['%.2f' % math.pow(10, float(l)) for l in ax.get_xticks()]\n",
    "                    ax.xaxis.set_major_formatter(customFormatter)\n",
    "                    #ax.semilogx()\n",
    "\n",
    "                    # Middle\n",
    "                    #ax = axes[1, p]\n",
    "                    #ax = plt.subplot2grid((3, 5), (1, p))\n",
    "                    ax = axes[1][p]\n",
    "                    label = 'cdf-%s-%s (%d)' % (period, slicename, len(ds['rate_mbps']))\n",
    "                    use_log = True\n",
    "                    if use_log:\n",
    "                        r = [math.log10(x) for x in ds['rate_mbps']]\n",
    "                        n, bins, patches = ax.hist(r, len(ds['rate_mbps']), # ds['rate_mbps']\n",
    "                                                   histtype='step', normed=1, cumulative=True, label=label, ls='-',\n",
    "                                                   color=p2c[period_str])\n",
    "                        ax.xaxis.set_major_formatter(customFormatter)\n",
    "\n",
    "                    else:\n",
    "                        n, bins, patches = ax.hist(ds['rate_mbps'], len(ds['rate_mbps']),\n",
    "                                       histtype='step', normed=1, cumulative=True, label=label, ls='-')\n",
    "                        ax.set_xlim(-1, 200)\n",
    "\n",
    "                    #ax.semilogx()\n",
    "\n",
    "                    ax.set_axisbelow(True)\n",
    "                    #ax.legend(loc=3, fontsize='x-small') # , loc='upper center', bbox_to_anchor=(0.5, 1.1))\n",
    "                    ax.grid(color='#dddddd')\n",
    "                    ax.set_title(host)\n",
    "                    if p != 0:\n",
    "                        ax.set_yticklabels([])\n",
    "\n",
    "    #for i, host_row in enumerate(hosts):\n",
    "    #    for j, host in enumerate(host_row):\n",
    "                    \n",
    "            #ax = axes[2, p]\n",
    "        if True:\n",
    "            print 'last'\n",
    "            axes[2] = plt.subplot2grid((3, 5), (2, 0), colspan=5)\n",
    "            ax = axes[2]\n",
    "        \n",
    "            ds = df_disco[ df_disco['hostname'] == host ]\n",
    "            ax.plot_date(dates.epoch2num(ds['ts']), ds['pct_discards'], ls='-', ms=0, label='switch', color='mediumpurple')\n",
    "        \n",
    "            ax.set_title(host)\n",
    "            ax.set_ylim(-0.01, 1)\n",
    "            ax.tick_params(axis='x', labelrotation=90)\n",
    "            ax.grid(color='#dddddd')\n",
    "            #ax.legend(loc=4, fontsize='x-small') \n",
    " \n",
    "            # Color switch regions with the PDF periods based on legend colors.\n",
    "            for p in range(0, len(periods_list)):\n",
    "                h, l = axes[0][p].get_legend_handles_labels()\n",
    "                for k, line in enumerate(h):\n",
    "                    s = label2date[l[k]]\n",
    "                    e = s + datetime.timedelta(days=4)\n",
    "                    color = h[k].get_edgecolor()\n",
    "                    ax.axvspan(dates.date2num(s), dates.date2num(e), alpha=0.5, color=color)\n",
    "\n",
    "            #if p != 0:\n",
    "            #    ax.set_yticklabels([])\n",
    "            #else:\n",
    "            ax.set_ylabel('% discard timebins')  \n",
    "                \n",
    "            ax2 = ax.twinx() # axes[2, p]\n",
    "        \n",
    "            ds = df_ss_count[ df_ss_count['hostname'] == host ]\n",
    "            ax2.plot_date(dates.epoch2num(ds['ts']), ds['count'], ls='-', ms=0, label='sidestream')\n",
    "        \n",
    "            #ax.set_title(host)\n",
    "            #ax.set_ylim(-0.01, 1)\n",
    "            if p != 4:\n",
    "                ax2.set_yticklabels([])\n",
    "            else:\n",
    "                ax2.set_ylabel('Sidestream Flow Count')\n",
    "            #ax2.set_xticklabels([])\n",
    "            #ax.tick_params(axis='x', labelrotation=90)\n",
    "            ax2.grid(color='#dddddd')\n",
    "            ax.legend(loc=4, fontsize='x-small') \n",
    "            ax2.legend(loc=1, fontsize='x-small') \n",
    "\n",
    "     \n",
    "        axes[0][0].set_ylabel('PDF')\n",
    "        axes[1][0].set_ylabel('CDF')\n",
    "        #axes[2, 0].set_ylabel('% discard timebins')    \n",
    "        #axes[2, 0].set_ylabel('Sidestream Flow Count')    \n",
    "\n",
    "        fig.suptitle(title) # + ('\\n%s' % [period.strftime(\"%Y-%m-%d %H:%M:%S\") for period in times]))\n",
    "        plt.show()\n",
    "\n",
    "#plt.hist2d(\n",
    "#    df_ss[ (df_ss['period'] == '08-12 to 16') & (df_ss['hostname'] == 'mlab1.dfw02') & (df_ss['slice'] == 'samknows') ],\n",
    "#    df_ss[ (df_ss['period'] == '02-21 to 25') & (df_ss['hostname'] == 'mlab1.dfw02') & (df_ss['slice'] == 'samknows') ],\n",
    "#    bins=40,\n",
    "#)\n",
    "#print n, len(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def dt(date):\n",
    "    return datetime.strptime(date, '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import cm\n",
    "from numpy import linspace\n",
    "\n",
    "start = 0.0\n",
    "stop = 1.0\n",
    "number_of_lines= 6\n",
    "cm_subsection = linspace(start, stop, number_of_lines) \n",
    "\n",
    "colors = [ cm.jet(x) for x in cm_subsection ]\n",
    "\n",
    "for i, color in enumerate(colors):\n",
    "    plt.axhline(i, color=color)\n",
    "\n",
    "plt.ylabel('Line Number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((0.6509803921568628, 0.807843137254902, 0.8901960784313725), (0.12156862745098039, 0.47058823529411764, 0.7058823529411765), (0.6980392156862745, 0.8745098039215686, 0.5411764705882353), (0.2, 0.6274509803921569, 0.17254901960784313), (0.984313725490196, 0.6039215686274509, 0.6), (0.8901960784313725, 0.10196078431372549, 0.10980392156862745), (0.9921568627450981, 0.7490196078431373, 0.43529411764705883), (1.0, 0.4980392156862745, 0.0), (0.792156862745098, 0.6980392156862745, 0.8392156862745098), (0.41568627450980394, 0.23921568627450981, 0.6039215686274509), (1.0, 1.0, 0.6), (0.6941176470588235, 0.34901960784313724, 0.1568627450980392))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print                     plt.cm.Paired.colors\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
