{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "# Enables figures loading outside of browser.\n",
    "# If not run, figures will load inline.\n",
    "%matplotlib\n",
    "\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "import datetime\n",
    "import collections\n",
    "import itertools\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# Depends on: pip install sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Some matplotlib features are version dependent.\n",
    "assert(matplotlib.__version__ >= '2.1.2')\n",
    "\n",
    "# Depends on: pip install --upgrade google-cloud-bigquery\n",
    "from google.cloud import bigquery\n",
    "\n",
    "def run_query(query, project='mlab-sandbox'):\n",
    "    client = bigquery.Client(project=project)\n",
    "    job = client.query(query)\n",
    "\n",
    "    results = collections.defaultdict(list)\n",
    "    for row in job.result(timeout=3000):\n",
    "        for key in row.keys():\n",
    "            results[key].append(row.get(key))\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def unlog(x, pos):\n",
    "    \"\"\"Formats the x axis for histograms taken on the log of values.\"\"\"\n",
    "    v = math.pow(10, x)\n",
    "    frac, whole = math.modf(v)\n",
    "    if frac > 0:\n",
    "        return '%.1f' % v\n",
    "    else:\n",
    "        return '%d' % whole\n",
    "    \n",
    "    \n",
    "def hist(vals, bin_count, log=True, cdf=False):\n",
    "    \"\"\"Produces hist or cdf values for smooth plots.\"\"\"\n",
    "    if log:\n",
    "        r = [math.log10(x) for x in vals]\n",
    "    else:\n",
    "        r = vals\n",
    "        \n",
    "    m, bins = np.histogram(r, bin_count, normed=True)\n",
    "    m = m.astype(float)\n",
    "\n",
    "    tops = m\n",
    "    if cdf:\n",
    "        tops = np.cumsum(m)\n",
    "        total = sum(m)\n",
    "        tops = [float(t) / total for t in tops ]\n",
    "    \n",
    "    return tops, bins\n",
    "\n",
    "\n",
    "logFormatter = matplotlib.ticker.FuncFormatter(unlog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_df(\n",
    "    df, xname='', yname='',\n",
    "    cname='', bins=None, cdf=False,\n",
    "    fig_by='', axes_by='', group_by='',\n",
    "    figsize=(6,8), axes=(1,1),\n",
    "    label='{group}',\n",
    "    xlabel='', ylabel='',\n",
    "    xlim=(), ylim=(),\n",
    "    fx=list, fy=list,\n",
    "    xlog=False, ylog=False,\n",
    "    suptitle='', title='', legend={}, figmap=None, log=None, fxn=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        df: pandas.DataFrame,\n",
    "        xname: str, name of column to use as x-axis.\n",
    "        yname: str, name of column to use as y-axis.\n",
    "        cname: str, name of column to use as data source.\n",
    "        cdf: bool,\n",
    "        bins: int or callable,\n",
    "        fig_by: str, name of column to split data into multiple figures.\n",
    "        axes_by: str, name of column to arrange into a single panel.\n",
    "        group_by: str, name of column to plot common split_by and group_by columns.\n",
    "        figsize: (int, int), dimensions of figure.\n",
    "        axes: (int, int), arrangement of axes within figure.\n",
    "        label: str,\n",
    "        xlabel: str,\n",
    "        ylabel: str,\n",
    "        xlim: (xmin, xmax),\n",
    "        ylim: (ymin, ymax),\n",
    "        fx: func,\n",
    "        fy: func,\n",
    "        xlog: bool,\n",
    "        ylog: bool,\n",
    "        suptitle: str,\n",
    "        title: str,\n",
    "        legend: **legend_args,\n",
    "        figmap: returned from a previous run of plot_df, used to overlay values\n",
    "            from multiple data frames. Must use the same fig_by, axes_by, and\n",
    "            group_by values.\n",
    "        log: bool,\n",
    "        f: callable,\n",
    "    Returns:\n",
    "      dict of str to (figures, axes) tuples\n",
    "    \"\"\"\n",
    "    def info(f):\n",
    "        if log:\n",
    "            print f\n",
    "\n",
    "    if figmap is None:\n",
    "        info('new figmap')\n",
    "        figmap = {}\n",
    "    scatter = None\n",
    "    if (xname and yname):\n",
    "        scatter = True\n",
    "    if cname:\n",
    "        scatter = False\n",
    "    if scatter is None:\n",
    "        raise Exception('Provide xname and yname or cname')\n",
    "    \n",
    "    for f in sorted(set(['default'] if not fig_by else df[fig_by])):\n",
    "        if f in figmap:\n",
    "            info('reusing figmap for %s' % f)\n",
    "            fig, ax = figmap[f]\n",
    "        else:\n",
    "            fig = plt.figure(figsize=figsize)\n",
    "            ax = fig.subplots(axes[0], axes[1], squeeze=False)\n",
    "            info('saving figmap for %s' % f)\n",
    "            figmap[f] = (fig, ax)\n",
    "        ax_index = list(itertools.product(range(axes[0]), range(axes[1])))\n",
    "        \n",
    "        df_fig = df if f == 'default' else df[df[fig_by] == f]\n",
    "        for p, a in enumerate(sorted(set(['default'] if not axes_by else df_fig[axes_by]))):\n",
    "\n",
    "            df_axes = df_fig if a == 'default' else df_fig[df_fig[axes_by] == a]\n",
    "            if p >= len(ax_index):\n",
    "                print 'SKIPPING', p, f, a, 'too few axes positions'\n",
    "                continue\n",
    "                \n",
    "            i, j = ax_index[p]\n",
    "            for g in sorted(set(['default'] if not group_by else df_axes[group_by])):\n",
    "                df_g = df_axes if g == 'default' else df_axes[df_axes[group_by] == g]\n",
    "\n",
    "                if scatter:\n",
    "                    x = fx(df_g[xname])\n",
    "                    y = fy(df_g[yname])\n",
    "                    l = label.format(figure=f, axis=a, group=g)\n",
    "                    ax[i][j].scatter(x, y, s=1, label=l)\n",
    "                else:\n",
    "                    r = df_g[cname]\n",
    "                    if bins is None:\n",
    "                        size = int(math.sqrt(len(r)))\n",
    "                    else:\n",
    "                        size = bins(r)\n",
    "                    if fxn:\n",
    "                        fxn(r, figure=f, axis=a, group=g, size=size)\n",
    "                    info(\"%s %s %s %s %s\" % (f, a, g, size, len(r)))\n",
    "                    h_tops, h_bins = hist(r, size, log=xlog , cdf=cdf)\n",
    "                    l = label.format(figure=f, axis=a, group=g, size=size)\n",
    "                    ax[i][j].plot(h_bins[:-1], h_tops, label=l)\n",
    "\n",
    "            if i != len(ax)-1:\n",
    "                ax[i][j].set_xticklabels([])\n",
    "\n",
    "            if title:\n",
    "                ax[i][j].set_title(title.format(figure=f, axis=a, group=g))\n",
    "            if ylabel:\n",
    "                ax[i][j].set_ylabel(ylabel.format(figure=f, axis=a, group=g))\n",
    "            if xlabel:\n",
    "                ax[i][j].set_xlabel(xlabel.format(figure=f, axis=a, group=g))\n",
    "\n",
    "            if xlim:\n",
    "                ax[i][j].set_xlim(xlim)\n",
    "            if ylim:\n",
    "                ax[i][j].set_ylim(ylim)\n",
    "\n",
    "            ax[i][j].grid(color='#dddddd')\n",
    "            ax[i][j].legend(fontsize='x-small', **legend)\n",
    "            if scatter:\n",
    "                ax[i][j].tick_params(axis='x', labelrotation=-90)\n",
    "            if xlog:\n",
    "                ax[i][j].xaxis.set_major_formatter(logFormatter)\n",
    "            if ylog:\n",
    "                ax[i][j].semilogy()\n",
    "\n",
    "        if suptitle:\n",
    "            fig.suptitle(suptitle.format(figure=f))\n",
    "        fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "    return figmap\n",
    "\n",
    "        \n",
    "def plot_scatter(df, xname, yname, **kwargs):\n",
    "    return plot_df(df, xname=xname, yname=yname, **kwargs)\n",
    "\n",
    "    \n",
    "def plot_hist(df, cname, bins=None, **kwargs):\n",
    "    return plot_df(df, cname=cname, bins=bins, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UPLINK UTILIZATION OVER TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disco_pct = run_query(\"\"\"\n",
    "#standardSQL\n",
    "SELECT\n",
    "\n",
    "  UPPER(REGEXP_EXTRACT(hostname, r'mlab1.([a-z]{3})[0-9]{2}.*')) AS metro,\n",
    "  REGEXP_EXTRACT(hostname, r'mlab1.([a-z]{3}[0-9]{2}).*') AS site,\n",
    "  FORMAT_TIMESTAMP(\"%Y-%m-%d\", TIMESTAMP_TRUNC(sts, DAY)) AS day,\n",
    "  UNIX_SECONDS(TIMESTAMP_TRUNC(sts, DAY)) AS ts,  \n",
    "  0.8 * APPROX_QUANTILES(value, 101)[ORDINAL(50)] as bytes_50th,\n",
    "  APPROX_QUANTILES(value, 101)[ORDINAL(90)] as bytes_90th\n",
    "\n",
    "FROM (\n",
    "  SELECT\n",
    "    metric,\n",
    "    REGEXP_EXTRACT(hostname, r'(mlab1.[a-z]{3}[0-9]{2}).*') AS hostname,\n",
    "    sample.timestamp AS sts,\n",
    "    sample.value AS value\n",
    "  FROM\n",
    "    `measurement-lab.base_tables.switch*`,\n",
    "    UNNEST(sample) AS sample\n",
    "  WHERE\n",
    "    metric LIKE 'switch.octets.uplink.tx'\n",
    "    AND REGEXP_CONTAINS(hostname, r\"mlab1.(dfw|lga|nuq)\\d\\d\")\n",
    "  GROUP BY\n",
    "    hostname, metric, sts, value\n",
    ")\n",
    "WHERE\n",
    "  hostname IS NOT NULL\n",
    "GROUP BY\n",
    "  hostname, day, ts\n",
    "ORDER BY\n",
    "  hostname, day, ts\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default': (<matplotlib.figure.Figure at 0x1a191710d0>,\n",
       "  array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1a190f0b50>],\n",
       "         [<matplotlib.axes._subplots.AxesSubplot object at 0x1a1832ca10>],\n",
       "         [<matplotlib.axes._subplots.AxesSubplot object at 0x116c30a90>]],\n",
       "        dtype=object))}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_scatter(\n",
    "    df_disco_pct, 'ts', 'bytes_50th',\n",
    "    axes_by='metro', group_by='site', axes=(3, 1),\n",
    "    suptitle='Daily Median Uplink Utilization',\n",
    "    ylabel=\"Mbps\",\n",
    "    title='{axis}',\n",
    "    xlim=(pd.to_datetime(\"2016-05-31\"), pd.to_datetime(\"2018-08-01\")),\n",
    "    ylim=(1e4, 1e9),\n",
    "    fx=lambda l: [pd.to_datetime(t, unit='s') for t in l],\n",
    "    legend={'loc':3, 'ncol':7, 'columnspacing':1},\n",
    "    ylog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily DISCO discard ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disco_ratio = run_query(\"\"\"\n",
    "WITH measurementlab_switch_dedup AS (\n",
    "  SELECT\n",
    "    metric,\n",
    "    REGEXP_EXTRACT(hostname, r'(mlab[1-4].[a-z]{3}[0-9]{2}).*') AS hostname,\n",
    "    sample.timestamp AS sts,\n",
    "    sample.value AS value\n",
    "  FROM\n",
    "    `measurement-lab.base_tables.switch*`,\n",
    "    UNNEST(sample) AS sample\n",
    "  WHERE\n",
    "    (metric LIKE 'switch.discards.uplink.tx' OR metric LIKE 'switch.unicast.uplink.tx')\n",
    "    AND REGEXP_CONTAINS(hostname, r\"mlab1.(dfw|lga|nuq)\\d\\d\")\n",
    "  GROUP BY\n",
    "    hostname, metric, sts, value\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  UPPER(REGEXP_EXTRACT(hostname, r'mlab1.([a-z]{3})[0-9]{2}.*')) AS metro,\n",
    "  REGEXP_EXTRACT(hostname, r'mlab1.([a-z]{3}[0-9]{2}).*') AS site,\n",
    "  hostname,\n",
    "  day,\n",
    "  ts,\n",
    "  IF(total > 0, discards / total, 0) as ratio\n",
    "FROM (\n",
    "SELECT\n",
    "  hostname,\n",
    "  FORMAT_TIMESTAMP(\"%Y-%m-%d\", TIMESTAMP_TRUNC(sts, DAY)) AS day,\n",
    "  UNIX_SECONDS(TIMESTAMP_TRUNC(sts, DAY)) AS ts,\n",
    "  SUM(IF(metric = \"switch.discards.uplink.tx\", value, 0)) AS discards,\n",
    "  SUM(IF(metric = \"switch.unicast.uplink.tx\", value, 0)) AS total\n",
    "FROM\n",
    "  measurementlab_switch_dedup\n",
    "WHERE\n",
    "  hostname IS NOT NULL\n",
    "GROUP BY\n",
    "  hostname, day, ts\n",
    "HAVING\n",
    "  discards < total\n",
    "ORDER BY\n",
    "  hostname, day, ts\n",
    ")\n",
    "GROUP BY\n",
    "  hostname, day, ts, ratio\n",
    "HAVING\n",
    "  ratio < 0.01\n",
    "ORDER BY\n",
    "  hostname, day, ts\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default': (<matplotlib.figure.Figure at 0x1a1966d4d0>,\n",
       "  array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1a19641b90>],\n",
       "         [<matplotlib.axes._subplots.AxesSubplot object at 0x116f38e50>],\n",
       "         [<matplotlib.axes._subplots.AxesSubplot object at 0x1a192d78d0>]],\n",
       "        dtype=object))}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_scatter(\n",
    "    df_disco_ratio, 'ts', 'ratio', axes_by='metro', group_by='site', axes=(3, 1),\n",
    "    suptitle='Daily Packet Loss Ratio (discards / unicast)',\n",
    "    ylabel=\"Ratio\",\n",
    "    title='{axis}',\n",
    "    xlim=(pd.to_datetime(\"2016-05-31\"), pd.to_datetime(\"2018-08-01\")),\n",
    "    ylim=(1e-6, 1e-1),\n",
    "    fx=lambda l: [pd.to_datetime(t, unit='s') for t in l],\n",
    "    legend={'loc':2},\n",
    "    ylog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDT Median Download Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ndt_all = run_query(\"\"\"\n",
    "WITH mlab_ndt AS (\n",
    "  SELECT\n",
    "    UPPER(REGEXP_EXTRACT(connection_spec.server_hostname, r\"([a-z]{3})[0-9]{2}\")) as metro,\n",
    "    REGEXP_EXTRACT(connection_spec.server_hostname, r\"([a-z]{3}[0-9]{2})\") as site,\n",
    "    web100_log_entry.connection_spec.remote_ip as remote_ip,\n",
    "    log_time,\n",
    "    (8 * (web100_log_entry.snap.HCThruOctetsAcked / (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd))) AS download_mbps\n",
    "\n",
    "  FROM\n",
    "    `measurement-lab.release.ndt_all`\n",
    "\n",
    "  WHERE\n",
    "        REGEXP_CONTAINS(connection_spec.server_hostname, r\"(lga|dfw|nuq)\\d\\d\")\n",
    "    AND web100_log_entry.snap.HCThruOctetsAcked >= 1000000\n",
    "    AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) >= 9000000\n",
    "    AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) < 600000000\n",
    "    AND connection_spec.data_direction = 1\n",
    "    AND web100_log_entry.connection_spec.remote_ip != \"45.56.98.222\"\n",
    "    AND web100_log_entry.connection_spec.remote_ip != \"2600:3c03::f03c:91ff:fe33:819\"\n",
    "    AND web100_log_entry.connection_spec.remote_ip != \"35.225.75.192\"\n",
    "    AND web100_log_entry.connection_spec.remote_ip != \"35.192.37.249\"\n",
    "    AND web100_log_entry.connection_spec.remote_ip != \"35.193.254.117\"\n",
    "    AND anomalies.no_meta is not true\n",
    "  \n",
    "  GROUP BY\n",
    "    connection_spec.server_hostname,\n",
    "    log_time,\n",
    "    web100_log_entry.connection_spec.remote_ip,\n",
    "    web100_log_entry.connection_spec.local_ip,\n",
    "    web100_log_entry.connection_spec.remote_port,\n",
    "    web100_log_entry.connection_spec.local_port,\n",
    "    download_mbps\n",
    ")\n",
    "    \n",
    "SELECT\n",
    "  metro,\n",
    "  site,\n",
    "  day,\n",
    " --  AVG(download_mbps) as download_mbps,\n",
    "  APPROX_QUANTILES(download_mbps, 101)[ORDINAL(50)] as download_mbps,\n",
    "  count(*) as count\n",
    "FROM\n",
    "(\n",
    "  SELECT\n",
    "    metro,\n",
    "    site,\n",
    "    TIMESTAMP_TRUNC(log_time, DAY) as day,\n",
    "    -- APPROX_QUANTILES(download_mbps, 101)[ORDINAL(50)] as download_mbps\n",
    "    MAX(download_mbps) as download_mbps\n",
    "  FROM\n",
    "    mlab_ndt\n",
    "\n",
    "  GROUP BY\n",
    "    metro, site, day, remote_ip\n",
    ")\n",
    "\n",
    "GROUP BY\n",
    "  metro, site, day\n",
    "\n",
    "ORDER BY\n",
    "  day\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default': (<matplotlib.figure.Figure at 0x1a197469d0>,\n",
       "  array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1a1a3ff050>],\n",
       "         [<matplotlib.axes._subplots.AxesSubplot object at 0x11676c550>],\n",
       "         [<matplotlib.axes._subplots.AxesSubplot object at 0x1a19787510>]],\n",
       "        dtype=object))}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_scatter(\n",
    "    df_ndt_all, 'day', 'download_mbps', axes_by='metro', group_by='site', axes=(3, 1),\n",
    "    suptitle='Median NDT Download Rates',\n",
    "    ylabel=\"Mbps\",\n",
    "    title='{axis}',\n",
    "    xlim=(pd.to_datetime(\"2016-05-31\"), pd.to_datetime(\"2018-08-01\")),\n",
    "    ylim=(0, 50),\n",
    "    fx=lambda l: [pd.to_datetime(t) for t in l],\n",
    "    legend={'loc':3, 'ncol':7, 'columnspacing':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDT Segs Retrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT ENOUGH HISTORICAL NDT DATA TO GET FULL TIMELINE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ndt_retrans = run_query(\"\"\"\n",
    "WITH mlab_ndt AS (\n",
    "  SELECT\n",
    "    connection_spec.server_hostname as hostname,\n",
    "    web100_log_entry.connection_spec.remote_ip as remote_ip,\n",
    "    log_time,\n",
    "    web100_log_entry.snap.SegsRetrans as SegsRetrans,\n",
    "    web100_log_entry.snap.SegsOut as SegsOut\n",
    "\n",
    "  FROM\n",
    "    `measurement-lab.release.ndt_all`\n",
    "\n",
    "  WHERE\n",
    "        REGEXP_CONTAINS(connection_spec.server_hostname, r\"(lga|dfw|nuq)\\d\\d\")\n",
    "    AND web100_log_entry.snap.HCThruOctetsAcked >= 1000000\n",
    "    AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) >= 9000000\n",
    "    AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) < 600000000\n",
    "    AND connection_spec.data_direction = 1\n",
    "    AND web100_log_entry.connection_spec.remote_ip != \"45.56.98.222\"\n",
    "    AND web100_log_entry.connection_spec.remote_ip != \"2600:3c03::f03c:91ff:fe33:819\"\n",
    "    AND web100_log_entry.connection_spec.remote_ip != \"35.225.75.192\"\n",
    "    AND web100_log_entry.connection_spec.remote_ip != \"35.192.37.249\"\n",
    "    AND web100_log_entry.connection_spec.remote_ip != \"35.193.254.117\"\n",
    "    AND log_time >= TIMESTAMP(\"2016-06-01\")\n",
    "  \n",
    "  GROUP BY\n",
    "    connection_spec.server_hostname,\n",
    "    log_time,\n",
    "    web100_log_entry.connection_spec.remote_ip,\n",
    "    web100_log_entry.connection_spec.local_ip,\n",
    "    web100_log_entry.connection_spec.remote_port,\n",
    "    web100_log_entry.connection_spec.local_port,\n",
    "    SegsRetrans,\n",
    "    SegsOut\n",
    ")\n",
    "    \n",
    "SELECT\n",
    "  UPPER(REGEXP_EXTRACT(hostname, r\"([a-z]{3})[0-9]{2}\")) as metro,\n",
    "  REGEXP_EXTRACT(hostname, r\"([a-z]{3}[0-9]{2})\") as site,\n",
    "  day,\n",
    "  APPROX_QUANTILES(ratio, 101)[ORDINAL(50)] AS median_ratio,\n",
    "  count(*) as count\n",
    "FROM\n",
    "(\n",
    "  SELECT\n",
    "    hostname,\n",
    "    TIMESTAMP_TRUNC(log_time, DAY) as day,\n",
    "    MAX(SAFE_DIVIDE(SegsRetrans, SegsOut)) as ratio\n",
    "\n",
    "  FROM\n",
    "    mlab_ndt\n",
    "\n",
    "  GROUP BY\n",
    "    hostname,\n",
    "    day,\n",
    "    remote_ip\n",
    ")\n",
    "\n",
    "GROUP BY\n",
    "  hostname, day\n",
    "\n",
    "ORDER BY\n",
    "  day\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'default': (<matplotlib.figure.Figure at 0x1a193b3290>,\n",
       "  array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1a1966d850>],\n",
       "         [<matplotlib.axes._subplots.AxesSubplot object at 0x116e2c3d0>],\n",
       "         [<matplotlib.axes._subplots.AxesSubplot object at 0x1a1a312d50>]],\n",
       "        dtype=object))}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_scatter(\n",
    "    df_ndt_retrans, 'day', 'median_ratio', axes_by='metro', group_by='site', axes=(3, 1),\n",
    "    suptitle='Median NDT Retransmission Ratio - (SegsRetran / SegsOut)',\n",
    "    ylabel=\"Ratio\",\n",
    "    title='{axis}',\n",
    "    xlim=(pd.to_datetime(\"2016-05-31\"), pd.to_datetime(\"2018-08-01\")),\n",
    "    ylim=(1e-6, 1e-1),\n",
    "    fx=lambda l: [pd.to_datetime(t) for t in l],\n",
    "    legend={'loc':2},\n",
    "    ylog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# NDT test distributions - Before & After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ndt_variance = run_query(\"\"\"\n",
    "WITH mlab_ndt AS (\n",
    "  SELECT\n",
    "    connection_spec.server_hostname as server_hostname,\n",
    "    log_time,\n",
    "    web100_log_entry.connection_spec.remote_ip AS remote_ip,\n",
    "    (8 * (web100_log_entry.snap.HCThruOctetsAcked / (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd))) AS download_mbps\n",
    "  FROM\n",
    "    `measurement-lab.base_tables.ndt*`\n",
    "  WHERE\n",
    "\n",
    "  (    TIMESTAMP_TRUNC(log_time, DAY) BETWEEN TIMESTAMP(\"2018-02-11\") AND TIMESTAMP(\"2018-02-25\")\n",
    "    OR TIMESTAMP_TRUNC(log_time, DAY) BETWEEN TIMESTAMP(\"2018-03-11\") AND TIMESTAMP(\"2018-03-25\"))\n",
    "  AND REGEXP_CONTAINS(connection_spec.server_hostname, r\"mlab1.(dfw|lga|nuq)\\d\\d\")\n",
    "  AND web100_log_entry.snap.HCThruOctetsAcked >= 1000000\n",
    "  AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) >= 9000000\n",
    "  AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) < 600000000\n",
    "  AND connection_spec.data_direction = 1\n",
    "  \n",
    "  GROUP BY\n",
    "    server_hostname,\n",
    "    log_time,\n",
    "    web100_log_entry.connection_spec.remote_ip,\n",
    "    web100_log_entry.connection_spec.local_ip,\n",
    "    web100_log_entry.connection_spec.remote_port,\n",
    "    web100_log_entry.connection_spec.local_port,\n",
    "    download_mbps)\n",
    "\n",
    "\n",
    "SELECT\n",
    "  UPPER(REGEXP_EXTRACT(server_hostname, r'mlab[1-4].([a-z]{3})[0-9]{2}.*')) AS metro,\n",
    "  REGEXP_EXTRACT(server_hostname, r'mlab[1-4].([a-z]{3}[0-9]{2}).*') AS site,\n",
    "  REGEXP_EXTRACT(server_hostname, r'(mlab[1-4].[a-z]{3}[0-9]{2}).*') AS hostname,\n",
    "  CASE\n",
    "    WHEN TIMESTAMP_TRUNC(log_time, DAY) BETWEEN TIMESTAMP(\"2018-02-11\") AND TIMESTAMP(\"2018-02-25\") THEN 'before-2w'\n",
    "    WHEN TIMESTAMP_TRUNC(log_time, DAY) BETWEEN TIMESTAMP(\"2018-03-11\") AND TIMESTAMP(\"2018-03-25\") THEN 'after-2w'\n",
    "    ELSE 'what'\n",
    "  END AS period,\n",
    "  remote_ip,\n",
    "  STDDEV(download_mbps) AS download_stddev,\n",
    "  (STDDEV(download_mbps) / AVG(download_mbps)) AS download_cv,\n",
    "  MAX(download_mbps) AS download_max,\n",
    "  MIN(download_mbps) AS download_min,\n",
    "  AVG(download_mbps) AS download_avg\n",
    "\n",
    "FROM\n",
    "  mlab_ndt\n",
    "WHERE\n",
    "  remote_ip IN(\n",
    "    SELECT\n",
    "      remote_ip\n",
    "    FROM (\n",
    "      SELECT\n",
    "        remote_ip, count(*) as c1\n",
    "      FROM\n",
    "        mlab_ndt\n",
    "      WHERE\n",
    "        TIMESTAMP_TRUNC(log_time, DAY) BETWEEN TIMESTAMP(\"2018-02-11\") AND TIMESTAMP(\"2018-02-25\")\n",
    "      GROUP BY\n",
    "        remote_ip\n",
    "      HAVING c1 > 5\n",
    "    ) INNER JOIN (\n",
    "      SELECT\n",
    "        remote_ip AS remote_ip, count(*) as c2\n",
    "      FROM\n",
    "        mlab_ndt\n",
    "      WHERE\n",
    "        TIMESTAMP_TRUNC(log_time, DAY) BETWEEN TIMESTAMP(\"2018-03-11\") AND TIMESTAMP(\"2018-03-25\")\n",
    "      GROUP BY\n",
    "        remote_ip\n",
    "      HAVING c2 > 5\n",
    "    ) USING (remote_ip)) \n",
    "GROUP BY\n",
    "  server_hostname,\n",
    "  period,\n",
    "  remote_ip\n",
    "  --download_mbps\n",
    "\n",
    "HAVING download_stddev is not NULL\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff LGA lga02 Ks_2sampResult(statistic=0.13487760908755242, pvalue=6.455805572283752e-05)\n",
      "diff LGA lga03 Ks_2sampResult(statistic=0.05627438029592241, pvalue=0.0006379908963118555)\n",
      "diff LGA lga07 Ks_2sampResult(statistic=0.049918312849347335, pvalue=0.0061856763535876064)\n"
     ]
    }
   ],
   "source": [
    "values = {}\n",
    "def ks_compare(r, figure='', axis='', group='', size=''):\n",
    "    values[\"%s-%s-%s\" % (figure, axis, group)] = r\n",
    "    if group == 'before-2w':\n",
    "        after = values[\"%s-%s-%s\" % (figure, axis, 'after-2w')]\n",
    "        result = stats.ks_2samp(r, after)\n",
    "        if result.pvalue < 0.01:\n",
    "            print 'diff', figure, axis, result\n",
    "\n",
    "            \n",
    "f = plot_hist(\n",
    "    df_ndt_variance, 'download_max', lambda r: int(math.sqrt(len(r))),\n",
    "    fig_by='metro', axes_by='site', group_by='period',\n",
    "    suptitle='Distribution of NDT Downloads - MAX(per remote_ip)',\n",
    "    label='{group} ({size})',\n",
    "    title='{axis}', axes=(3, 2),\n",
    "    xlim=(math.log10(.01), math.log10(1000)),\n",
    "    cdf=False, xlog=True, figsize=(9, 7),\n",
    "    fxn=ks_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff LGA lga03 Ks_2sampResult(statistic=0.06594182035779406, pvalue=3.1651607393831e-05)\n",
      "diff LGA lga07 Ks_2sampResult(statistic=0.05214086679603924, pvalue=0.0036553957015487497)\n"
     ]
    }
   ],
   "source": [
    "values = {}\n",
    "def ks_compare(r, figure='', axis='', group='', size=''):\n",
    "    values[\"%s-%s-%s\" % (figure, axis, group)] = r\n",
    "    if group == 'before-2w':\n",
    "        after = values[\"%s-%s-%s\" % (figure, axis, 'after-2w')]\n",
    "        result = stats.ks_2samp(r, after)\n",
    "        if result.pvalue < 0.01:\n",
    "            print 'diff', figure, axis, result\n",
    "\n",
    "f = plot_hist(\n",
    "    df_ndt_variance, 'download_avg', lambda r: int(math.sqrt(len(r))),\n",
    "    fig_by='metro', axes_by='site', group_by='period',\n",
    "    suptitle='Distribution of NDT Downloads - AVERAGE(per remote_ip)',\n",
    "    label='{group} ({size})',\n",
    "    title='{axis}', axes=(3, 2),\n",
    "    xlim=(math.log10(.01), math.log10(1000)),\n",
    "    cdf=True, xlog=True, figsize=(9, 7),\n",
    "    fxn=ks_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running query dfw01 Thu Aug 30 21:15:41 2018\n",
      "running query dfw02 Thu Aug 30 21:16:08 2018\n",
      "running query dfw03 Thu Aug 30 21:20:34 2018\n",
      "running query dfw04 Thu Aug 30 21:21:45 2018\n",
      "running query dfw05 Thu Aug 30 21:23:38 2018\n",
      "running query dfw06 Thu Aug 30 21:26:26 2018\n",
      "running query lga02 Thu Aug 30 21:27:09 2018\n",
      "running query lga03 Thu Aug 30 21:27:52 2018\n",
      "running query lga04 Thu Aug 30 21:29:04 2018\n",
      "running query lga05 Thu Aug 30 21:29:32 2018\n",
      "running query lga06 Thu Aug 30 21:30:01 2018\n",
      "running query lga07 Thu Aug 30 21:32:12 2018\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def query(site):\n",
    "    print 'running query', site, time.ctime()\n",
    "    return \"\"\"\n",
    "CREATE TEMPORARY FUNCTION\n",
    "  timeBin(ts_usec INT64,\n",
    "    size INT64) AS ( CAST(TRUNC(ts_usec / 1e6 / 10) * 10 AS INT64) );\n",
    "\n",
    "WITH\n",
    "  mlab_ndt_dedup AS (\n",
    "  SELECT\n",
    "    test_id,\n",
    "    log_time,\n",
    "    connection_spec.server_hostname AS hostname,\n",
    "    web100_log_entry.snap.StartTimeStamp as StartTimeStamp,\n",
    "    (8 * (web100_log_entry.snap.HCThruOctetsAcked / (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd))) AS download_mbps\n",
    "\n",
    "  FROM\n",
    "    `measurement-lab.release.ndt_all`\n",
    "  WHERE\n",
    "          log_time BETWEEN TIMESTAMP(\"2016-06-01\") AND TIMESTAMP(\"2018-08-01\")\n",
    "      AND (connection_spec.server_hostname = \"mlab1.\"\"\"+site+\"\"\".measurement-lab.org\" OR connection_spec.server_hostname = \"ndt.iupui.mlab1.\"\"\"+site+\"\"\".measurement-lab.org\")\n",
    "      AND connection_spec.data_direction = 1\n",
    "      AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) >= 9000000\n",
    "      AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) < 600000000\n",
    "      AND web100_log_entry.snap.HCThruOctetsAcked >= 1000000\n",
    "\n",
    "\n",
    "  GROUP BY\n",
    "    test_id,\n",
    "    log_time,\n",
    "    hostname,\n",
    "    StartTimeStamp,\n",
    "    web100_log_entry.connection_spec.remote_ip,\n",
    "    web100_log_entry.connection_spec.local_ip,\n",
    "    web100_log_entry.connection_spec.remote_port,\n",
    "    web100_log_entry.connection_spec.local_port,\n",
    "    download_mbps)\n",
    "    \n",
    "  ,ndt_test_ids_with_discards AS (\n",
    "  SELECT\n",
    "    ndt.test_id as test_id,\n",
    "    ndt.hostname as hostname,\n",
    "    ndt.day as day,\n",
    "    SUM(disco.discards) AS discards,\n",
    "    ndt.download_mbps as download_mbps\n",
    "  FROM (\n",
    "    SELECT\n",
    "      hostname,\n",
    "      UNIX_SECONDS(sample.timestamp) - 10 AS tstart,\n",
    "      UNIX_SECONDS(sample.timestamp) AS tend,\n",
    "      sample.value AS discards\n",
    "    FROM\n",
    "      `measurement-lab.base_tables.switch*`,\n",
    "      UNNEST(sample) AS sample\n",
    "    WHERE\n",
    "      metric = 'switch.discards.uplink.tx'\n",
    "      AND sample.timestamp BETWEEN TIMESTAMP(\"2016-06-01\") AND TIMESTAMP(\"2018-08-01\")\n",
    "      AND hostname = \"mlab1.\"\"\"+site+\"\"\".measurement-lab.org\"\n",
    "    GROUP BY\n",
    "      hostname,\n",
    "      tstart,\n",
    "      tend,\n",
    "      discards\n",
    "    HAVING\n",
    "      discards > 0\n",
    "  ) AS disco\n",
    "  JOIN (\n",
    "    SELECT\n",
    "      test_id,\n",
    "      REGEXP_EXTRACT(connection_spec.server_hostname, r\"(mlab1.\"\"\"+site+\"\"\".measurement-lab.org)\") as hostname,\n",
    "      TIMESTAMP_TRUNC(log_time, DAY) as day,\n",
    "      timeBin(web100_log_entry.snap.StartTimeStamp, 10) AS tstart,\n",
    "      timeBin(web100_log_entry.snap.StartTimeStamp, 10) + 20 AS tend,\n",
    "      (8 * (web100_log_entry.snap.HCThruOctetsAcked / (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd))) AS download_mbps\n",
    "\n",
    "  FROM\n",
    "    `measurement-lab.release.ndt_all`\n",
    "    --`measurement-lab.base_tables.ndt*`\n",
    "  WHERE\n",
    "          log_time BETWEEN TIMESTAMP(\"2016-06-01\") AND TIMESTAMP(\"2018-08-01\")\n",
    "      AND connection_spec.data_direction = 1\n",
    "      AND (connection_spec.server_hostname = \"mlab1.\"\"\"+site+\"\"\".measurement-lab.org\" OR connection_spec.server_hostname = \"ndt.iupui.mlab1.\"\"\"+site+\"\"\".measurement-lab.org\")\n",
    "      AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) >= 9000000\n",
    "      AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) < 600000000\n",
    "      AND web100_log_entry.snap.HCThruOctetsAcked >= 1000000\n",
    "\n",
    "    GROUP BY\n",
    "      test_id,\n",
    "      hostname,\n",
    "      day,\n",
    "      tstart,\n",
    "      tend,\n",
    "      download_mbps ) AS ndt\n",
    "  ON (disco.hostname = ndt.hostname\n",
    "      AND (disco.tstart = ndt.tstart OR disco.tend = ndt.tend))\n",
    "  GROUP BY\n",
    "    day, hostname, test_id, download_mbps\n",
    "  )\n",
    "\n",
    "\n",
    "SELECT\n",
    "  day, metro, site, hostname, discards, COUNT(*) as count\n",
    "FROM\n",
    "(\n",
    "  SELECT\n",
    "    TIMESTAMP_TRUNC(log_time, DAY) as day,\n",
    "    UPPER(REGEXP_EXTRACT(connection_spec.server_hostname, r'mlab[1-4].([a-z]{3})[0-9]{2}.*')) AS metro,\n",
    "    REGEXP_EXTRACT(connection_spec.server_hostname, r'mlab[1-4].([a-z]{3}[0-9]{2}).*') AS site,\n",
    "    REGEXP_EXTRACT(connection_spec.server_hostname, r'(mlab[1-4].[a-z]{3}[0-9]{2}).*') AS hostname,\n",
    "    CASE\n",
    "      WHEN test_id IN(SELECT test_id from ndt_test_ids_with_discards) THEN 'non-zero'\n",
    "      ELSE 'zero'\n",
    "--      WHEN test_id NOT IN(SELECT test_id from ndt_test_ids_with_discards) THEN 'without'\n",
    "--      ELSE 'what'\n",
    "    END as discards\n",
    "\n",
    "  FROM\n",
    "    --`measurement-lab.base_tables.ndt*`\n",
    "    `measurement-lab.release.ndt_all`\n",
    "  WHERE\n",
    "        log_time BETWEEN TIMESTAMP(\"2016-06-01\") AND TIMESTAMP(\"2018-08-01\")\n",
    "    AND connection_spec.data_direction = 1\n",
    "    AND (connection_spec.server_hostname = \"mlab1.\"\"\"+site+\"\"\".measurement-lab.org\" OR connection_spec.server_hostname = \"ndt.iupui.mlab1.\"\"\"+site+\"\"\".measurement-lab.org\")\n",
    "    AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) >= 9000000\n",
    "    AND (web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) < 600000000\n",
    "    AND web100_log_entry.snap.HCThruOctetsAcked >= 1000000\n",
    "\n",
    "  )\n",
    "GROUP BY\n",
    "  day, metro, site, hostname, discards\n",
    "\"\"\"\n",
    "\n",
    "if False:\n",
    "    df_test_counts = pd.concat([\n",
    "    run_query(query(\"dfw01\")),\n",
    "    run_query(query(\"dfw02\")),\n",
    "    run_query(query(\"dfw03\")),\n",
    "    run_query(query(\"dfw04\")),\n",
    "    run_query(query(\"dfw05\")),\n",
    "    run_query(query(\"dfw06\")),\n",
    "    run_query(query(\"lga02\")),\n",
    "    run_query(query(\"lga03\")),\n",
    "    run_query(query(\"lga04\")),\n",
    "    run_query(query(\"lga05\")),\n",
    "    run_query(query(\"lga06\")),\n",
    "    run_query(query(\"lga07\")),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'count', u'day', u'discards', u'hostname', u'metro', u'site'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{u'DFW': (<matplotlib.figure.Figure at 0x1a345d2890>,\n",
       "  array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1a342ec290>,\n",
       "          <matplotlib.axes._subplots.AxesSubplot object at 0x1a332e0910>],\n",
       "         [<matplotlib.axes._subplots.AxesSubplot object at 0x116aaa350>,\n",
       "          <matplotlib.axes._subplots.AxesSubplot object at 0x1a331b6bd0>],\n",
       "         [<matplotlib.axes._subplots.AxesSubplot object at 0x1a1fe61b10>,\n",
       "          <matplotlib.axes._subplots.AxesSubplot object at 0x1a3e0e3890>]],\n",
       "        dtype=object)),\n",
       " u'LGA': (<matplotlib.figure.Figure at 0x1a33082a90>,\n",
       "  array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1a2a7ea910>,\n",
       "          <matplotlib.axes._subplots.AxesSubplot object at 0x1a1fc355d0>],\n",
       "         [<matplotlib.axes._subplots.AxesSubplot object at 0x1a3d50a290>,\n",
       "          <matplotlib.axes._subplots.AxesSubplot object at 0x1a3e1cbf50>],\n",
       "         [<matplotlib.axes._subplots.AxesSubplot object at 0x1a27e1ca10>,\n",
       "          <matplotlib.axes._subplots.AxesSubplot object at 0x1a27d50b10>]],\n",
       "        dtype=object))}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: does not preserve binsize across group_by. Each line re-calculates the bin size.\n",
    "print df_test_counts.keys()\n",
    "plot_scatter(\n",
    "    df_test_counts, 'day', 'count',\n",
    "    fig_by='metro', axes_by='site', group_by='discards',\n",
    "    suptitle='NDT Test Counts (with or without discards)',\n",
    "    label='{group}',\n",
    "    title='{axis}',\n",
    "    axes=(3, 2), figsize=(12, 10),\n",
    "    ylim=(-200, 30000),\n",
    "    xlim=(pd.to_datetime(\"2016-05-31\"), pd.to_datetime(\"2018-08-01\")),\n",
    "    fx=lambda l: [pd.to_datetime(t) for t in l])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
