{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "# Enables figures loading outside of browser.\n",
    "# If not run, figures will load inline.\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "import datetime\n",
    "\n",
    "# Some matplotlib features are version dependent.\n",
    "assert(matplotlib.__version__ >= '2.1.2')\n",
    "\n",
    "# Depends on: pip install --upgrade google-cloud-bigquery\n",
    "import query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unlog(x, pos):\n",
    "    return '%.2f' % math.pow(10, x)\n",
    "\n",
    "customFormatter = matplotlib.ticker.FuncFormatter(unlog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = query.sync_query(\"\"\"\n",
    "#standardSQL\n",
    "SELECT\n",
    "  name AS hostname,\n",
    "  FORMAT_TIMESTAMP(\"%Y-%m-%d\", TIMESTAMP_TRUNC(sts, DAY)) AS day,\n",
    "  UNIX_SECONDS(TIMESTAMP_TRUNC(sts, DAY)) AS ts,\n",
    "  SUM(IF(metric = 'switch.discards.uplink.tx', value, 0)) AS total_discards,\n",
    "  SUM(IF(metric = 'switch.unicast.uplink.tx', value, 0)) AS total_packets,\n",
    "  COUNTIF(metric = 'switch.discards.uplink.tx' AND value > 0) / 8640 AS pct_discards\n",
    "\n",
    "FROM (\n",
    "  SELECT\n",
    "    metric,\n",
    "    REGEXP_EXTRACT(hostname, r'(mlab[1-4].[a-z]{3}[0-9]{2}).*') AS name,\n",
    "    sample.timestamp AS sts,\n",
    "    sample.value AS value\n",
    "  FROM\n",
    "    `mlab-sandbox.base_tables.switch*`,\n",
    "    UNNEST(sample) AS sample\n",
    "  WHERE\n",
    "    metric LIKE 'switch.discards.uplink.tx' OR metric LIKE 'switch.unicast.uplink.tx'\n",
    "  GROUP BY\n",
    "    hostname, metric, sts, value\n",
    ")\n",
    "WHERE\n",
    "  name IS NOT NULL\n",
    "GROUP BY\n",
    "  hostname, day, ts\n",
    "ORDER BY\n",
    "  hostname, day, ts\n",
    "\"\"\")\n",
    "\n",
    "df_disco = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discards over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0.98,'Discards over time')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites = [\n",
    "    ['dfw', 'lga', 'iad'],\n",
    "    ['sea', 'atl', 'den'],\n",
    "    ['mia', 'nuq', 'ord'],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(12, 10))\n",
    "for i, site_row in enumerate(sites):\n",
    "    for j, site in enumerate(site_row):\n",
    "        if j != 0:\n",
    "            axes[i, j].set_yticklabels([])\n",
    "        if i != len(sites)-1:\n",
    "            axes[i, j].set_xticklabels([])\n",
    "        for h in set(df_disco['hostname']):\n",
    "            if ('mlab1.' + site) in h:\n",
    "                ds = df_disco[ (df_disco['hostname'] == h) & (df_disco['total_discards'] > 100)& (df_disco['total_discards'] < 1000000)]\n",
    "                axes[i, j].plot_date(dates.epoch2num(ds['ts']), ds['total_discards'], ls='-', ms=0, label=h[6:11])\n",
    "\n",
    "        axes[i, j].set_title(site)\n",
    "        axes[i, j].set_ylim(100, 1000000)\n",
    "        axes[i, j].tick_params(axis='x', labelrotation=90)\n",
    "        axes[i, j].grid(color='#dddddd')\n",
    "        axes[i, j].legend(loc=4, fontsize='x-small')\n",
    "        axes[i, j].semilogy()\n",
    "        \n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.4)\n",
    "fig.suptitle('Discards over time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percent of Timebins with Discards "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0.98,'Daily percentage of timebins with any discards')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = 'Daily percentage of timebins with any discards'\n",
    "sites = [\n",
    "    ['mlab1.dfw02', 'mlab1.dfw03', 'mlab1.dfw04'],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(sites[0]))\n",
    "for i, hosts in enumerate(sites):\n",
    "    for j, host in enumerate(hosts): \n",
    "        ax = axes[j]\n",
    "        \n",
    "        ds = df_disco[ df_disco['hostname'] == host ]\n",
    "        ax.plot_date(dates.epoch2num(ds['ts']), ds['pct_discards'], ls='-', ms=0, label=host)\n",
    "        \n",
    "        ax.set_title(host)\n",
    "        ax.set_ylim(-0.01, .4)\n",
    "        ax.tick_params(axis='x', labelrotation=90)\n",
    "        ax.grid(color='#dddddd')\n",
    "        ax.legend(loc=4, fontsize='x-small')\n",
    "        \n",
    "        \n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.4)\n",
    "fig.suptitle(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Packet Discard Ratios (Switch Loss Rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0.98,'Switch Packet Loss Rate')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites = [\n",
    "    ['dfw', 'lga', 'iad'],\n",
    "    ['sea', 'atl', 'den'],\n",
    "    ['mia', 'nuq', 'ord'],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(12, 10))\n",
    "for i, site_row in enumerate(sites):\n",
    "    for j, site in enumerate(site_row):\n",
    "        axes[i, j].set_title(site)\n",
    "        if j != 0:\n",
    "            axes[i, j].set_yticklabels([])\n",
    "        if i != len(sites)-1:\n",
    "            axes[i, j].set_xticklabels([])\n",
    "        if j == 0:\n",
    "            axes[i, j].set_ylabel('Percent Loss')\n",
    "\n",
    "        for h in set(df_disco['hostname']):\n",
    "            if 'mlab1.' + site in h:\n",
    "                #ds = df_disco[ df_disco['hostname'] == h]\n",
    "                ds = df_disco[ (df_disco['hostname'] == h) &\n",
    "                               (df_disco['total_discards'] > 100) &\n",
    "                               (df_disco['total_discards'] < 1000000) ]\n",
    "                ratio = 100 * ds['total_discards'] / ds['total_packets']\n",
    "                axes[i, j].plot_date(dates.epoch2num(ds['ts']), ratio, ls='-', ms=0, label=h[:11])\n",
    "        axes[i, j].set_ylim(10**-4, 10**-1)\n",
    "        axes[i, j].tick_params(axis='x', labelrotation=90)\n",
    "        axes[i, j].grid(color='#dddddd')\n",
    "        axes[i, j].legend(loc=4, fontsize='x-small')\n",
    "        axes[i, j].semilogy()\n",
    "        \n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.4)\n",
    "fig.suptitle('Switch Packet Loss Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Flow-Control Trial (measurement-lab.public)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cat sidestream.sql | bq query --format=csv --max_rows=1000000 --nouse_legacy_sql > sidestream-trial-6w.csv\n",
    "#df = pd.read_csv('sidestream-trial-6w.csv')\n",
    "\n",
    "result = query.sync_query(\"\"\"\n",
    "#standardSQL                                                                    \n",
    "    -- Only works for mlab1 addresses. May not work on all machines.\n",
    "CREATE TEMPORARY FUNCTION sliceFromIP(ipaddr STRING)\n",
    "    AS ( MOD(CAST(REGEXP_EXTRACT(ipaddr, r'[:.]([0-9]+)$') AS INT64), 64) - 10 );\n",
    "\n",
    "CREATE TEMPORARY FUNCTION betweenTimes(ts INT64, starttime STRING, endtime STRING)\n",
    "    AS ( TIMESTAMP_SECONDS(ts) >= TIMESTAMP(starttime) AND TIMESTAMP_SECONDS(ts) <= TIMESTAMP(endtime) );\n",
    "\n",
    "SELECT\n",
    "    CASE \n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 1 THEN 'ndt'\n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7 THEN 'samknows'\n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 9 THEN 'neubot'\n",
    "        ELSE 'other' \n",
    "    END AS slice,\n",
    "    CASE\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-01-26 00:00:00\", \"2018-01-27 00:00:00\") THEN '5w'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-02 00:00:00\", \"2018-02-03 00:00:00\") THEN '4w'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-09 00:00:00\", \"2018-02-10 00:00:00\") THEN '3w'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-16 00:00:00\", \"2018-02-17 00:00:00\") THEN '2w'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-23 00:00:00\", \"2018-02-24 00:00:00\") THEN '1w'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-03-02 00:00:00\", \"2018-03-03 00:00:00\") THEN '0w'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-03-09 00:00:00\", \"2018-03-10 00:00:00\") THEN '+1w'\n",
    "    ELSE 'unknown'                                                                    \n",
    "    END AS period,\n",
    "    REGEXP_EXTRACT(test_id, r\"\\d\\d\\d\\d/\\d\\d/\\d\\d/(mlab[1-4].[a-z]{3}[0-9]{2})\") AS hostname,\n",
    "    web100_log_entry.snap.StartTimeStamp AS ts,                                   \n",
    "    8 * (web100_log_entry.snap.HCThruOctetsAcked /                                \n",
    "      (web100_log_entry.snap.SndLimTimeRwin +                                     \n",
    "       web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "       web100_log_entry.snap.SndLimTimeSnd)) as rate_mbps   \n",
    "FROM\n",
    "    `measurement-lab.public.sidestream`\n",
    "\n",
    "WHERE\n",
    "        (  betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-01-26 00:00:00\", \"2018-01-27 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-02 00:00:00\", \"2018-02-03 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-09 00:00:00\", \"2018-02-10 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-16 00:00:00\", \"2018-02-17 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-23 00:00:00\", \"2018-02-24 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-03-02 00:00:00\", \"2018-03-03 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-03-09 00:00:00\", \"2018-03-10 00:00:00\")\n",
    "        )\n",
    "  AND REGEXP_CONTAINS(test_id, r\"mlab1.(dfw\\d\\d)\")\n",
    "  AND web100_log_entry.snap.HCThruOctetsAcked >= 1000000 -- 819200                          \n",
    "  AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "    web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "    web100_log_entry.snap.SndLimTimeSnd) >= 9000000                             \n",
    "  AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "    web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "    web100_log_entry.snap.SndLimTimeSnd) < 600000000                            \n",
    "  AND (web100_log_entry.snap.State = 1 OR                                       \n",
    "    (web100_log_entry.snap.State >= 5 AND                                       \n",
    "    web100_log_entry.snap.State <= 11))\n",
    "    \n",
    "GROUP BY\n",
    "  hostname, slice, period, ts, rate_mbps\n",
    "\"\"\")\n",
    "df_ss = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "730671 1303.9458692 854\n",
      "94\n"
     ]
    }
   ],
   "source": [
    "print len(df_ss), max(df_ss['rate_mbps']), int(math.sqrt(len(df_ss['rate_mbps'])))\n",
    "\n",
    "hosts = [\n",
    "    ['mlab1.lga03', 'mlab1.lga04'],\n",
    "    ['mlab1.lga05', 'mlab1.lga06'],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "for i, host_row in enumerate(hosts):\n",
    "    for j, host in enumerate(host_row):\n",
    "        for period in ['+1w', '0w', '1w', '2w', '3w']: #, '4w', '5w']:\n",
    "            ds = df_ss[ (df_ss['period'] == period) & (df_ss['hostname'] == host) & (df_ss['slice'] == 'ndt') ]\n",
    "            label = 'pdf-%s (%d)' % (period, len(ds['rate_mbps']))\n",
    "            if len(ds) == 0:\n",
    "                continue\n",
    "            r = [math.log10(x) for x in ds['rate_mbps']]\n",
    "            n, bins, patches = axes[i, j].hist(r, int(math.sqrt(len(ds['rate_mbps']))),\n",
    "                                       histtype='step', normed=1, label=label, ls='-')\n",
    "#            n, bins, patches = axes[i, j].hist(ds['rate_mbps'], int(math.sqrt(len(ds['rate_mbps']))),\n",
    "#                               histtype='step', label=label, ls='-')\n",
    "#            n, bins, patches = axes[i, j].hist(ds['rate_mbps'], len(ds['rate_mbps']),\n",
    "#                               histtype='step', normed=1, cumulative=True, label='cdf-' + period,\n",
    "#                               ls='-')\n",
    "\n",
    "        axes[i, j].set_xlim(math.log10(0.1), math.log10(1000))\n",
    "        axes[i, j].set_axisbelow(True)\n",
    "        axes[i, j].legend(loc=2)\n",
    "        axes[i, j].grid(color='#dddddd')\n",
    "        axes[i, j].set_title(host)\n",
    "        axes[i, j].xaxis.set_major_formatter(customFormatter)\n",
    "\n",
    "fig.suptitle('Sidestream Download Rate PDFs over three week period (0w is trial)')\n",
    "plt.show()\n",
    "print len(bins)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Historical (mlab-sandbox.batch) - Sidestream by Period & Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Variations, for each period:\n",
    "# * all sidestream connections from each period.\n",
    "# * all sidestream connections from each period and slice\n",
    "# * all sidestream connections from each period and slice and from same cohort.\n",
    "# * some sidestream connections from each period and slice and from same cohort, grouped by ts & remote_ip.\n",
    "# * some sidestream connections from each period and slice and from same cohort, grouped by only by remote_ip.\n",
    "\n",
    "result = query.sync_query(\n",
    "    \"\"\"#standardSQL                                                                    \n",
    "    -- Only works for mlab1 addresses. May not work on all machines.\n",
    "CREATE TEMPORARY FUNCTION sliceFromIP(ipaddr STRING)\n",
    "    AS ( MOD(CAST(REGEXP_EXTRACT(ipaddr, r'[:.]([0-9]+)$') AS INT64), 64) - 10 );\n",
    "\n",
    "CREATE TEMPORARY FUNCTION betweenTimes(ts INT64, starttime STRING, endtime STRING)\n",
    "    AS ( TIMESTAMP_SECONDS(ts) >= TIMESTAMP(starttime) AND TIMESTAMP_SECONDS(ts) <= TIMESTAMP(endtime) );\n",
    "\n",
    "SELECT\n",
    "    CASE \n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 1 THEN 'ndt'\n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7 THEN 'samknows'\n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7 THEN 'neubot'\n",
    "        ELSE 'other' \n",
    "    END AS slice,\n",
    "    CASE                                                                          \n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2017-07-26 00:00:00\", \"2017-07-30 00:00:00\") THEN '07-26 to 29'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2017-08-12 00:00:00\", \"2017-08-16 00:00:00\") THEN '08-12 to 16'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2017-10-30 00:00:00\", \"2017-11-02 00:00:00\") THEN '10-30 to 11-02'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2017-11-26 00:00:00\", \"2017-12-01 00:00:00\") THEN '11-29 to 12-03'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-21 00:00:00\", \"2018-02-25 00:00:00\") THEN '02-21 to 25'\n",
    "    ELSE 'bad'                                                                    \n",
    "    END AS period,\n",
    "    REGEXP_EXTRACT(test_id, r\"\\d\\d\\d\\d/\\d\\d/\\d\\d/(mlab[1-4].[a-z]{3}[0-9]{2})\") AS hostname,\n",
    "    web100_log_entry.snap.StartTimeStamp AS ts,                                   \n",
    "    8 * (web100_log_entry.snap.HCThruOctetsAcked /                                \n",
    "      (web100_log_entry.snap.SndLimTimeRwin +                                     \n",
    "       web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "       web100_log_entry.snap.SndLimTimeSnd)) as rate_mbps   \n",
    "FROM\n",
    "    `mlab-sandbox.batch.sidestream*`                                              \n",
    "WHERE\n",
    "        (  betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2017-07-26 00:00:00\", \"2017-07-30 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2017-08-12 00:00:00\", \"2017-08-16 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2017-11-26 00:00:00\", \"2017-12-01 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-21 00:00:00\", \"2018-02-25 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2017-10-30 00:00:00\", \"2017-11-02 00:00:00\") )\n",
    "  AND (test_id LIKE '%mlab1.dfw%')            \n",
    "  AND web100_log_entry.snap.HCThruOctetsAcked >= 1000000 -- 819200                          \n",
    "  AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "    web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "    web100_log_entry.snap.SndLimTimeSnd) >= 9000000                             \n",
    "  AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "    web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "    web100_log_entry.snap.SndLimTimeSnd) < 600000000                            \n",
    "  AND (web100_log_entry.snap.State = 1 OR                                       \n",
    "    (web100_log_entry.snap.State >= 5 AND                                       \n",
    "    web100_log_entry.snap.State <= 11))\n",
    "  AND web100_log_entry.connection_spec.remote_ip IN(\n",
    "    (SELECT\n",
    "     remote_ip\n",
    "    FROM (\n",
    "      SELECT\n",
    "         web100_log_entry.connection_spec.remote_ip as remote_ip,\n",
    "         count(*) as c1\n",
    "      FROM\n",
    "         `mlab-sandbox.batch.sidestream*`\n",
    "      WHERE\n",
    "          (test_id LIKE '%mlab1.dfw0%')\n",
    "        AND TIMESTAMP_SECONDS(web100_log_entry.log_time) >= TIMESTAMP(\"2017-08-12 00:00:00\")\n",
    "        AND TIMESTAMP_SECONDS(web100_log_entry.log_time) < TIMESTAMP(\"2017-08-16 00:00:00\")\n",
    "        AND sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7\n",
    "      GROUP BY\n",
    "        remote_ip\n",
    "      HAVING c1 > 10\n",
    "    ) INNER JOIN (\n",
    "      SELECT\n",
    "         web100_log_entry.connection_spec.remote_ip as remote_ip,\n",
    "         count(*) as c2\n",
    "      FROM\n",
    "         `mlab-sandbox.batch.sidestream*`\n",
    "      WHERE\n",
    "          (test_id LIKE '%mlab1.dfw0%')\n",
    "        AND TIMESTAMP_SECONDS(web100_log_entry.log_time) >= TIMESTAMP(\"2017-11-26 00:00:00\")\n",
    "        AND TIMESTAMP_SECONDS(web100_log_entry.log_time) < TIMESTAMP(\"2017-11-30 00:00:00\")\n",
    "        AND sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7\n",
    "      GROUP BY\n",
    "        remote_ip\n",
    "      HAVING c2 > 10\n",
    "    ) USING (remote_ip))\n",
    "  )\n",
    "    \n",
    "GROUP BY\n",
    "  hostname, slice, period, ts, rate_mbps\n",
    "    \"\"\")\n",
    "df_ss = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hosts = [\n",
    "    ['mlab1.dfw02', 'mlab1.dfw03', 'mlab1.dfw04', 'mlab1.dfw05'],\n",
    "    #['mlab1.dfw02', 'mlab1.dfw04', 'mlab1.dfw05'],\n",
    "]\n",
    "\n",
    "periods_list = [\n",
    "    (datetime.datetime(2017,  8, 16), datetime.datetime(2017,  8, 23)),\n",
    "    (datetime.datetime(2017,  8, 23), datetime.datetime(2017,  8, 28)),\n",
    "    (datetime.datetime(2017,  8, 28), datetime.datetime(2017, 11, 22)),\n",
    "    (datetime.datetime(2017, 11, 22), datetime.datetime(2018,  2, 21)),\n",
    "    (datetime.datetime(2018,  2, 21), datetime.datetime(2018,  3,  7)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping (datetime.datetime(2017, 8, 16, 0, 0), datetime.datetime(2017, 8, 23, 0, 0))\n",
      "skipping (datetime.datetime(2017, 8, 23, 0, 0), datetime.datetime(2017, 8, 28, 0, 0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved (datetime.datetime(2017, 8, 23, 0, 0), datetime.datetime(2017, 11, 22, 0, 0)) mlab1.dfw02 981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved (datetime.datetime(2017, 8, 23, 0, 0), datetime.datetime(2017, 11, 22, 0, 0)) mlab1.dfw03 129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved (datetime.datetime(2017, 8, 23, 0, 0), datetime.datetime(2017, 11, 22, 0, 0)) mlab1.dfw04 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved (datetime.datetime(2017, 8, 23, 0, 0), datetime.datetime(2017, 11, 22, 0, 0)) mlab1.dfw05 378\n",
      "skipping (datetime.datetime(2017, 11, 22, 0, 0), datetime.datetime(2018, 2, 21, 0, 0))\n",
      "skipping (datetime.datetime(2018, 2, 21, 0, 0), datetime.datetime(2018, 3, 7, 0, 0))\n"
     ]
    }
   ],
   "source": [
    "def start_and_end(d):\n",
    "    s = d.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    e = (d + datetime.timedelta(days=4)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    return s, e\n",
    "\n",
    "#df_hosts = []\n",
    "for i, periods in enumerate(periods_list):\n",
    "    a_s, a_e = start_and_end(periods[0])\n",
    "    b_s, b_e = start_and_end(periods[1])\n",
    "    #df_hosts.append({})\n",
    "    if i not in [2]:\n",
    "        print 'skipping', periods_list[i]\n",
    "        continue\n",
    "    for host in hosts[0]:\n",
    "        result = query.sync_query(\"\"\"\n",
    "#standardSQL                                                                    \n",
    "    -- Only works for mlab1 addresses. May not work on all machines.\n",
    "CREATE TEMPORARY FUNCTION sliceFromIP(ipaddr STRING)\n",
    "    AS ( MOD(CAST(REGEXP_EXTRACT(ipaddr, r'[:.]([0-9]+)$') AS INT64), 64) - 10 );\n",
    "\n",
    "CREATE TEMPORARY FUNCTION betweenTimes(ts INT64, starttime STRING, endtime STRING)\n",
    "    AS ( TIMESTAMP_SECONDS(ts) >= TIMESTAMP(starttime) AND TIMESTAMP_SECONDS(ts) <= TIMESTAMP(endtime) );\n",
    "\n",
    "SELECT\n",
    "   slice,\n",
    "   period,\n",
    "   hostname,\n",
    "   AVG(rate_mbps) as rate_mbps,\n",
    "   APPROX_QUANTILES(rate_mbps, 101)[ORDINAL(50)] as med_rate_mbps,\n",
    "   MAX(rate_mbps) as max_rate_mbps,\n",
    "   SUM(rate_mbps) as sum_rate_mbps\n",
    "    \n",
    "FROM (\n",
    "\n",
    "SELECT\n",
    "    web100_log_entry.connection_spec.remote_ip as remote_ip,\n",
    "    CASE \n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 1 THEN 'ndt'\n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7 THEN 'samknows'\n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7 THEN 'neubot'\n",
    "        ELSE 'other' \n",
    "    END AS slice,\n",
    "    CASE                                                                          \n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, '\"\"\"+a_s+\"\"\"', '\"\"\"+a_e+\"\"\"')\n",
    "            THEN '\"\"\"+a_s+\"\"\"'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, '\"\"\"+b_s+\"\"\"', '\"\"\"+b_e+\"\"\"')\n",
    "            THEN '\"\"\"+b_s+\"\"\"'\n",
    "    ELSE 'bad'                                                                    \n",
    "    END AS period,\n",
    "    REGEXP_EXTRACT(test_id, r\"\\d\\d\\d\\d/\\d\\d/\\d\\d/(mlab[1-4].[a-z]{3}[0-9]{2})\") AS hostname,\n",
    "    web100_log_entry.snap.StartTimeStamp AS ts,                                   \n",
    "    8 * (web100_log_entry.snap.HCThruOctetsAcked /                                \n",
    "      (web100_log_entry.snap.SndLimTimeRwin +                                     \n",
    "       web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "       web100_log_entry.snap.SndLimTimeSnd)) as rate_mbps   \n",
    "FROM\n",
    "    `mlab-sandbox.batch.sidestream*`                                              \n",
    "WHERE\n",
    "        (  betweenTimes(web100_log_entry.snap.StartTimeStamp, '\"\"\"+a_s+\"\"\"', '\"\"\"+a_e+\"\"\"')\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, '\"\"\"+b_s+\"\"\"', '\"\"\"+b_e+\"\"\"')\n",
    "        )\n",
    "  AND (test_id LIKE '%\"\"\"+host+\"\"\"%')            \n",
    "  AND web100_log_entry.snap.HCThruOctetsAcked >= 1000000 -- 819200                          \n",
    "  AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "    web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "    web100_log_entry.snap.SndLimTimeSnd) >= 9000000                             \n",
    "  AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "    web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "    web100_log_entry.snap.SndLimTimeSnd) < 600000000                            \n",
    "  AND (web100_log_entry.snap.State = 1 OR                                       \n",
    "    (web100_log_entry.snap.State >= 5 AND                                       \n",
    "    web100_log_entry.snap.State <= 11))\n",
    "  AND web100_log_entry.connection_spec.remote_ip IN(\n",
    "    (SELECT\n",
    "     remote_ip\n",
    "    FROM (\n",
    "      SELECT\n",
    "         web100_log_entry.connection_spec.remote_ip as remote_ip,\n",
    "         count(*) as c1\n",
    "      FROM\n",
    "         `mlab-sandbox.batch.sidestream*`\n",
    "      WHERE\n",
    "          (test_id LIKE '%\"\"\"+host+\"\"\"%')\n",
    "        AND betweenTimes(web100_log_entry.snap.StartTimeStamp, '\"\"\"+a_s+\"\"\"', '\"\"\"+a_e+\"\"\"')\n",
    "        AND sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7\n",
    "      GROUP BY\n",
    "        remote_ip\n",
    "      HAVING c1 > 10\n",
    "    ) INNER JOIN (\n",
    "      SELECT\n",
    "         web100_log_entry.connection_spec.remote_ip as remote_ip,\n",
    "         count(*) as c2\n",
    "      FROM\n",
    "         `mlab-sandbox.batch.sidestream*`\n",
    "      WHERE\n",
    "          (test_id LIKE '%\"\"\"+host+\"\"\"%')\n",
    "        AND betweenTimes(web100_log_entry.snap.StartTimeStamp, '\"\"\"+b_s+\"\"\"', '\"\"\"+b_e+\"\"\"')\n",
    "        AND sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7\n",
    "      GROUP BY\n",
    "        remote_ip\n",
    "      HAVING c2 > 10\n",
    "    ) USING (remote_ip))\n",
    "  )\n",
    "    \n",
    "GROUP BY\n",
    "  hostname, slice, period, ts, web100_log_entry.connection_spec.remote_ip, rate_mbps\n",
    ")\n",
    "\n",
    "GROUP BY\n",
    "  hostname, slice, period,   remote_ip -- CAST(ts/4 AS INT64),\n",
    "\"\"\")\n",
    "        df_hosts[i][host] = pd.DataFrame(result)\n",
    "        print 'saved', periods_list[i], host, len(df_hosts[i][host])\n",
    "#df_ss = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sidestream CDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10079 507.5426899233347\n"
     ]
    }
   ],
   "source": [
    "title = 'CDF - per-slice sidestream Download Rate CDFs'\n",
    "print len(df_ss), max(df_ss['rate_mbps']) # 'sqrt', int(math.sqrt(len(df['rate_mbps'])))\n",
    "\n",
    "hosts = [\n",
    "    ['mlab1.dfw02', 'mlab1.dfw03', 'mlab1.dfw04'],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=len(hosts[0]), figsize=(13, 10))\n",
    "\n",
    "for i, host_row in enumerate(hosts):\n",
    "    for j, host in enumerate(host_row):\n",
    "        if len(df_ss[ df_ss['hostname'] == host ]) == 0:\n",
    "            print 'skipping', host\n",
    "            continue\n",
    "        for period in ['08-12 to 16', '11-29 to 12-03', '02-21 to 25']: #set(df['period']):\n",
    "            ds = df_ss[ (df_ss['period'] == period) & (df_ss['hostname'] == host) ]\n",
    "            for k, slicename in enumerate(['ndt', 'samknows']): # set(ds['slice']):\n",
    "                #print 'sqrt', int(math.sqrt(len(ds['rate_mbps'])))\n",
    "                d = ds[ ds['slice'] == slicename ]\n",
    "                if len(d) == 0:\n",
    "                    continue\n",
    "                ax = axes[k, j]\n",
    "                #n, bins, patches = ax.hist(ds['rate_mbps'], len(ds['rate_mbps']),\n",
    "                #                   histtype='step', normed=1, cumulative=True, label='cdf-' + period,\n",
    "                #                   ls='-')\n",
    "                r = [math.log10(x) for x in d['rate_mbps']]\n",
    "                n, bins, patches = ax.hist(d['rate_mbps'], int(math.sqrt(len(d['rate_mbps']))),\n",
    "                                   histtype='step', normed=1, cumulative=True, label=('cdf-' + period + '-' + slicename), \n",
    "                                   ls='-')\n",
    "\n",
    "                ax.set_xlim(1, 200)       \n",
    "                ax.set_axisbelow(True)\n",
    "        #ax.semilogx()\n",
    "                ax.legend(loc=4, fontsize='x-small')\n",
    "\n",
    "                ax.grid(color='#dddddd')\n",
    "                ax.set_title(host)\n",
    "        #labels = ['%.2f' % math.pow(10, float(l)) for l in ax.get_xticks()]\n",
    "        #ax.xaxis.set_major_formatter(customFormatter)\n",
    "        \n",
    "\n",
    "fig.suptitle(title)\n",
    "\n",
    "plt.show()\n",
    "#print n, len(bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sidestream PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10079 507.5426899233347\n"
     ]
    }
   ],
   "source": [
    "title = 'PDF - per-slice sidestream Download Rate PDFs'\n",
    "print len(df_ss), max(df_ss['rate_mbps']) # 'sqrt', int(math.sqrt(len(df['rate_mbps'])))\n",
    "\n",
    "hosts = [\n",
    "    ['mlab1.dfw02', 'mlab1.dfw03', 'mlab1.dfw04'],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=len(hosts[0]), figsize=(13, 10))\n",
    "for i, host_row in enumerate(hosts):\n",
    "    for j, host in enumerate(host_row):\n",
    "        if len(df_ss[ df_ss['hostname'] == host ]) == 0:\n",
    "            print 'skipping', host\n",
    "            continue\n",
    "        for period in ['08-12 to 16', '02-21 to 25']: # '11-29 to 12-03',  #set(df['period']):\n",
    "            ds = df_ss[ (df_ss['period'] == period) & (df_ss['hostname'] == host) ]\n",
    "            for k, slicename in enumerate(['ndt', 'samknows']): # set(ds['slice']):\n",
    "                #print 'sqrt', int(math.sqrt(len(ds['rate_mbps'])))\n",
    "                d = ds[ ds['slice'] == slicename ]\n",
    "                if len(d) == 0:\n",
    "                    continue\n",
    "                ax = axes[k, j]\n",
    "\n",
    "                label = 'pdf-%s-%s (%d)' % (period, slicename, len(d['rate_mbps']))\n",
    "                r = [math.log10(x) for x in d['rate_mbps']]\n",
    "                n, bins, patches = ax.hist(r, int(math.sqrt(len(d['rate_mbps']))),\n",
    "                                   histtype='step', normed=1, label=label, \n",
    "                                   ls='-')\n",
    "\n",
    "                #ax.set_xlim(1, 200)       \n",
    "                #ax.semilogx()\n",
    "                #ax.set_ylim(0, 1.4)\n",
    "                ax.set_axisbelow(True)\n",
    "                ax.legend(loc=2, fontsize='x-small')\n",
    "\n",
    "                ax.grid(color='#dddddd')\n",
    "                ax.set_title(host)\n",
    "                ax.xaxis.set_major_formatter(customFormatter)\n",
    "        \n",
    "fig.suptitle(title)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF, CDF, & Switch - by Site and Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title = 'PDF, CDF, Switch - per-slice sidestream Download Rates'\n",
    "#print len(df_ss), max(df_ss['rate_mbps']) # 'sqrt', int(math.sqrt(len(df['rate_mbps'])))\n",
    "\n",
    "d = None\n",
    "df=None\n",
    "label2date = {}\n",
    "slices = ['samknows', 'ndt']\n",
    "slices = ['samknows']\n",
    "for i, host_row in enumerate(hosts):\n",
    "    for j, host in enumerate(host_row):\n",
    "        fig, axes = plt.subplots(nrows=3, ncols=len(periods_list), figsize=(16, 10))\n",
    "        \n",
    "        for p, times in enumerate(periods_list):\n",
    "            for k, slicename in enumerate(slices):\n",
    "                \n",
    "                df_ss = df_hosts[p][host]\n",
    "                if len(df_ss) == 0:\n",
    "                    print 'skipping', host, 'no data'\n",
    "                    continue\n",
    "                if len(df_ss[ df_ss['hostname'] == host ]) == 0:\n",
    "                    print 'skipping', host\n",
    "                    continue\n",
    "                for period in times: # '08-12 to 16', '11-29 to 12-03',  set(df['period']):\n",
    "                #for period in [ '02-21 to 25', '03-02 to 06' ]:\n",
    "                # for period in [ '08-12 to 16','11-29 to 12-03', '02-21 to 25', '03-02 to 06']: # '08-12 to 16', '11-29 to 12-03',  set(df['period']):\n",
    "                    period_str = period.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    ds = df_ss[ (df_ss['period'] == period_str) &\n",
    "                                (df_ss['hostname'] == host) &\n",
    "                                (df_ss['slice'] == slicename) ]\n",
    "\n",
    "                    if len(ds) == 0:\n",
    "                        continue\n",
    "\n",
    "                    # Top\n",
    "                    ax = axes[0, p]\n",
    "                    r = [math.log10(x) for x in ds['rate_mbps']]\n",
    "                    label = 'pdf-%s-%s (%d)' % (period_str, slicename, len(ds['rate_mbps']))\n",
    "                    label2date[label] = period\n",
    "                    n, bins, patches = ax.hist(r, int(math.sqrt(len(ds['rate_mbps']))) * 2,\n",
    "                                   histtype='step', normed=1, label=label, ls='-')\n",
    "\n",
    "                    #ax.set_xlim(1, 100)\n",
    "                    ax.set_axisbelow(True)\n",
    "\n",
    "                \n",
    "                    ax.legend(fontsize='x-small', loc='upper center', bbox_to_anchor=(0.5, 1.3))\n",
    "                    ax.grid(color='#dddddd')\n",
    "                    ax.set_title(host)\n",
    "                    labels = ['%.2f' % math.pow(10, float(l)) for l in ax.get_xticks()]\n",
    "                    ax.xaxis.set_major_formatter(customFormatter)\n",
    "                    #ax.semilogx()\n",
    "\n",
    "                    # Middle\n",
    "                    ax = axes[1, p]\n",
    "                    label = 'cdf-%s-%s (%d)' % (period, slicename, len(ds['rate_mbps']))\n",
    "                    use_log = True\n",
    "                    if use_log:\n",
    "                        r = [math.log10(x) for x in ds['rate_mbps']]\n",
    "                        n, bins, patches = ax.hist(r, len(ds['rate_mbps']), # ds['rate_mbps']\n",
    "                                               histtype='step', normed=1, cumulative=True, label=label, ls='-')\n",
    "                        ax.xaxis.set_major_formatter(customFormatter)\n",
    "\n",
    "                    else:\n",
    "                        n, bins, patches = ax.hist(ds['rate_mbps'], len(ds['rate_mbps']),\n",
    "                                       histtype='step', normed=1, cumulative=True, label=label, ls='-')\n",
    "                        ax.set_xlim(-1, 200)\n",
    "\n",
    "                    #ax.semilogx()\n",
    "\n",
    "                    ax.set_axisbelow(True)\n",
    "                    #ax.legend(loc=3, fontsize='x-small') # , loc='upper center', bbox_to_anchor=(0.5, 1.1))\n",
    "                    ax.grid(color='#dddddd')\n",
    "                    ax.set_title(host)\n",
    "\n",
    "    #for i, host_row in enumerate(hosts):\n",
    "    #    for j, host in enumerate(host_row):\n",
    "            ax = axes[2, p]\n",
    "        \n",
    "            ds = df_disco[ df_disco['hostname'] == host ]\n",
    "            ax.plot_date(dates.epoch2num(ds['ts']), ds['pct_discards'], ls='-', ms=0, label=host)\n",
    "        \n",
    "            ax.set_title(host)\n",
    "            ax.set_ylim(-0.01, 1)\n",
    "            ax.tick_params(axis='x', labelrotation=90)\n",
    "            ax.grid(color='#dddddd')\n",
    "            #ax.legend(loc=4, fontsize='x-small') \n",
    " \n",
    "            # Color switch regions with the PDF periods based on legend colors.\n",
    "            h, l = axes[0, p].get_legend_handles_labels()\n",
    "            for k, line in enumerate(h):\n",
    "                # print h[k], l[k]\n",
    "                s = label2date[l[k]]\n",
    "                e = s + datetime.timedelta(days=4)\n",
    "                color = h[k].get_edgecolor()\n",
    "                # print s, e\n",
    "\n",
    "                ax.axvspan(dates.date2num(s), dates.date2num(e), alpha=0.5, color=color)\n",
    "            \n",
    "\n",
    "     \n",
    "        axes[0, 0].set_ylabel('PDF')\n",
    "        axes[1, 0].set_ylabel('CDF')\n",
    "        axes[2, 0].set_ylabel('% discard timebins')    \n",
    "\n",
    "        fig.suptitle(title + ('\\n%s' % [period.strftime(\"%Y-%m-%d %H:%M:%S\") for period in times]))\n",
    "        plt.show()\n",
    "\n",
    "#plt.hist2d(\n",
    "#    df_ss[ (df_ss['period'] == '08-12 to 16') & (df_ss['hostname'] == 'mlab1.dfw02') & (df_ss['slice'] == 'samknows') ],\n",
    "#    df_ss[ (df_ss['period'] == '02-21 to 25') & (df_ss['hostname'] == 'mlab1.dfw02') & (df_ss['slice'] == 'samknows') ],\n",
    "#    bins=40,\n",
    "#)\n",
    "#print n, len(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def dt(date):\n",
    "    return datetime.strptime(date, '%Y-%m-%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
