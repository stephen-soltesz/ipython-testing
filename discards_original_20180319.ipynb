{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "# Enables figures loading outside of browser.\n",
    "# If not run, figures will load inline.\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "import datetime\n",
    "import collections\n",
    "\n",
    "# Some matplotlib features are version dependent.\n",
    "assert(matplotlib.__version__ >= '2.1.2')\n",
    "\n",
    "# Depends on: pip install --upgrade google-cloud-bigquery\n",
    "import query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unlog(x, pos):\n",
    "    v = math.pow(10, x)\n",
    "    frac, whole = math.modf(v)\n",
    "    if frac > 0:\n",
    "        return '%.1f' % v\n",
    "    else:\n",
    "        return '%d' % whole\n",
    "\n",
    "logFormatter = matplotlib.ticker.FuncFormatter(unlog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = query.sync_query(\"\"\"\n",
    "#standardSQL\n",
    "SELECT\n",
    "  name AS hostname,\n",
    "  FORMAT_TIMESTAMP(\"%Y-%m-%d\", TIMESTAMP_TRUNC(sts, DAY)) AS day,\n",
    "  UNIX_SECONDS(TIMESTAMP_TRUNC(sts, DAY)) AS ts,\n",
    "  SUM(IF(metric = 'switch.discards.uplink.tx', value, 0)) AS total_discards,\n",
    "  SUM(IF(metric = 'switch.unicast.uplink.tx', value, 0)) AS total_packets,\n",
    "  SUM(IF(metric = 'switch.octets.uplink.tx', value, 0)) AS total_bytes,\n",
    "  COUNTIF(metric = 'switch.discards.uplink.tx' AND value > 0) / 8640 AS pct_discards\n",
    "\n",
    "FROM (\n",
    "  SELECT\n",
    "    metric,\n",
    "    REGEXP_EXTRACT(hostname, r'(mlab[1-4].[a-z]{3}[0-9]{2}).*') AS name,\n",
    "    sample.timestamp AS sts,\n",
    "    sample.value AS value\n",
    "  FROM\n",
    "    `mlab-sandbox.base_tables.switch*`,\n",
    "    UNNEST(sample) AS sample\n",
    "  WHERE\n",
    "       metric LIKE 'switch.discards.uplink.tx'\n",
    "    OR metric LIKE 'switch.unicast.uplink.tx'\n",
    "    OR metric LIKE 'switch.octets.uplink.tx'\n",
    "  GROUP BY\n",
    "    hostname, metric, sts, value\n",
    ")\n",
    "WHERE\n",
    "  name IS NOT NULL\n",
    "GROUP BY\n",
    "  hostname, day, ts\n",
    "ORDER BY\n",
    "  hostname, day, ts\n",
    "\"\"\")\n",
    "\n",
    "df_disco = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DISCO RATES 90th PERCENTILE\n",
    "\n",
    "result = query.sync_query(\"\"\"\n",
    "#standardSQL\n",
    "SELECT\n",
    "  name AS hostname,\n",
    "  FORMAT_TIMESTAMP(\"%Y-%m-%d\", TIMESTAMP_TRUNC(sts, DAY)) AS day,\n",
    "  UNIX_SECONDS(TIMESTAMP_TRUNC(sts, DAY)) AS ts,\n",
    "  \n",
    "  APPROX_QUANTILES(value, 101)[ORDINAL(50)] as bytes_50th,\n",
    "  APPROX_QUANTILES(value, 101)[ORDINAL(90)] as bytes_90th,\n",
    "  APPROX_QUANTILES(value, 101)[ORDINAL(98)] as bytes_98th,\n",
    "  APPROX_QUANTILES(value, 101)[ORDINAL(99)] as bytes_99th,\n",
    "  MAX(value) as bytes_max\n",
    "\n",
    "FROM (\n",
    "  SELECT\n",
    "    metric,\n",
    "    REGEXP_EXTRACT(hostname, r'(mlab[1-4].[a-z]{3}[0-9]{2}).*') AS name,\n",
    "    sample.timestamp AS sts,\n",
    "    sample.value AS value\n",
    "  FROM\n",
    "    `mlab-sandbox.base_tables.switch*`,\n",
    "    UNNEST(sample) AS sample\n",
    "  WHERE\n",
    "    metric LIKE 'switch.octets.uplink.tx'\n",
    "  GROUP BY\n",
    "    hostname, metric, sts, value\n",
    ")\n",
    "WHERE\n",
    "  name IS NOT NULL\n",
    "GROUP BY\n",
    "  hostname, day, ts\n",
    "ORDER BY\n",
    "  hostname, day, ts\n",
    "\"\"\")\n",
    "\n",
    "df_disco_max = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discards over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0.98,'Discards over time')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites = [\n",
    "    ['dfw', 'lga', 'iad'],\n",
    "    ['sea', 'atl', 'den'],\n",
    "    ['mia', 'nuq', 'ord'],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(12, 10))\n",
    "for i, site_row in enumerate(sites):\n",
    "    for j, site in enumerate(site_row):\n",
    "        if j != 0:\n",
    "            axes[i, j].set_yticklabels([])\n",
    "        if i != len(sites)-1:\n",
    "            axes[i, j].set_xticklabels([])\n",
    "        for h in set(df_disco['hostname']):\n",
    "            if ('mlab1.' + site) in h:\n",
    "                ds = df_disco[ (df_disco['hostname'] == h) & (df_disco['total_discards'] > 100)& (df_disco['total_discards'] < 1000000)]\n",
    "                axes[i, j].plot_date(dates.epoch2num(ds['ts']), ds['total_discards'], ls='-', ms=0, label=h[6:11])\n",
    "\n",
    "        axes[i, j].set_title(site)\n",
    "        axes[i, j].set_ylim(100, 1000000)\n",
    "        axes[i, j].tick_params(axis='x', labelrotation=90)\n",
    "        axes[i, j].grid(color='#dddddd')\n",
    "        axes[i, j].legend(loc=4, fontsize='x-small')\n",
    "        axes[i, j].semilogy()\n",
    "        \n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.4)\n",
    "fig.suptitle('Discards over time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avg Daily Rate over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0.98,'Daily Avg Rate over time')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites = [\n",
    "    ['dfw', 'lga', 'iad'],\n",
    "    ['sea', 'atl', 'den'],\n",
    "    ['mia', 'nuq', 'ord'],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(12, 10))\n",
    "for i, site_row in enumerate(sites):\n",
    "    for j, site in enumerate(site_row):\n",
    "        if j != 0:\n",
    "            axes[i, j].set_yticklabels([])\n",
    "        if i != len(sites)-1:\n",
    "            axes[i, j].set_xticklabels([])\n",
    "        for h in set(df_disco['hostname']):\n",
    "            if ('mlab1.' + site) in h:\n",
    "                ds = df_disco[ (df_disco['hostname'] == h) ] # & (df_disco['total_discards'] > 100)& (df_disco['total_discards'] < 1000000)]\n",
    "                axes[i, j].plot_date(dates.epoch2num(ds['ts']), ds['total_bytes'] / 1000000 / 86400, ls='-', ms=0, label=h[6:11])\n",
    "\n",
    "        axes[i, j].set_title(site)\n",
    "        axes[i, j].set_ylim(1, 1000)\n",
    "        axes[i, j].tick_params(axis='x', labelrotation=90)\n",
    "        axes[i, j].grid(color='#dddddd')\n",
    "        axes[i, j].legend(loc=2, fontsize='x-small', ncol=3)\n",
    "        axes[i, j].semilogy()\n",
    "        \n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.4)\n",
    "fig.suptitle('Daily Avg Rate over time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 90th Percentile Over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sites = [\n",
    "    ['dfw', 'lga', 'iad'],\n",
    "    ['lax', 'atl', 'den'],\n",
    "    ['sea', 'nuq', 'ord'], # MIA is low utilization.\n",
    "]\n",
    "\n",
    "sites = [\n",
    "    ['dfw', 'lga', 'iad'],\n",
    "    ['lax', 'atl',  'nuq'], #  'ord', # MIA is low utilization. 'den', 'sea' low enough.\n",
    "]\n",
    "\n",
    "cols = len(sites[0])\n",
    "fig = plt.figure(figsize=(4 * cols, 6))\n",
    "axes = [\n",
    "    [None] * cols,\n",
    "    [None] * cols,\n",
    "    #[None] * cols,\n",
    "]\n",
    "\n",
    "for r, siter in enumerate(sites):\n",
    "    for c, site in enumerate(siter):\n",
    "        for x, rate in enumerate(['98th']):\n",
    "            axes[r][c] = plt.subplot2grid((2, cols), (r, c))\n",
    "            if c != 0:\n",
    "                axes[r][c].set_yticklabels([])\n",
    "            else:\n",
    "                axes[r][c].set_ylabel('Mbps')\n",
    "\n",
    "            if r != 1:\n",
    "                axes[r][c].set_xticklabels([])\n",
    "\n",
    "            prefix = 'mlab1.' + site\n",
    "            ds_sites = df_disco_max[ df_disco_max['hostname'].str.contains(prefix) ]\n",
    "            for h in sorted(set(ds_sites[ ds_sites['hostname'].str.contains(prefix) ]['hostname'])):\n",
    "                ds = ds_sites[ (ds_sites['hostname'].str.contains(h)) ]\n",
    "                axes[r][c].plot_date(dates.epoch2num(ds['ts']), ds['bytes_' + rate] * 8 / 10000000, ls='-', ms=0, label=h[6:11] + '-' +  rate)\n",
    "\n",
    "            axes[r][c].set_title(site)\n",
    "            axes[r][c].set_ylim(100, 1000)\n",
    "            axes[r][c].tick_params(axis='x', labelrotation=90)\n",
    "            axes[r][c].grid(color='#dddddd')\n",
    "            axes[r][c].legend(loc=2, fontsize='x-small', ncol=2)\n",
    "\n",
    "fig.suptitle('Daily Percentile Rates')\n",
    "#fig.tight_layout()\n",
    "#fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SS COUNTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [ 'lga', nuq'], #  'ord', # MIA is low utilization. 'den', 'sea' low enough.\n",
    "\n",
    "sites = [\n",
    "    ['dfw', 'iad', 'lax', 'atl', 'lga'],\n",
    "]\n",
    "\n",
    "cols = len(sites[0])\n",
    "fig = plt.figure(figsize=(4 * cols, 6))\n",
    "axes = [\n",
    "    [None] * cols,\n",
    "    [None] * cols,\n",
    "]\n",
    "\n",
    "for r, siter in enumerate(sites):\n",
    "    for c, site in enumerate(siter):\n",
    "        for x, rate in enumerate(['98th']):\n",
    "            r = 1\n",
    "            axes[r][c] = plt.subplot2grid((2, cols), (r, c))\n",
    "            if c != 0:\n",
    "                #axes[r][c].set_yticklabels([])\n",
    "                pass\n",
    "            else:\n",
    "                axes[r][c].set_ylabel('Connection Counts')\n",
    "\n",
    "            if r != 1:\n",
    "                axes[r][c].set_xticklabels([])\n",
    "\n",
    "            prefix = 'mlab1.' + site\n",
    "            ds_sites = df_ss_count[ df_ss_count['hostname'].str.contains(prefix) ]\n",
    "            for h in sorted(set(ds_sites[ ds_sites['hostname'].str.contains(prefix) ]['hostname'])):\n",
    "                ds = ds_sites[ (ds_sites['hostname'].str.contains(h)) ]\n",
    "                axes[r][c].plot_date(dates.epoch2num(ds['ts']), ds['count'], ls='-', ms=0, label=h[6:11])\n",
    "\n",
    "            axes[r][c].set_title(site)\n",
    "            axes[r][c].set_ylim(0, 25000)\n",
    "            axes[r][c].tick_params(axis='x', labelrotation=90)\n",
    "            axes[r][c].grid(color='#dddddd')\n",
    "            axes[r][c].legend(loc=2, fontsize='x-small', ncol=2)\n",
    "            \n",
    "    for c, site in enumerate(siter):\n",
    "        for r in [0]:\n",
    "            axes[r][c] = plt.subplot2grid((2, cols), (r, c))\n",
    "            if c != 0:\n",
    "                axes[r][c].set_yticklabels([])\n",
    "            else:\n",
    "                axes[r][c].set_ylabel('Mbps')\n",
    "\n",
    "            if r != 1:\n",
    "                axes[r][c].set_xticklabels([])\n",
    "\n",
    "            prefix = 'mlab1.' + site\n",
    "            ds_sites = df_disco_max[ df_disco_max['hostname'].str.contains(prefix) ]\n",
    "            for h in sorted(set(ds_sites[ ds_sites['hostname'].str.contains(prefix) ]['hostname'])):\n",
    "                ds = ds_sites[ (ds_sites['hostname'].str.contains(h)) ]\n",
    "                axes[r][c].plot_date(dates.epoch2num(ds['ts']), ds['bytes_' + rate] * 8 / 10000000, ls='-', ms=0, label=h[6:11] + '-' +  rate)\n",
    "\n",
    "            axes[r][c].set_title(site)\n",
    "            axes[r][c].set_ylim(100, 1000)\n",
    "            axes[r][c].tick_params(axis='x', labelrotation=90)\n",
    "            axes[r][c].grid(color='#dddddd')\n",
    "            axes[r][c].legend(loc=2, fontsize='x-small', ncol=2)\n",
    "\n",
    "fig.suptitle('Daily 98th Percentile Switch Traffic & TCP Connection Counts Per Metro')\n",
    "#fig.tight_layout()\n",
    "#fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([u'mlab1.dfw06', u'mlab1.dfw05', u'mlab1.dfw04', u'mlab1.dfw03', u'mlab1.dfw02', u'mlab1.dfw01'])\n"
     ]
    }
   ],
   "source": [
    "print set(df_disco_max[df_disco_max['hostname'].str.contains('mlab1.dfw')]['hostname'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percent of Timebins with Discards "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0.98,u'Daily percentage of timebins with any discards')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = 'Daily percentage of timebins with any discards'\n",
    "sites = [\n",
    "    ['mlab1.dfw02', 'mlab1.dfw03', 'mlab1.dfw04'],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(sites[0]))\n",
    "for i, hosts in enumerate(sites):\n",
    "    for j, host in enumerate(hosts): \n",
    "        ax = axes[j]\n",
    "        \n",
    "        ds = df_disco[ df_disco['hostname'] == host ]\n",
    "        ax.plot_date(dates.epoch2num(ds['ts']), ds['pct_discards'], ls='-', ms=0, label=host)\n",
    "        \n",
    "        ax.set_title(host)\n",
    "        ax.set_ylim(-0.01, .4)\n",
    "        ax.tick_params(axis='x', labelrotation=90)\n",
    "        ax.grid(color='#dddddd')\n",
    "        ax.legend(loc=4, fontsize='x-small')\n",
    "        \n",
    "        \n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.4)\n",
    "fig.suptitle(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Packets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0.98,u'Daily percentage of timebins with any discards')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = 'Daily percentage of timebins with any discards'\n",
    "sites = [\n",
    "    ['mlab1.dfw02', 'mlab1.dfw03', 'mlab1.dfw04'],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(sites[0]))\n",
    "for i, hosts in enumerate(sites):\n",
    "    for j, host in enumerate(hosts): \n",
    "        ax = axes[j]\n",
    "        \n",
    "        ds = df_disco[ df_disco['hostname'] == host ]\n",
    "        ax.plot_date(dates.epoch2num(ds['ts']), ds['total_packets'], ls='-', ms=0, label=host)\n",
    "        \n",
    "        ax.set_title(host)\n",
    "        #ax.set_ylim(-0.01, .4)\n",
    "        ax.tick_params(axis='x', labelrotation=90)\n",
    "        ax.grid(color='#dddddd')\n",
    "        ax.legend(loc=4, fontsize='x-small')\n",
    "        \n",
    "        \n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.4)\n",
    "fig.suptitle(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Packet Discard Ratios (Switch Loss Rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0.98,u'Switch Packet Loss Rate')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites = [\n",
    "    ['dfw', 'lga', 'iad'],\n",
    "    ['sea', 'atl', 'den'],\n",
    "    ['mia', 'nuq', 'ord'],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(12, 10))\n",
    "for i, site_row in enumerate(sites):\n",
    "    for j, site in enumerate(site_row):\n",
    "        axes[i, j].set_title(site)\n",
    "        if j != 0:\n",
    "            axes[i, j].set_yticklabels([])\n",
    "        if i != len(sites)-1:\n",
    "            axes[i, j].set_xticklabels([])\n",
    "        if j == 0:\n",
    "            axes[i, j].set_ylabel('Daily Loss Ratio')\n",
    "\n",
    "        for h in set(df_disco['hostname']):\n",
    "            if 'mlab1.' + site in h:\n",
    "                ds = df_disco[ (df_disco['hostname'] == h) &\n",
    "                               (df_disco['total_discards'] > 100) &\n",
    "                               (df_disco['total_discards'] < 1000000) ]\n",
    "                ratio = ds['total_discards'] / ds['total_packets']\n",
    "                axes[i, j].plot_date(dates.epoch2num(ds['ts']), ratio, ls='-', ms=0, label=h[:11])\n",
    "        axes[i, j].set_ylim(10**-6, 10**-3)\n",
    "        axes[i, j].tick_params(axis='x', labelrotation=90)\n",
    "        axes[i, j].grid(color='#dddddd')\n",
    "        axes[i, j].legend(loc=4, fontsize='x-small')\n",
    "        axes[i, j].semilogy()\n",
    "        \n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.4)\n",
    "fig.suptitle('Switch Packet Loss Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Flow-Control Trial (measurement-lab.public)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cat sidestream.sql | bq query --format=csv --max_rows=1000000 --nouse_legacy_sql > sidestream-trial-6w.csv\n",
    "#df = pd.read_csv('sidestream-trial-6w.csv')\n",
    "\n",
    "result = query.sync_query(\"\"\"\n",
    "#standardSQL                                                                    \n",
    "    -- Only works for mlab1 addresses. May not work on all machines.\n",
    "CREATE TEMPORARY FUNCTION sliceFromIP(ipaddr STRING)\n",
    "    AS ( MOD(CAST(REGEXP_EXTRACT(ipaddr, r'[:.]([0-9]+)$') AS INT64), 64) - 10 );\n",
    "\n",
    "CREATE TEMPORARY FUNCTION betweenTimes(ts INT64, starttime STRING, endtime STRING)\n",
    "    AS ( TIMESTAMP_SECONDS(ts) >= TIMESTAMP(starttime) AND TIMESTAMP_SECONDS(ts) <= TIMESTAMP(endtime) );\n",
    "\n",
    "SELECT\n",
    "    CASE \n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 1 THEN 'ndt'\n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7 THEN 'samknows'\n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 9 THEN 'neubot'\n",
    "        ELSE 'other' \n",
    "    END AS slice,\n",
    "    CASE\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-01-26 00:00:00\", \"2018-01-27 00:00:00\") THEN '5w'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-02 00:00:00\", \"2018-02-03 00:00:00\") THEN '4w'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-09 00:00:00\", \"2018-02-10 00:00:00\") THEN '3w'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-16 00:00:00\", \"2018-02-17 00:00:00\") THEN '2w'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-23 00:00:00\", \"2018-02-24 00:00:00\") THEN '1w'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-03-02 00:00:00\", \"2018-03-03 00:00:00\") THEN '0w'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-03-09 00:00:00\", \"2018-03-10 00:00:00\") THEN '+1w'\n",
    "    ELSE 'unknown'                                                                    \n",
    "    END AS period,\n",
    "    REGEXP_EXTRACT(test_id, r\"\\d\\d\\d\\d/\\d\\d/\\d\\d/(mlab[1-4].[a-z]{3}[0-9]{2})\") AS hostname,\n",
    "    web100_log_entry.snap.StartTimeStamp AS ts,                                   \n",
    "    8 * (web100_log_entry.snap.HCThruOctetsAcked /                                \n",
    "      (web100_log_entry.snap.SndLimTimeRwin +                                     \n",
    "       web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "       web100_log_entry.snap.SndLimTimeSnd)) as rate_mbps   \n",
    "FROM\n",
    "   -- `measurement-lab.public.sidestream`\n",
    "   -- `mlab-sandbox.batch.sidestream*`\n",
    "    `mlab-sandbox.gfr.sidestream_*`\n",
    "WHERE\n",
    "        (  betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-01-26 00:00:00\", \"2018-01-27 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-02 00:00:00\", \"2018-02-03 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-09 00:00:00\", \"2018-02-10 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-16 00:00:00\", \"2018-02-17 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-23 00:00:00\", \"2018-02-24 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-03-02 00:00:00\", \"2018-03-03 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-03-09 00:00:00\", \"2018-03-10 00:00:00\")\n",
    "        )\n",
    "  AND REGEXP_CONTAINS(test_id, r\"mlab1.(dfw\\d\\d)\")\n",
    "  AND web100_log_entry.snap.HCThruOctetsAcked >= 1000000 -- 819200                          \n",
    "  AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "    web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "    web100_log_entry.snap.SndLimTimeSnd) >= 9000000                             \n",
    "  AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "    web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "    web100_log_entry.snap.SndLimTimeSnd) < 600000000                            \n",
    "  AND (web100_log_entry.snap.State = 1 OR                                       \n",
    "    (web100_log_entry.snap.State >= 5 AND                                       \n",
    "    web100_log_entry.snap.State <= 11))\n",
    "    \n",
    "GROUP BY\n",
    "  hostname, slice, period, ts, rate_mbps\n",
    "\"\"\")\n",
    "df_ss_trial = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    }
   ],
   "source": [
    "result = query.sync_query(\"\"\"\n",
    "\n",
    "CREATE TEMPORARY FUNCTION betweenTimes(ts INT64, starttime STRING, endtime STRING)\n",
    "    AS ( TIMESTAMP_SECONDS(ts) >= TIMESTAMP(starttime) AND TIMESTAMP_SECONDS(ts) <= TIMESTAMP(endtime) );\n",
    "\n",
    "SELECT\n",
    "CASE\n",
    "WHEN betweenTimes(StartTimeStamp, \"2018-02-16 00:00:00\", \"2018-02-17 00:00:00\") THEN CONCAT(sitename, '-2w')\n",
    "WHEN betweenTimes(StartTimeStamp, \"2018-02-23 00:00:00\", \"2018-02-24 00:00:00\") THEN CONCAT(sitename, '-1w')\n",
    "WHEN betweenTimes(StartTimeStamp, \"2018-03-02 00:00:00\", \"2018-03-03 00:00:00\") THEN CONCAT(sitename, '-0w (flow)')\n",
    "ELSE 'unknown'\n",
    "END AS test_period,\n",
    "\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(10)], 2) as q10,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(12)], 2) as q12,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(15)], 2) as q15,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(18)], 2) as q18,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(20)], 2) as q20,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(22)], 2) as q22,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(25)], 2) as q25,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(28)], 2) as q28,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(30)], 2) as q30,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(32)], 2) as q32,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(35)], 2) as q35,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(38)], 2) as q38,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(40)], 2) as q40,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(42)], 2) as q42,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(45)], 2) as q45,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(48)], 2) as q48,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(50)], 2) as q50,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(52)], 2) as q52,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(55)], 2) as q55,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(58)], 2) as q58,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(60)], 2) as q60,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(62)], 2) as q62,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(65)], 2) as q65,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(68)], 2) as q68,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(70)], 2) as q70,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(72)], 2) as q72,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(75)], 2) as q75,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(78)], 2) as q78,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(80)], 2) as q80,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(82)], 2) as q82,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(85)], 2) as q85,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(88)], 2) as q88,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(90)], 2) as q90,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(92)], 2) as q92,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(95)], 2) as q95,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(98)], 2) as q98,\n",
    "round(APPROX_QUANTILES(rate_mbps, 101) [ORDINAL(100)], 2) as q100,\n",
    "COUNT(*) as sample_count\n",
    "\n",
    "FROM\n",
    "(\n",
    "SELECT\n",
    "    UNIX_SECONDS(TIMESTAMP_TRUNC(log_time, DAY)) as StartTimeStamp,\n",
    "    --  web100_log_entry.snap.StartTimeStamp as StartTimeStamp,\n",
    "    REGEXP_EXTRACT(test_id, r\"\\d\\d\\d\\d/\\d\\d/[0-9]+/mlab1.(dfw02|lga03)/.*\") AS sitename,\n",
    "    8 * (\n",
    "        web100_log_entry.snap.HCThruOctetsAcked / (\n",
    "        web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd)\n",
    "    ) AS rate_mbps\n",
    "FROM\n",
    "    -- `mlab-sandbox.batch.sidestream*`\n",
    "     `mlab-sandbox.gfr.sidestream_*`\n",
    "WHERE\n",
    "\n",
    "    REGEXP_CONTAINS(test_id, r\"\\d\\d\\d\\d/\\d\\d/[0-9]+/mlab1.(dfw02|lga03)/.*\")\n",
    "    AND (\n",
    "             betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-16 00:00:00\", \"2018-02-17 00:00:00\")\n",
    "          OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-23 00:00:00\", \"2018-02-24 00:00:00\")\n",
    "          OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-03-02 00:00:00\", \"2018-03-03 00:00:00\"))\n",
    "    AND web100_log_entry.snap.HCThruOctetsAcked >= 819200\n",
    "    AND ( web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) >= 9000000\n",
    "    AND ( web100_log_entry.snap.SndLimTimeRwin + web100_log_entry.snap.SndLimTimeCwnd + web100_log_entry.snap.SndLimTimeSnd) < 600000000\n",
    "    AND ( web100_log_entry.snap.State = 1 OR ( web100_log_entry.snap.State >= 5 AND web100_log_entry.snap.State <= 11))\n",
    ")\n",
    "GROUP BY\n",
    "    sitename, test_period\n",
    "ORDER BY\n",
    "    sitename, test_period\n",
    "\"\"\")\n",
    "df_ss_trial_pct = pd.DataFrame(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "cols = df_ss_trial_pct['test_period']\n",
    "n = df_ss_trial_pct.drop(['q100', 'sample_count', 'test_period'], axis=1)\n",
    "\n",
    "t= n.transpose()\n",
    "t.columns = cols\n",
    "\n",
    "lines = []\n",
    "for row in cols:\n",
    "    lines.append((t[row], row))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(11,6))\n",
    "\n",
    "#print lines\n",
    "for l, label in lines:\n",
    "    x = [v[1:] for v in list(n.keys())]\n",
    "    axes.plot(x, l, label=label)\n",
    "\n",
    "#axes.set_xticklabels(list(n.keys()))\n",
    "axes.legend(loc=2)\n",
    "axes.set_ylabel('Mbps')\n",
    "axes.set_xlabel('Percentiles')\n",
    "axes.grid(color='#dddddd')\n",
    "fig.suptitle('Sidestream comparing Flow-control trial to earlier periods')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "730671 1303.9458692 854\n",
      "94\n"
     ]
    }
   ],
   "source": [
    "print len(df_ss), max(df_ss['rate_mbps']), int(math.sqrt(len(df_ss['rate_mbps'])))\n",
    "\n",
    "hosts = [\n",
    "    ['mlab1.lga03', 'mlab1.lga04'],\n",
    "    ['mlab1.lga05', 'mlab1.lga06'],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "for i, host_row in enumerate(hosts):\n",
    "    for j, host in enumerate(host_row):\n",
    "        for period in ['+1w', '0w', '1w', '2w', '3w']: #, '4w', '5w']:\n",
    "            ds = df_ss[ (df_ss['period'] == period) & (df_ss['hostname'] == host) & (df_ss['slice'] == 'ndt') ]\n",
    "            label = 'pdf-%s (%d)' % (period, len(ds['rate_mbps']))\n",
    "            if len(ds) == 0:\n",
    "                continue\n",
    "            r = [math.log10(x) for x in ds['rate_mbps']]\n",
    "            n, bins, patches = axes[i, j].hist(r, int(math.sqrt(len(ds['rate_mbps']))),\n",
    "                                       histtype='step', normed=1, label=label, ls='-')\n",
    "#            n, bins, patches = axes[i, j].hist(ds['rate_mbps'], int(math.sqrt(len(ds['rate_mbps']))),\n",
    "#                               histtype='step', label=label, ls='-')\n",
    "#            n, bins, patches = axes[i, j].hist(ds['rate_mbps'], len(ds['rate_mbps']),\n",
    "#                               histtype='step', normed=1, cumulative=True, label='cdf-' + period,\n",
    "#                               ls='-')\n",
    "\n",
    "        axes[i, j].set_xlim(math.log10(0.1), math.log10(1000))\n",
    "        axes[i, j].set_axisbelow(True)\n",
    "        axes[i, j].legend(loc=2)\n",
    "        axes[i, j].grid(color='#dddddd')\n",
    "        axes[i, j].set_title(host)\n",
    "        axes[i, j].xaxis.set_major_formatter(logFormatter)\n",
    "\n",
    "fig.suptitle('Sidestream Download Rate PDFs over three week period (0w is trial)')\n",
    "plt.show()\n",
    "print len(bins)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Historical (mlab-sandbox.batch) - Sidestream by Period & Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Variations, for each period:\n",
    "# * all sidestream connections from each period.\n",
    "# * all sidestream connections from each period and slice\n",
    "# * all sidestream connections from each period and slice and from same cohort.\n",
    "# * some sidestream connections from each period and slice and from same cohort, grouped by ts & remote_ip.\n",
    "# * some sidestream connections from each period and slice and from same cohort, grouped by only by remote_ip.\n",
    "\n",
    "result = query.sync_query(\n",
    "    \"\"\"#standardSQL                                                                    \n",
    "    -- Only works for mlab1 addresses. May not work on all machines.\n",
    "CREATE TEMPORARY FUNCTION sliceFromIP(ipaddr STRING)\n",
    "    AS ( MOD(CAST(REGEXP_EXTRACT(ipaddr, r'[:.]([0-9]+)$') AS INT64), 64) - 10 );\n",
    "\n",
    "CREATE TEMPORARY FUNCTION betweenTimes(ts INT64, starttime STRING, endtime STRING)\n",
    "    AS ( TIMESTAMP_SECONDS(ts) >= TIMESTAMP(starttime) AND TIMESTAMP_SECONDS(ts) <= TIMESTAMP(endtime) );\n",
    "\n",
    "SELECT\n",
    "    CASE \n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 1 THEN 'ndt'\n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7 THEN 'samknows'\n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7 THEN 'neubot'\n",
    "        ELSE 'other' \n",
    "    END AS slice,\n",
    "    CASE                                                                          \n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2017-07-26 00:00:00\", \"2017-07-30 00:00:00\") THEN '07-26 to 29'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2017-08-12 00:00:00\", \"2017-08-16 00:00:00\") THEN '08-12 to 16'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2017-10-30 00:00:00\", \"2017-11-02 00:00:00\") THEN '10-30 to 11-02'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2017-11-26 00:00:00\", \"2017-12-01 00:00:00\") THEN '11-29 to 12-03'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-21 00:00:00\", \"2018-02-25 00:00:00\") THEN '02-21 to 25'\n",
    "    ELSE 'bad'                                                                    \n",
    "    END AS period,\n",
    "    REGEXP_EXTRACT(test_id, r\"\\d\\d\\d\\d/\\d\\d/\\d\\d/(mlab[1-4].[a-z]{3}[0-9]{2})\") AS hostname,\n",
    "    web100_log_entry.snap.StartTimeStamp AS ts,                                   \n",
    "    8 * (web100_log_entry.snap.HCThruOctetsAcked /                                \n",
    "      (web100_log_entry.snap.SndLimTimeRwin +                                     \n",
    "       web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "       web100_log_entry.snap.SndLimTimeSnd)) as rate_mbps   \n",
    "FROM\n",
    "    -- `mlab-sandbox.batch.sidestream*`       \n",
    "    `mlab-sandbox.gfr.sidestream_*`\n",
    "WHERE\n",
    "        (  betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2017-07-26 00:00:00\", \"2017-07-30 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2017-08-12 00:00:00\", \"2017-08-16 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2017-11-26 00:00:00\", \"2017-12-01 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2018-02-21 00:00:00\", \"2018-02-25 00:00:00\")\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, \"2017-10-30 00:00:00\", \"2017-11-02 00:00:00\") )\n",
    "  AND (test_id LIKE '%mlab1.dfw%')            \n",
    "  AND web100_log_entry.snap.HCThruOctetsAcked >= 1000000 -- 819200                          \n",
    "  AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "    web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "    web100_log_entry.snap.SndLimTimeSnd) >= 9000000                             \n",
    "  AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "    web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "    web100_log_entry.snap.SndLimTimeSnd) < 600000000                            \n",
    "  AND (web100_log_entry.snap.State = 1 OR                                       \n",
    "    (web100_log_entry.snap.State >= 5 AND                                       \n",
    "    web100_log_entry.snap.State <= 11))\n",
    "  AND web100_log_entry.connection_spec.remote_ip IN(\n",
    "    (SELECT\n",
    "     remote_ip\n",
    "    FROM (\n",
    "      SELECT\n",
    "         web100_log_entry.connection_spec.remote_ip as remote_ip,\n",
    "         count(*) as c1\n",
    "      FROM\n",
    "         -- `mlab-sandbox.batch.sidestream*`\n",
    "          `mlab-sandbox.gfr.sidestream_*`\n",
    "      WHERE\n",
    "          (test_id LIKE '%mlab1.dfw0%')\n",
    "        AND TIMESTAMP_SECONDS(web100_log_entry.log_time) >= TIMESTAMP(\"2017-08-12 00:00:00\")\n",
    "        AND TIMESTAMP_SECONDS(web100_log_entry.log_time) < TIMESTAMP(\"2017-08-16 00:00:00\")\n",
    "        AND sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7\n",
    "      GROUP BY\n",
    "        remote_ip\n",
    "      HAVING c1 > 10\n",
    "    ) INNER JOIN (\n",
    "      SELECT\n",
    "         web100_log_entry.connection_spec.remote_ip as remote_ip,\n",
    "         count(*) as c2\n",
    "      FROM\n",
    "         -- `mlab-sandbox.batch.sidestream*`\n",
    "          `mlab-sandbox.gfr.sidestream_*`\n",
    "      WHERE\n",
    "          (test_id LIKE '%mlab1.dfw0%')\n",
    "        AND TIMESTAMP_SECONDS(web100_log_entry.log_time) >= TIMESTAMP(\"2017-11-26 00:00:00\")\n",
    "        AND TIMESTAMP_SECONDS(web100_log_entry.log_time) < TIMESTAMP(\"2017-11-30 00:00:00\")\n",
    "        AND sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7\n",
    "      GROUP BY\n",
    "        remote_ip\n",
    "      HAVING c2 > 10\n",
    "    ) USING (remote_ip))\n",
    "  )\n",
    "    \n",
    "\n",
    "GROUP BY\n",
    "  hostname, slice, period, ts, rate_mbps\n",
    "    \"\"\")\n",
    "df_ss = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    }
   ],
   "source": [
    "#df_ss_count_raw = df_ss_count\n",
    "\n",
    "result = query.sync_query(\n",
    "    \"\"\"#standardSQL                                                                    \n",
    "CREATE TEMPORARY FUNCTION sliceFromIP(ipaddr STRING)\n",
    "    AS ( MOD(CAST(REGEXP_EXTRACT(ipaddr, r'[:.]([0-9]+)$') AS INT64), 64) - 10 );\n",
    "\n",
    "\n",
    "SELECT\n",
    "   hostname, ts, count(*) as count\n",
    "FROM (\n",
    "    SELECT\n",
    "        REGEXP_EXTRACT(test_id, r\"\\d\\d\\d\\d/\\d\\d/\\d\\d/(mlab[1-4].[a-z]{3}[0-9]{2})\") AS hostname,\n",
    "        UNIX_SECONDS(TIMESTAMP_TRUNC(log_time, DAY)) AS ts                            \n",
    "    FROM\n",
    "        -- `mlab-sandbox.batch.sidestream*`                                              \n",
    "         `mlab-sandbox.gfr.sidestream_*`\n",
    "    WHERE\n",
    "      REGEXP_CONTAINS(test_id, r\"mlab1.(dfw|lga|iad|lax|atl|nuq)[0-9]{2}.*\")     \n",
    "      AND sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7\n",
    "      AND web100_log_entry.snap.HCThruOctetsAcked >= 1000000 -- 819200                          \n",
    "      AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "        web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "        web100_log_entry.snap.SndLimTimeSnd) >= 9000000                             \n",
    "      AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "        web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "        web100_log_entry.snap.SndLimTimeSnd) < 600000000                            \n",
    "      AND (web100_log_entry.snap.State = 1 OR                                       \n",
    "        (web100_log_entry.snap.State >= 5 AND                                       \n",
    "        web100_log_entry.snap.State <= 11))\n",
    "\n",
    "    GROUP BY\n",
    "      hostname, ts, web100_log_entry.connection_spec.remote_ip, web100_log_entry.connection_spec.remote_port, web100_log_entry.connection_spec.local_port, web100_log_entry.connection_spec.local_ip\n",
    ")\n",
    "\n",
    "GROUP BY\n",
    "  hostname, ts\n",
    "ORDER BY\n",
    "  hostname, ts\n",
    "    \"\"\")\n",
    "df_ss_count = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hosts = [\n",
    "    #['mlab1.dfw02', 'mlab1.dfw03', 'mlab1.dfw04', 'mlab1.dfw05'],\n",
    "    #['mlab1.dfw02', 'mlab1.dfw05', 'mlab1.lga02', 'mlab1.lga03', 'mlab1.lga04', 'mlab1.lga05', 'mlab1.lga06'],\n",
    "    #['mlab1.dfw02', 'mlab1.dfw05', 'mlab1.atl02', 'mlab1.atl03', 'mlab1.atl04', 'mlab1.atl05'],\n",
    "    #['mlab1.lax02', 'mlab1.lax03', 'mlab1.lax04', 'mlab1.lax05'],\n",
    "    #['mlab1.dfw02', 'mlab1.dfw05', 'mlab1.iad01', 'mlab1.iad02', 'mlab1.iad03', 'mlab1.iad04', 'mlab1.iad05', 'mlab1.lax02', 'mlab1.lax03', 'mlab1.lax04', 'mlab1.lax05'],\n",
    "    #['mlab1.lga02', 'mlab1.lga03', 'mlab1.lga04', 'mlab1.lga05', 'mlab1.lga06'],\n",
    "    #['mlab1.atl02', 'mlab1.atl03', 'mlab1.atl04', 'mlab1.atl05'],\n",
    "    ['mlab1.dfw02', 'mlab1.dfw05'],\n",
    "]\n",
    "\n",
    "periods_list = [\n",
    "    #(datetime.datetime(2017,  8, 16), datetime.datetime(2017,  8, 23)),\n",
    "    (datetime.datetime(2017,  8, 23), datetime.datetime(2017,   8, 28)),\n",
    "    (datetime.datetime(2017,  8, 28), datetime.datetime(2017,  10, 14)),\n",
    "    #(datetime.datetime(2017, 10, 14), datetime.datetime(2017,  11, 22)),\n",
    "    #(datetime.datetime(2017, 11, 22), datetime.datetime(2018,  1,  7)),\n",
    "    (datetime.datetime(2017, 10, 14), datetime.datetime(2017,  12, 7)),\n",
    "    (datetime.datetime(2017, 12,  7), datetime.datetime(2018,  1,  12)),\n",
    "    (datetime.datetime(2018,  1, 12), datetime.datetime(2018,  1,  21)),\n",
    "    (datetime.datetime(2018,  1, 21), datetime.datetime(2018,  2,  7)),\n",
    "    (datetime.datetime(2018,  2, 7),  datetime.datetime(2018,  3,  10)),\n",
    "    #(datetime.datetime(2017, 11, 22), datetime.datetime(2018,  2, 21)),\n",
    "    #(datetime.datetime(2018,  2, 21), datetime.datetime(2018,  3,  7)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved (datetime.datetime(2017, 8, 23, 0, 0), datetime.datetime(2017, 8, 28, 0, 0)) mlab1.dfw02 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved (datetime.datetime(2017, 8, 23, 0, 0), datetime.datetime(2017, 8, 28, 0, 0)) mlab1.dfw05 318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved (datetime.datetime(2017, 8, 28, 0, 0), datetime.datetime(2017, 10, 14, 0, 0)) mlab1.dfw02 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved (datetime.datetime(2017, 8, 28, 0, 0), datetime.datetime(2017, 10, 14, 0, 0)) mlab1.dfw05 233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved (datetime.datetime(2017, 10, 14, 0, 0), datetime.datetime(2017, 12, 7, 0, 0)) mlab1.dfw02 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved (datetime.datetime(2017, 10, 14, 0, 0), datetime.datetime(2017, 12, 7, 0, 0)) mlab1.dfw05 237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved (datetime.datetime(2017, 12, 7, 0, 0), datetime.datetime(2018, 1, 12, 0, 0)) mlab1.dfw02 192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved (datetime.datetime(2017, 12, 7, 0, 0), datetime.datetime(2018, 1, 12, 0, 0)) mlab1.dfw05 323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved (datetime.datetime(2018, 1, 12, 0, 0), datetime.datetime(2018, 1, 21, 0, 0)) mlab1.dfw02 383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved (datetime.datetime(2018, 1, 12, 0, 0), datetime.datetime(2018, 1, 21, 0, 0)) mlab1.dfw05 569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved (datetime.datetime(2018, 1, 21, 0, 0), datetime.datetime(2018, 2, 7, 0, 0)) mlab1.dfw02 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved (datetime.datetime(2018, 1, 21, 0, 0), datetime.datetime(2018, 2, 7, 0, 0)) mlab1.dfw05 367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved (datetime.datetime(2018, 2, 7, 0, 0), datetime.datetime(2018, 3, 10, 0, 0)) mlab1.dfw02 162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved (datetime.datetime(2018, 2, 7, 0, 0), datetime.datetime(2018, 3, 10, 0, 0)) mlab1.dfw05 214\n"
     ]
    }
   ],
   "source": [
    "# STREAMS WITH MATCHING COHORTS\n",
    "def start_and_end(d):\n",
    "    s = d.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    e = (d + datetime.timedelta(days=4)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    return s, e\n",
    "\n",
    "#df_hosts = []\n",
    "for i, periods in enumerate(periods_list):\n",
    "    a_s, a_e = start_and_end(periods[0])\n",
    "    b_s, b_e = start_and_end(periods[1])\n",
    "    #df_hosts.append({})\n",
    "    #if i not in [2]:\n",
    "    #    print 'skipping', periods_list[i]\n",
    "    #    continue\n",
    "    for host in hosts[0]:\n",
    "        result = query.sync_query(\"\"\"\n",
    "#standardSQL                                                                    \n",
    "    -- Only works for mlab1 addresses. May not work on all machines.\n",
    "CREATE TEMPORARY FUNCTION sliceFromIP(ipaddr STRING)\n",
    "    AS ( MOD(CAST(REGEXP_EXTRACT(ipaddr, r'[:.]([0-9]+)$') AS INT64), 64) - 10 );\n",
    "\n",
    "CREATE TEMPORARY FUNCTION betweenTimes(ts INT64, starttime STRING, endtime STRING)\n",
    "    AS ( TIMESTAMP_SECONDS(ts) >= TIMESTAMP(starttime) AND TIMESTAMP_SECONDS(ts) <= TIMESTAMP(endtime) );\n",
    "\n",
    "SELECT\n",
    "    slice,\n",
    "    period,\n",
    "    hostname,\n",
    "    remote_ip,\n",
    "    AVG(sum_rate_mbps) as sum_rate_mbps\n",
    "\n",
    "FROM (\n",
    "\n",
    "SELECT\n",
    "   slice,\n",
    "   period,\n",
    "   hostname,\n",
    "   remote_ip,\n",
    "   --AVG(rate_mbps) as rate_mbps,\n",
    "   --APPROX_QUANTILES(rate_mbps, 101)[ORDINAL(50)] as med_rate_mbps,\n",
    "   --MAX(rate_mbps) as max_rate_mbps,\n",
    "   SUM(rate_mbps) as sum_rate_mbps\n",
    "    \n",
    "FROM (\n",
    "\n",
    "SELECT\n",
    "    web100_log_entry.connection_spec.remote_ip as remote_ip,\n",
    "    CASE \n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 1 THEN 'ndt'\n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7 THEN 'samknows'\n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 9 THEN 'neubot'\n",
    "        ELSE 'other' \n",
    "    END AS slice,\n",
    "    CASE                                                                          \n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, '\"\"\"+a_s+\"\"\"', '\"\"\"+a_e+\"\"\"')\n",
    "            THEN '\"\"\"+a_s+\"\"\"'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, '\"\"\"+b_s+\"\"\"', '\"\"\"+b_e+\"\"\"')\n",
    "            THEN '\"\"\"+b_s+\"\"\"'\n",
    "    ELSE 'bad'                                                                    \n",
    "    END AS period,\n",
    "    REGEXP_EXTRACT(test_id, r\"\\d\\d\\d\\d/\\d\\d/\\d\\d/(mlab[1-4].[a-z]{3}[0-9]{2})\") AS hostname,\n",
    "    web100_log_entry.snap.StartTimeStamp AS ts,                                   \n",
    "    8 * (web100_log_entry.snap.HCThruOctetsAcked /                                \n",
    "      (web100_log_entry.snap.SndLimTimeRwin +                                     \n",
    "       web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "       web100_log_entry.snap.SndLimTimeSnd)) as rate_mbps   \n",
    "FROM\n",
    "    `mlab-sandbox.batch.sidestream*`                                              \n",
    "WHERE\n",
    "        (  betweenTimes(web100_log_entry.snap.StartTimeStamp, '\"\"\"+a_s+\"\"\"', '\"\"\"+a_e+\"\"\"')\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, '\"\"\"+b_s+\"\"\"', '\"\"\"+b_e+\"\"\"')\n",
    "        )\n",
    "  AND (test_id LIKE '%\"\"\"+host+\"\"\"%')            \n",
    "  AND web100_log_entry.snap.HCThruOctetsAcked >= 1000000 -- 819200                          \n",
    "  AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "    web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "    web100_log_entry.snap.SndLimTimeSnd) >= 9000000                             \n",
    "  AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "    web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "    web100_log_entry.snap.SndLimTimeSnd) < 600000000                            \n",
    "  AND (web100_log_entry.snap.State = 1 OR                                       \n",
    "    (web100_log_entry.snap.State >= 5 AND                                       \n",
    "    web100_log_entry.snap.State <= 11))\n",
    "  AND web100_log_entry.connection_spec.remote_ip IN(\n",
    "    (SELECT\n",
    "     remote_ip\n",
    "    FROM (\n",
    "      SELECT\n",
    "         web100_log_entry.connection_spec.remote_ip as remote_ip,\n",
    "         count(*) as c1\n",
    "      FROM\n",
    "         `mlab-sandbox.batch.sidestream*`\n",
    "      WHERE\n",
    "          (test_id LIKE '%\"\"\"+host+\"\"\"%')\n",
    "        AND betweenTimes(web100_log_entry.snap.StartTimeStamp, '\"\"\"+a_s+\"\"\"', '\"\"\"+a_e+\"\"\"')\n",
    "        AND sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7\n",
    "        AND web100_log_entry.snap.HCThruOctetsAcked >= 819200                          \n",
    "        AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "            web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "            web100_log_entry.snap.SndLimTimeSnd) >= 9000000                             \n",
    "        AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "            web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "            web100_log_entry.snap.SndLimTimeSnd) < 600000000                            \n",
    "        AND (web100_log_entry.snap.State = 1 OR                                       \n",
    "            (web100_log_entry.snap.State >= 5 AND                                       \n",
    "            web100_log_entry.snap.State <= 11))\n",
    "      GROUP BY\n",
    "        remote_ip\n",
    "      HAVING c1 > 10\n",
    "    ) INNER JOIN (\n",
    "      SELECT\n",
    "         web100_log_entry.connection_spec.remote_ip as remote_ip,\n",
    "         count(*) as c2\n",
    "      FROM\n",
    "         `mlab-sandbox.batch.sidestream*`\n",
    "      WHERE\n",
    "          (test_id LIKE '%\"\"\"+host+\"\"\"%')\n",
    "        AND betweenTimes(web100_log_entry.snap.StartTimeStamp, '\"\"\"+b_s+\"\"\"', '\"\"\"+b_e+\"\"\"')\n",
    "        AND sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7\n",
    "                AND web100_log_entry.snap.HCThruOctetsAcked >=  819200                          \n",
    "        AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "            web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "            web100_log_entry.snap.SndLimTimeSnd) >= 9000000                             \n",
    "        AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "            web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "            web100_log_entry.snap.SndLimTimeSnd) < 600000000                            \n",
    "        AND (web100_log_entry.snap.State = 1 OR                                       \n",
    "            (web100_log_entry.snap.State >= 5 AND                                       \n",
    "            web100_log_entry.snap.State <= 11))\n",
    "      GROUP BY\n",
    "        remote_ip\n",
    "      HAVING c2 > 10\n",
    "    ) USING (remote_ip))\n",
    "  )\n",
    "    \n",
    "GROUP BY\n",
    "  hostname, slice, period, ts, web100_log_entry.connection_spec.remote_ip, rate_mbps\n",
    ")\n",
    "\n",
    "GROUP BY\n",
    "  hostname, slice, period, ts,  remote_ip\n",
    ")\n",
    "\n",
    "GROUP BY\n",
    "  hostname, slice, period, remote_ip\n",
    "\"\"\")\n",
    "        df_hosts[i][host] = pd.DataFrame(result)\n",
    "        print 'saved', periods_list[i], host, len(df_hosts[i][host])\n",
    "#df_ss = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mlab1.dfw05', 'mlab1.dfw02', 'mlab1.iad04', 'mlab1.iad05', 'mlab1.iad01', 'mlab1.iad02', 'mlab1.iad03', 'mlab1.lax03', 'mlab1.lax02', 'mlab1.lax05', 'mlab1.lax04']\n"
     ]
    }
   ],
   "source": [
    "print df_hosts[6].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ds = df_hosts[0]['mlab1.dfw02']\n",
    "#a = ds[ (ds['slice'] == 'samknows') & (ds['period'] == '2017-08-23 00:00:00')]\n",
    "##b = ds[ (ds['slice'] == 'samknows') & (ds['period'] == '2017-08-28 00:00:00')]\n",
    "#a, b\n",
    "\n",
    "#pd.merge(a, b,  how='left', left_on=['hostname', 'remote_ip', 'slice'], right_on = ['hostname', 'remote_ip', 'slice'])\n",
    "\n",
    "#a.join(b.set_index('remote_ip'), on='remote_ip', lsuffix='_a', rsuffix='_b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved (datetime.datetime(2017, 8, 16, 0, 0), datetime.datetime(2017, 8, 23, 0, 0)) mlab1.dfw02 31008\n",
      "saved (datetime.datetime(2017, 8, 16, 0, 0), datetime.datetime(2017, 8, 23, 0, 0)) mlab1.dfw03 29927\n",
      "saved (datetime.datetime(2017, 8, 16, 0, 0), datetime.datetime(2017, 8, 23, 0, 0)) mlab1.dfw04 29941\n",
      "saved (datetime.datetime(2017, 8, 16, 0, 0), datetime.datetime(2017, 8, 23, 0, 0)) mlab1.dfw05 31220\n",
      "saved (datetime.datetime(2017, 8, 23, 0, 0), datetime.datetime(2017, 8, 28, 0, 0)) mlab1.dfw02 31113\n",
      "saved (datetime.datetime(2017, 8, 23, 0, 0), datetime.datetime(2017, 8, 28, 0, 0)) mlab1.dfw03 30294\n",
      "saved (datetime.datetime(2017, 8, 23, 0, 0), datetime.datetime(2017, 8, 28, 0, 0)) mlab1.dfw04 29945\n",
      "saved (datetime.datetime(2017, 8, 23, 0, 0), datetime.datetime(2017, 8, 28, 0, 0)) mlab1.dfw05 31137\n",
      "saved (datetime.datetime(2017, 8, 28, 0, 0), datetime.datetime(2017, 11, 22, 0, 0)) mlab1.dfw02 31078\n",
      "saved (datetime.datetime(2017, 8, 28, 0, 0), datetime.datetime(2017, 11, 22, 0, 0)) mlab1.dfw03 31273\n",
      "saved (datetime.datetime(2017, 8, 28, 0, 0), datetime.datetime(2017, 11, 22, 0, 0)) mlab1.dfw04 31348\n",
      "saved (datetime.datetime(2017, 8, 28, 0, 0), datetime.datetime(2017, 11, 22, 0, 0)) mlab1.dfw05 31382\n",
      "saved (datetime.datetime(2017, 11, 22, 0, 0), datetime.datetime(2018, 2, 21, 0, 0)) mlab1.dfw02 33344\n",
      "saved (datetime.datetime(2017, 11, 22, 0, 0), datetime.datetime(2018, 2, 21, 0, 0)) mlab1.dfw03 33696\n",
      "saved (datetime.datetime(2017, 11, 22, 0, 0), datetime.datetime(2018, 2, 21, 0, 0)) mlab1.dfw04 33405\n",
      "saved (datetime.datetime(2017, 11, 22, 0, 0), datetime.datetime(2018, 2, 21, 0, 0)) mlab1.dfw05 32253\n",
      "saved (datetime.datetime(2018, 2, 21, 0, 0), datetime.datetime(2018, 3, 7, 0, 0)) mlab1.dfw02 39887\n",
      "saved (datetime.datetime(2018, 2, 21, 0, 0), datetime.datetime(2018, 3, 7, 0, 0)) mlab1.dfw03 38836\n",
      "saved (datetime.datetime(2018, 2, 21, 0, 0), datetime.datetime(2018, 3, 7, 0, 0)) mlab1.dfw04 36768\n",
      "saved (datetime.datetime(2018, 2, 21, 0, 0), datetime.datetime(2018, 3, 7, 0, 0)) mlab1.dfw05 37670\n"
     ]
    }
   ],
   "source": [
    "# ALL STREAMS per PERIOD\n",
    "\n",
    "def start_and_end(d):\n",
    "    s = d.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    e = (d + datetime.timedelta(days=4)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    return s, e\n",
    "\n",
    "df_hosts = []\n",
    "for i, periods in enumerate(periods_list):\n",
    "    a_s, a_e = start_and_end(periods[0])\n",
    "    b_s, b_e = start_and_end(periods[1])\n",
    "    df_hosts.append({})\n",
    "    #if i not in [2]:\n",
    "    #    print 'skipping', periods_list[i]\n",
    "    #    continue\n",
    "    for host in hosts[0]:\n",
    "        result = query.sync_query(\"\"\"\n",
    "#standardSQL                                                                    \n",
    "    -- Only works for mlab1 addresses. May not work on all machines.\n",
    "CREATE TEMPORARY FUNCTION sliceFromIP(ipaddr STRING)\n",
    "    AS ( MOD(CAST(REGEXP_EXTRACT(ipaddr, r'[:.]([0-9]+)$') AS INT64), 64) - 10 );\n",
    "\n",
    "CREATE TEMPORARY FUNCTION betweenTimes(ts INT64, starttime STRING, endtime STRING)\n",
    "    AS ( TIMESTAMP_SECONDS(ts) >= TIMESTAMP(starttime) AND TIMESTAMP_SECONDS(ts) <= TIMESTAMP(endtime) );\n",
    "\n",
    "SELECT\n",
    "   slice,\n",
    "   period,\n",
    "   hostname,\n",
    "   AVG(rate_mbps) as rate_mbps,\n",
    "   APPROX_QUANTILES(rate_mbps, 101)[ORDINAL(50)] as med_rate_mbps,\n",
    "   MAX(rate_mbps) as max_rate_mbps,\n",
    "   SUM(rate_mbps) as sum_rate_mbps\n",
    "    \n",
    "FROM (\n",
    "\n",
    "SELECT\n",
    "    web100_log_entry.connection_spec.remote_ip as remote_ip,\n",
    "    CASE \n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 1 THEN 'ndt'\n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7 THEN 'samknows'\n",
    "        WHEN sliceFromIP(web100_log_entry.connection_spec.local_ip) = 7 THEN 'neubot'\n",
    "        ELSE 'other' \n",
    "    END AS slice,\n",
    "    CASE                                                                          \n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, '\"\"\"+a_s+\"\"\"', '\"\"\"+a_e+\"\"\"')\n",
    "            THEN '\"\"\"+a_s+\"\"\"'\n",
    "        WHEN betweenTimes(web100_log_entry.snap.StartTimeStamp, '\"\"\"+b_s+\"\"\"', '\"\"\"+b_e+\"\"\"')\n",
    "            THEN '\"\"\"+b_s+\"\"\"'\n",
    "    ELSE 'bad'                                                                    \n",
    "    END AS period,\n",
    "    REGEXP_EXTRACT(test_id, r\"\\d\\d\\d\\d/\\d\\d/\\d\\d/(mlab[1-4].[a-z]{3}[0-9]{2})\") AS hostname,\n",
    "    web100_log_entry.snap.StartTimeStamp AS ts,                                   \n",
    "    8 * (web100_log_entry.snap.HCThruOctetsAcked /                                \n",
    "      (web100_log_entry.snap.SndLimTimeRwin +                                     \n",
    "       web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "       web100_log_entry.snap.SndLimTimeSnd)) as rate_mbps   \n",
    "FROM\n",
    "    `mlab-sandbox.batch.sidestream*`                                              \n",
    "WHERE\n",
    "        (  betweenTimes(web100_log_entry.snap.StartTimeStamp, '\"\"\"+a_s+\"\"\"', '\"\"\"+a_e+\"\"\"')\n",
    "        OR betweenTimes(web100_log_entry.snap.StartTimeStamp, '\"\"\"+b_s+\"\"\"', '\"\"\"+b_e+\"\"\"')\n",
    "        )\n",
    "  AND (test_id LIKE '%\"\"\"+host+\"\"\"%')            \n",
    "  AND web100_log_entry.snap.HCThruOctetsAcked >= 1000000 -- 819200                          \n",
    "  AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "    web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "    web100_log_entry.snap.SndLimTimeSnd) >= 9000000                             \n",
    "  AND (web100_log_entry.snap.SndLimTimeRwin +                                   \n",
    "    web100_log_entry.snap.SndLimTimeCwnd +                                      \n",
    "    web100_log_entry.snap.SndLimTimeSnd) < 600000000                            \n",
    "  AND (web100_log_entry.snap.State = 1 OR                                       \n",
    "    (web100_log_entry.snap.State >= 5 AND                                       \n",
    "    web100_log_entry.snap.State <= 11))\n",
    "    \n",
    "GROUP BY\n",
    "  hostname, slice, period, ts, web100_log_entry.connection_spec.remote_ip, rate_mbps\n",
    ")\n",
    "\n",
    "GROUP BY\n",
    "  hostname, slice, period,   remote_ip -- CAST(ts/4 AS INT64),\n",
    "\"\"\")\n",
    "        df_hosts[i][host] = pd.DataFrame(result)\n",
    "        print 'saved', periods_list[i], host, len(df_hosts[i][host])\n",
    "#df_ss = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sidestream CDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10079 507.5426899233347\n"
     ]
    }
   ],
   "source": [
    "title = 'CDF - per-slice sidestream Download Rate CDFs'\n",
    "print len(df_ss), max(df_ss['rate_mbps']) # 'sqrt', int(math.sqrt(len(df['rate_mbps'])))\n",
    "\n",
    "hosts = [\n",
    "    ['mlab1.dfw02', 'mlab1.dfw03', 'mlab1.dfw04'],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=len(hosts[0]), figsize=(13, 10))\n",
    "\n",
    "for i, host_row in enumerate(hosts):\n",
    "    for j, host in enumerate(host_row):\n",
    "        if len(df_ss[ df_ss['hostname'] == host ]) == 0:\n",
    "            print 'skipping', host\n",
    "            continue\n",
    "        for period in ['08-12 to 16', '11-29 to 12-03', '02-21 to 25']: #set(df['period']):\n",
    "            ds = df_ss[ (df_ss['period'] == period) & (df_ss['hostname'] == host) ]\n",
    "            for k, slicename in enumerate(['ndt', 'samknows']): # set(ds['slice']):\n",
    "                #print 'sqrt', int(math.sqrt(len(ds['rate_mbps'])))\n",
    "                d = ds[ ds['slice'] == slicename ]\n",
    "                if len(d) == 0:\n",
    "                    continue\n",
    "                ax = axes[k, j]\n",
    "                #n, bins, patches = ax.hist(ds['rate_mbps'], len(ds['rate_mbps']),\n",
    "                #                   histtype='step', normed=1, cumulative=True, label='cdf-' + period,\n",
    "                #                   ls='-')\n",
    "                r = [math.log10(x) for x in d['rate_mbps']]\n",
    "                n, bins, patches = ax.hist(d['rate_mbps'], int(math.sqrt(len(d['rate_mbps']))),\n",
    "                                   histtype='step', normed=1, cumulative=True, label=('cdf-' + period + '-' + slicename), \n",
    "                                   ls='-')\n",
    "\n",
    "                ax.set_xlim(1, 200)       \n",
    "                ax.set_axisbelow(True)\n",
    "        #ax.semilogx()\n",
    "                ax.legend(loc=4, fontsize='x-small')\n",
    "\n",
    "                ax.grid(color='#dddddd')\n",
    "                ax.set_title(host)\n",
    "        #labels = ['%.2f' % math.pow(10, float(l)) for l in ax.get_xticks()]\n",
    "        #ax.xaxis.set_major_formatter(logFormatter)\n",
    "        \n",
    "\n",
    "fig.suptitle(title)\n",
    "\n",
    "plt.show()\n",
    "#print n, len(bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sidestream PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10079 507.5426899233347\n"
     ]
    }
   ],
   "source": [
    "title = 'PDF - per-slice sidestream Download Rate PDFs'\n",
    "print len(df_ss), max(df_ss['rate_mbps']) # 'sqrt', int(math.sqrt(len(df['rate_mbps'])))\n",
    "\n",
    "hosts = [\n",
    "    ['mlab1.dfw02', 'mlab1.dfw03', 'mlab1.dfw04'],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=len(hosts[0]), figsize=(13, 10))\n",
    "for i, host_row in enumerate(hosts):\n",
    "    for j, host in enumerate(host_row):\n",
    "        if len(df_ss[ df_ss['hostname'] == host ]) == 0:\n",
    "            print 'skipping', host\n",
    "            continue\n",
    "        for period in ['08-12 to 16', '02-21 to 25']: # '11-29 to 12-03',  #set(df['period']):\n",
    "            ds = df_ss[ (df_ss['period'] == period) & (df_ss['hostname'] == host) ]\n",
    "            for k, slicename in enumerate(['ndt', 'samknows']): # set(ds['slice']):\n",
    "                #print 'sqrt', int(math.sqrt(len(ds['rate_mbps'])))\n",
    "                d = ds[ ds['slice'] == slicename ]\n",
    "                if len(d) == 0:\n",
    "                    continue\n",
    "                ax = axes[k, j]\n",
    "\n",
    "                label = 'pdf-%s-%s (%d)' % (period, slicename, len(d['rate_mbps']))\n",
    "                r = [math.log10(x) for x in d['rate_mbps']]\n",
    "                n, bins, patches = ax.hist(r, int(math.sqrt(len(d['rate_mbps']))),\n",
    "                                   histtype='step', normed=1, label=label, \n",
    "                                   ls='-')\n",
    "\n",
    "                #ax.set_xlim(1, 200)       \n",
    "                #ax.semilogx()\n",
    "                #ax.set_ylim(0, 1.4)\n",
    "                ax.set_axisbelow(True)\n",
    "                ax.legend(loc=2, fontsize='x-small')\n",
    "\n",
    "                ax.grid(color='#dddddd')\n",
    "                ax.set_title(host)\n",
    "                ax.xaxis.set_major_formatter(logFormatter)\n",
    "        \n",
    "fig.suptitle(title)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF, CDF, & Switch - by Site and Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['iad', 'dfw', 'lga', 'lax', 'atl'])\n",
      "[['mlab1.iad01', 'mlab1.iad02', 'mlab1.iad03', 'mlab1.iad04', 'mlab1.iad05'], ['mlab1.dfw02', 'mlab1.dfw05'], ['mlab1.lga02', 'mlab1.lga03', 'mlab1.lga04', 'mlab1.lga05', 'mlab1.lga06'], ['mlab1.lax02', 'mlab1.lax03', 'mlab1.lax04', 'mlab1.lax05'], ['mlab1.atl02', 'mlab1.atl03', 'mlab1.atl04', 'mlab1.atl05']]\n"
     ]
    }
   ],
   "source": [
    "# extract metros\n",
    "metros = set([h[6:9] for h in df_hosts[0].keys()])\n",
    "print metros\n",
    "hosts = []\n",
    "for i, metro in enumerate(metros):\n",
    "    m = []\n",
    "    for h in df_hosts[0].keys():\n",
    "        if metro in h:\n",
    "            m.append(h)\n",
    "    hosts.append(sorted(m))\n",
    "print hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        hostname               period  \\\n",
      "0    mlab1.dfw02  2017-08-23 00:00:00   \n",
      "1    mlab1.dfw02  2017-08-23 00:00:00   \n",
      "2    mlab1.dfw02  2017-08-23 00:00:00   \n",
      "3    mlab1.dfw02  2017-08-23 00:00:00   \n",
      "4    mlab1.dfw02  2017-08-23 00:00:00   \n",
      "5    mlab1.dfw02  2017-08-23 00:00:00   \n",
      "6    mlab1.dfw02  2017-08-23 00:00:00   \n",
      "7    mlab1.dfw02  2017-08-23 00:00:00   \n",
      "8    mlab1.dfw02  2017-08-23 00:00:00   \n",
      "9    mlab1.dfw02  2017-08-23 00:00:00   \n",
      "10   mlab1.dfw02  2017-08-23 00:00:00   \n",
      "11   mlab1.dfw02  2017-08-23 00:00:00   \n",
      "12   mlab1.dfw02  2017-08-23 00:00:00   \n",
      "13   mlab1.dfw02  2017-08-23 00:00:00   \n",
      "14   mlab1.dfw02  2017-08-23 00:00:00   \n",
      "15   mlab1.dfw02  2017-08-23 00:00:00   \n",
      "16   mlab1.dfw02  2017-08-23 00:00:00   \n",
      "17   mlab1.dfw02  2017-08-23 00:00:00   \n",
      "18   mlab1.dfw02  2017-08-23 00:00:00   \n",
      "19   mlab1.dfw02  2017-08-23 00:00:00   \n",
      "20   mlab1.dfw02  2017-08-23 00:00:00   \n",
      "21   mlab1.dfw02  2017-08-23 00:00:00   \n",
      "22   mlab1.dfw02  2017-08-23 00:00:00   \n",
      "23   mlab1.dfw02  2017-08-23 00:00:00   \n",
      "24   mlab1.dfw02  2017-08-23 00:00:00   \n",
      "25   mlab1.dfw02  2017-08-23 00:00:00   \n",
      "26   mlab1.dfw02  2017-08-23 00:00:00   \n",
      "27   mlab1.dfw02  2017-08-23 00:00:00   \n",
      "28   mlab1.dfw02  2017-08-23 00:00:00   \n",
      "29   mlab1.dfw02  2017-08-23 00:00:00   \n",
      "..           ...                  ...   \n",
      "160  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "161  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "162  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "163  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "164  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "165  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "166  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "167  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "168  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "169  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "170  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "171  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "172  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "173  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "174  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "175  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "176  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "177  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "178  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "179  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "180  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "181  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "182  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "183  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "184  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "185  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "186  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "187  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "188  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "189  mlab1.dfw02  2017-08-28 00:00:00   \n",
      "\n",
      "                                   remote_ip     slice  sum_rate_mbps  \n",
      "0                              72.129.234.74  samknows      23.290562  \n",
      "1                                76.85.0.126  samknows       5.244051  \n",
      "2                             24.255.133.181  samknows      59.383931  \n",
      "3                             70.122.212.222  samknows      24.792585  \n",
      "4     2600:8804:5500:4a70:aa74:ce49:945:efc3  samknows     118.006453  \n",
      "5                              76.205.156.88  samknows      11.793089  \n",
      "6                             47.189.111.222  samknows      29.829194  \n",
      "7                               68.12.119.44  samknows     136.040807  \n",
      "8                                68.12.76.26  samknows      33.628377  \n",
      "9                              76.251.38.202  samknows       6.824098  \n",
      "10      2600:8803:aa00:6b:6666:b3ff:fece:688  samknows     155.767867  \n",
      "11                             184.189.82.70  samknows     156.871890  \n",
      "12                             63.153.164.91  samknows      21.361686  \n",
      "13                           173.172.148.143  samknows      24.922444  \n",
      "14                             24.254.65.164  samknows      42.592685  \n",
      "15   2605:6000:3f83:7100:eade:27ff:fefe:9c8f  samknows      22.892995  \n",
      "16                             72.204.57.141  samknows      12.729242  \n",
      "17                             72.177.190.11  samknows       3.126743  \n",
      "18   2605:6001:e802:e000:eade:27ff:fefe:a37b  samknows     335.873731  \n",
      "19   2605:6000:37af:a700:eade:27ff:fefe:8a37  samknows      22.917898  \n",
      "20                             47.217.96.103  samknows     163.105047  \n",
      "21                             24.243.20.125  samknows       2.510768  \n",
      "22                             24.242.32.236  samknows      20.340672  \n",
      "23                            47.186.199.146  samknows      24.831844  \n",
      "24   2605:6000:376b:ca00:eade:27ff:fefe:8b3b  samknows     284.011353  \n",
      "25    2602:304:ccd9:c580:da37:beff:fefe:3007  samknows      11.986840  \n",
      "26                              73.2.230.109  samknows      37.575211  \n",
      "27                             76.183.183.12  samknows      25.460045  \n",
      "28                            24.252.111.177  samknows      13.022904  \n",
      "29   2605:6000:e7cb:1300:fa1a:67ff:fe5a:7967  samknows       3.458054  \n",
      "..                                       ...       ...            ...  \n",
      "160                           24.166.176.227  samknows     318.466313  \n",
      "161                             72.200.45.86  samknows      51.811178  \n",
      "162                            70.120.93.214  samknows       2.578769  \n",
      "163                          107.221.187.113  samknows      39.784682  \n",
      "164                            68.12.154.245  samknows      58.238991  \n",
      "165                            66.25.144.140  samknows       1.118127  \n",
      "166                            173.172.83.35  samknows     308.308635  \n",
      "167                            67.60.209.151  samknows      76.493270  \n",
      "168                          173.172.148.143  samknows      25.080554  \n",
      "169  2605:6000:6688:5500:eade:27ff:fefe:9097  samknows     333.394962  \n",
      "170                             70.119.70.99  samknows     201.669162  \n",
      "171                              76.85.0.126  samknows       3.013029  \n",
      "172   2602:306:c41f:1e20:6666:b3ff:feeb:11e2  samknows      48.002591  \n",
      "173                            99.101.201.73  samknows      13.138787  \n",
      "174                           24.252.111.177  samknows      12.030128  \n",
      "175   2600:8804:5500:4a70:aa74:ce49:945:efc3  samknows      77.645636  \n",
      "176                              75.81.7.189  samknows      19.962254  \n",
      "177                             24.55.56.197  samknows     113.880215  \n",
      "178                             68.12.119.44  samknows     114.425559  \n",
      "179                             68.11.134.26  samknows     113.118282  \n",
      "180                            76.251.38.202  samknows       6.080120  \n",
      "181                           72.200.192.173  samknows     132.036372  \n",
      "182   2602:304:ccd9:c580:da37:beff:fefe:3007  samknows      14.329296  \n",
      "183                              68.12.76.26  samknows      28.799124  \n",
      "184                            104.57.183.87  samknows     161.351296  \n",
      "185                            24.243.20.125  samknows       2.510621  \n",
      "186  2605:6000:3bac:7600:eade:27ff:fefe:8a93  samknows      22.926840  \n",
      "187                            71.96.207.246  samknows      57.299097  \n",
      "188  2605:6000:e7cb:1300:fa1a:67ff:fe5a:7967  samknows       4.012922  \n",
      "189  2605:6001:e802:e000:eade:27ff:fefe:a37b  samknows     337.051856  \n",
      "\n",
      "[190 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print df_hosts[0]['mlab1.dfw02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last\n",
      "last\n"
     ]
    }
   ],
   "source": [
    "title = 'PDF, CDF, Switch - slice sidestream Download Rates'\n",
    "#print len(df_ss), max(df_ss['rate_mbps']) # 'sqrt', int(math.sqrt(len(df['rate_mbps'])))\n",
    "\n",
    "d = None\n",
    "df=None\n",
    "label2date = {}\n",
    "#slices = ['samknows', 'ndt']\n",
    "slices = ['samknows']\n",
    "colors = plt.cm.Dark2.colors\n",
    "colors = plt.cm.tab10.colors\n",
    "p2c = {}\n",
    "c=0\n",
    "\n",
    "\n",
    "for i, host_row in enumerate(hosts):\n",
    "    for j, host in enumerate(host_row):\n",
    "\n",
    "        rows = 4\n",
    "        cols = len(periods_list)\n",
    "        fig = plt.figure(figsize=(4 * cols, 13))\n",
    "        axes = [\n",
    "            [None] * cols,\n",
    "            [None] * cols,\n",
    "            [None] * cols,\n",
    "            None,\n",
    "        ]\n",
    "\n",
    "        for p, times in enumerate(periods_list):\n",
    "            axes[0][p] = plt.subplot2grid((rows, cols), (0, p))\n",
    "            axes[1][p] = plt.subplot2grid((rows, cols), (1, p))\n",
    "            axes[2][p] = plt.subplot2grid((rows, cols), (2, p))\n",
    "\n",
    "            for k, slicename in enumerate(slices):\n",
    "                \n",
    "                df_ss = df_hosts[p][host]\n",
    "                if len(df_ss) == 0:\n",
    "                    print 'skipping', host, 'no data'\n",
    "                    continue\n",
    "                if len(df_ss[ df_ss['hostname'] == host ]) == 0:\n",
    "                    print 'skipping', host\n",
    "                    continue\n",
    "                \n",
    "                t_a, t_b = times\n",
    "                p_a, p_b = t_a.strftime(\"%Y-%m-%d %H:%M:%S\"), t_b.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                \n",
    "                a = df_ss[ (df_ss['slice'] == slicename) & (df_ss['period'] == p_a) ]\n",
    "                b = df_ss[ (df_ss['slice'] == slicename) & (df_ss['period'] == p_b) ]\n",
    "                #print 'len ab', len(a), len(b)\n",
    "\n",
    "                columns = ['hostname', 'remote_ip', 'slice']\n",
    "                ds = pd.merge(a, b,  how='left', left_on=columns, right_on=columns)\n",
    "                #print ds   \n",
    "                for period_str in [p_a, p_b]:\n",
    "                    if period_str not in p2c:\n",
    "                        p2c[period_str] = colors[c]\n",
    "                        c += 1\n",
    "                \n",
    "                if True:\n",
    "                    #ds = df_ss[ (df_ss['period'] == period_str) &\n",
    "                    #            (df_ss['hostname'] == host) &\n",
    "                    #            (df_ss['slice'] == slicename) ]\n",
    "                    if len(ds['sum_rate_mbps_x'].dropna()) == 0 or len(ds['sum_rate_mbps_y'].dropna()) == 0:\n",
    "                        continue\n",
    "\n",
    "                # Top\n",
    "                ax = axes[0][p]\n",
    "                for period, l in [(t_a, ds['sum_rate_mbps_x']), (t_b, ds['sum_rate_mbps_y'])]:\n",
    "                    vals = [math.log10(x) for x in l.dropna()]\n",
    "                    period_str = period.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    label = 'pdf-%s-%s (%d)' % (period_str, slicename, len(vals))\n",
    "                    label2date[label] = period\n",
    "                    #color = p2c[period_str]\n",
    "                    \n",
    "                    #print len(l), len(l.dropna()), int(math.sqrt(len(vals)))\n",
    "                    #print label\n",
    "                    #print color\n",
    "                    \n",
    "                    sqrt_bins = int(math.sqrt(len(vals)))\n",
    "                    #print 'bins', sqrt_bins\n",
    "                    #print period_str, label, color\n",
    "                    n, bins, patches = ax.hist(\n",
    "                            vals, sqrt_bins,\n",
    "                            histtype='step', normed=1, label=label, ls='-', color=p2c[period_str])\n",
    "\n",
    "                ax.set_axisbelow(True)\n",
    "                ax.legend(fontsize='x-small', loc='upper center', bbox_to_anchor=(0.5, 1.3))\n",
    "                ax.grid(color='#dddddd')\n",
    "                ax.set_title(host)\n",
    "                ax.xaxis.set_major_formatter(logFormatter)\n",
    "\n",
    "                # Middle\n",
    "                ax = axes[1][p]\n",
    "                for period, l in [(t_a, ds['sum_rate_mbps_x']), (t_b, ds['sum_rate_mbps_y'])]:\n",
    "                    vals = [math.log10(x) for x in  l.dropna()]\n",
    "                    period_str = period.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    label = 'cdf-%s-%s (%d)' % (period_str, slicename, len(vals))\n",
    "\n",
    "                    n, bins, patches = ax.hist(vals, len(vals),\n",
    "                                               histtype='step', normed=1, cumulative=True, label=label, ls='-',\n",
    "                                               color=p2c[period_str])\n",
    "\n",
    "                    ax.xaxis.set_major_formatter(logFormatter)\n",
    "                    ax.set_axisbelow(True)\n",
    "                    #ax.legend(fontsize='x-small', loc='upper center', bbox_to_anchor=(0.5, 1.3))\n",
    "\n",
    "                    ax.grid(color='#dddddd')\n",
    "                    ax.set_title(host)\n",
    "                    if p != 0:\n",
    "                        ax.set_yticklabels([])\n",
    "\n",
    "                if True:\n",
    "                    # Bottom\n",
    "                    #t_a, t_b = times\n",
    "                    #p_a, p_b = t_a.strftime(\"%Y-%m-%d %H:%M:%S\"), t_b.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    #a = df_ss[ (df_ss['slice'] == slicename) & (df_ss['period'] == p_a) ]\n",
    "                    #b = df_ss[ (df_ss['slice'] == slicename) & (df_ss['period'] == p_b) ]\n",
    "\n",
    "                    #columns = ['hostname', 'remote_ip', 'slice']\n",
    "                    #d = pd.merge(a, b,  how='left', left_on=columns, right_on=columns)\n",
    "\n",
    "                    ax = axes[2][p]\n",
    "                    \n",
    "                    label = 'scatter-%s (%d)/(%d)' % (slicename, len(ds['sum_rate_mbps_x']), len(ds['sum_rate_mbps_y']))\n",
    "                    \n",
    "                    ax.plot([0.1, 1000], [0.1, 1000], color='r', alpha=0.1)\n",
    "                    ax.add_patch(\n",
    "                        matplotlib.patches.Polygon(\n",
    "                            [[.1, .1], [1000, .1], [1000, 1000], [.1, .1]], closed=True,\n",
    "                            fill=True, color=p2c[p_b], alpha=0.1))\n",
    "                    ax.add_patch(\n",
    "                        matplotlib.patches.Polygon(\n",
    "                            [[.1, .1], [.1, 1000], [1000, 1000], [.1, .1]], closed=True,\n",
    "                            fill=True, color=p2c[p_a], alpha=0.1))\n",
    "                    ax.scatter(ds['sum_rate_mbps_y'], ds['sum_rate_mbps_x'], s=2, alpha=0.3, label=label)\n",
    "                    \n",
    "                    #ax.scatter([100], [200])\n",
    "                    ax.set_xlim(.1, 1000)\n",
    "                    ax.set_ylim(.1, 1000)\n",
    "                    \n",
    "                    #ax.set_xlabel('slow')\n",
    "                    #ax.set_ylabel('fast')\n",
    "                    ax.set_xlabel(p_b)\n",
    "                    ax.set_ylabel(p_a)\n",
    "\n",
    "                    \n",
    "                    #ax.xaxis.set_major_formatter(logFormatter)\n",
    "\n",
    "                    #ax.set_axisbelow(True)\n",
    "                    ax.grid(color='#dddddd')\n",
    "                    ax.semilogx()\n",
    "                    ax.semilogy()\n",
    "                    ax.legend(fontsize='x-small')\n",
    "\n",
    "                    #ax.set_title(host)\n",
    "                    #if p != 0:\n",
    "                    #    ax.set_yticklabels([])\n",
    "                        \n",
    "            axes[0][p].set_xlim(math.log10(.1), math.log10(1100))\n",
    "            axes[1][p].set_xlim(math.log10(.1), math.log10(1100))\n",
    "\n",
    "        if True:\n",
    "            print 'last'\n",
    "            axes[3] = plt.subplot2grid((rows, cols), (3, 0), colspan=cols)\n",
    "            ax = axes[3]\n",
    "        \n",
    "            ds = df_disco[ df_disco['hostname'] == host ]\n",
    "            ax.plot_date(dates.epoch2num(ds['ts']), ds['pct_discards'], ls='-', ms=0, label='switch', color='mediumpurple')\n",
    "        \n",
    "            ax.set_title(host)\n",
    "            ax.set_ylim(-0.01, 1)\n",
    "            ax.tick_params(axis='x', labelrotation=90)\n",
    "            ax.grid(color='#dddddd')\n",
    "            #ax.legend(loc=4, fontsize='x-small') \n",
    " \n",
    "            # Color switch regions with the PDF periods based on legend colors.\n",
    "            for p in range(0, len(periods_list)):\n",
    "                h, l = axes[0][p].get_legend_handles_labels()\n",
    "                for k, line in enumerate(h):\n",
    "                    s = label2date[l[k]]\n",
    "                    e = s + datetime.timedelta(days=4)\n",
    "                    color = h[k].get_edgecolor()\n",
    "                    ax.axvspan(dates.date2num(s), dates.date2num(e), alpha=0.5, color=color)\n",
    "\n",
    "            ax.set_ylabel('% discard timebins')                \n",
    "            ax2 = ax.twinx()\n",
    "        \n",
    "            ds = df_ss_count[ df_ss_count['hostname'] == host ]\n",
    "            ax2.plot_date(dates.epoch2num(ds['ts']), ds['count'], ls='-', ms=0, label='sidestream')\n",
    "\n",
    "            if p != 4:\n",
    "                ax2.set_yticklabels([])\n",
    "            else:\n",
    "                ax2.set_ylabel('Sidestream Flow Count')\n",
    "\n",
    "            ax2.grid(color='#dddddd')\n",
    "            ax.legend(loc=3, fontsize='small') \n",
    "            ax2.legend(loc=1, fontsize='small') \n",
    "\n",
    "     \n",
    "        axes[0][0].set_ylabel('PDF')\n",
    "        axes[1][0].set_ylabel('CDF')\n",
    "        #axes[2, 0].set_ylabel('% discard timebins')    \n",
    "        #axes[2, 0].set_ylabel('Sidestream Flow Count')    \n",
    "\n",
    "        fig.suptitle(title) # + ('\\n%s' % [period.strftime(\"%Y-%m-%d %H:%M:%S\") for period in times]))\n",
    "        fig.subplots_adjust(hspace=0.3, wspace=0.4)\n",
    "        plt.show()\n",
    "\n",
    "#plt.hist2d(\n",
    "#    df_ss[ (df_ss['period'] == '08-12 to 16') & (df_ss['hostname'] == 'mlab1.dfw02') & (df_ss['slice'] == 'samknows') ],\n",
    "#    df_ss[ (df_ss['period'] == '02-21 to 25') & (df_ss['hostname'] == 'mlab1.dfw02') & (df_ss['slice'] == 'samknows') ],\n",
    "#    bins=40,\n",
    "#)\n",
    "#print n, len(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print ds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
